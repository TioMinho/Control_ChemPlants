% ---------------------------------------------------------------
% Preamble
% ---------------------------------------------------------------
\documentclass[a4paper,11pt]{book}

\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage[margin=1in,a4paper,pdftex]{geometry}
\usepackage[protrusion=true,expansion=true]{microtype} 
\usepackage{amsmath,amsfonts,amsthm,amssymb,bm,mathdots,mathtools}
\usepackage{rotating}
\usepackage[colorlinks=true, linkcolor=blue, urlcolor=blue, anchorcolor=blue, citecolor=red]{hyperref}
\usepackage[all]{hypcap}
\usepackage{color, xcolor}
\usepackage{listings}
\usepackage[ruled,linesnumbered]{algorithm2e}
\usepackage{cite}
\usepackage{makecell}
\usepackage[printwatermark]{xwatermark}
\usepackage{subcaption}

\usepackage{framed}
\definecolor{shadecolor}{rgb}{0.94,0.94,0.96}

\numberwithin{figure}{chapter}
\numberwithin{equation}{chapter}
\numberwithin{table}{chapter}

\newtheorem{theorem}{Theorem}[chapter]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}

\theoremstyle{definition}
\newtheorem{definition}{Definition}[chapter]

\newwatermark[allpages,color=red!15,angle=45,scale=5,xpos=-1cm,ypos=2cm]{DRAFT}

\makeatletter
\setlength{\@fptop}{0pt}
\makeatother

\usepackage{graphicx}
\graphicspath{ {imgs/} }

\lstset{
    backgroundcolor=\color[rgb]{0.86,0.88,0.93},
    language=matlab, keywordstyle=\color[rgb]{0,0,1},
    basicstyle=\footnotesize \ttfamily,breaklines=true,
    escapeinside={\%*}{*)}
}

% --------------------------------------------------------------------
% Definitions
% --------------------------------------------------------------------
\newcommand{\HRule}[1]{\rule{\linewidth}{#1}} 

\makeatletter                       
\def\printtitle{
    {\centering \@title\par}}
\makeatother                                    

\makeatletter 
\def\printauthor{
    {\centering \large \@author}}               
\makeatother                            

\newcounter{boxed-theorem}
\makeatletter
\newenvironment{boxed-theorem}[1]
{\begin{shaded} \begin{theorem}{#1}}
{\end{theorem} \end{shaded}}

\newcounter{boxed-definition}
\makeatletter
\newenvironment{boxed-definition}[1]
{\begin{shaded} \begin{definition}{#1}}
{\end{definition} \end{shaded}}

% ---------------------------------------------------------------
% Metadata 
% ---------------------------------------------------------------
\title{ \normalsize \textsc{Course Conclusion Paper - DRAFT} 
        \\[2.0cm]             
        \HRule{0.5pt} \\              
        \LARGE \textbf{\uppercase{Dynamical Modelling and Control of Chemical Reactive Systems}}
        \HRule{2pt} \\[0.5cm]  
}

\author{
        Otacílio Bezerra Leite Neto\\   
        Federal University of Ceará\\  
        Department of Teleinformatics Engineering\\
        \texttt{minhotmog@gmail.com} \\
}

\begin{document}
% ---------------------------------------------------------------
% Maketitle
% ---------------------------------------------------------------
\thispagestyle{empty}       % Remove page numbering on this page

\printtitle                 % Print the title data as defined above
    \vfill
\printauthor                % Print the author data as defined above
\newpage

% ---------------------------------------------------------------
% Begin document
% ---------------------------------------------------------------
% Set page numbering to begin on this page
\thispagestyle{empty}   
\tableofcontents

% 1 - Introduction
% ---------------------------------------------------------------
\clearpage
\setcounter{page}{1}
\chapter{Introduction}

This chapter presents the main problem in discussion and the basic concepts concerning its formulation and solutions, which are detailed further in the next chapters. This is a work on Control Theory and its application to Chemical Reactive Systems, therefore the discussion will follow the notation common to the literature of this field, and a ``modern" approach to this theory is explored. 

The sections are organized as follows: Section 1.1 provides general definitions for control systems engineering, Section 1.2 discuss chemical reactive systems and its importance in both industry and academia, Sections 1.3 and 1.4 describes the motivation and justification of this work, respectively, and Section 1.5 details the subsequent chapters in this document.

\section{Control Systems Engineering}

The discipline of Control Systems Engineering deals with the design of devices, named \textit{controllers}, that are integrated to a physical system (a \textit{dynamical system}, in most cases) in order to impose a desired behavior to this system. To achieve this goal, the discipline covers topics ranging from applied mathematics, such as dynamical systems theory and signal processing, to a more engineering discussion, regarding instrumentation and implementation of these controllers in a real-life plant or individual system. 

A system, in a broad physical sense, is defined as a ensemble of interacting components that responds to external stimuli producing a determined dynamical response, and whose individual parts are not able to produce the same functionality by their own. Thus, the first essential element in Control Theory is a mathematical model of the system of interest. One such model is the \textit{Input-Output Representation}, as shown in \textbf{fig!!!}, in which an input stimuli, a signal $u(t)$, acts on the system producing an output response, a signal $y(t)$, described by the following differential equation:
\begin{equation} \label{eq:01-01}
\begin{split}
    \alpha_n \cfrac{d^n y(t)}{dt^n} + \alpha_{n-1} & \cfrac{d^{n-1} y(t)}{dt^{n-1}} + \cdots + \alpha_{1} \cfrac{d y(t)}{dt} + \alpha_{0} y(t) = \\
    & \beta_m \cfrac{d^m u(t)}{dt^m} + \beta_{m-1} \cfrac{d^{m-1} u(t)}{dt^{m-1}} + \cdots + \beta_{1} \cfrac{d u(t)}{dt} + \beta_{0} u(t)
\end{split}
\end{equation}

[fig]

In this representation, the input $u(t)$ is called the \textit{manipulated variable}, since it represents a arbitrary stimuli that can be given directly by human action or a by an automatic controller, while the output $y(t)$ is called the \textit{controlled variable}, since it can only be modified indirectly through $u(t)$. This also leads to a \textit{cause-and-effect} interpretation of the system.

A model can provide a quantitative understanding of the system that is useful both to access some response specifications and to design controllers to modify them based on some requirements. In the case of the model in Equation \eqref{eq:01-01}, it is possible to calculate the response $y(t)$, and its derivatives, resulting from any specific action $u(t)$. Besides, a model can be used to perform computer simulations, in order to visualize the dynamical behavior of the system without actually manipulating it, since real experiments could be expensive or even damage the system. Consider, for instance, a schematic and a simulation for a model representing a mass-spring-damper system, shown at \textbf{!!!!}.

[fig]

In this simulation, the \textit{rise time}, \textit{peak time}, \textit{overshoot ratio} and \textit{steady-state value} are examples of response specifications that can be defined to describe the system behavior to a external stimuli (in this case, a constant force of unit magnitude). These specified parameters are characteristic to responses of a class of systems known as \textit{underdamped second-order systems}, that will be discussed further in the document. 

A controller is used to calculate, for a time $t \in \left[ t_0, t_N\right)$, the necessary input $u(t)$ to produce an output $y(t)$ as close as possible to a desired reference signal $r(t)$. There are two common configurations, shown in \textbf{Fig!!!}, of how to connect the controller to the system.

[fig]

The configuration in \textbf{Fig!!!.a}, known as \textit{Open-Loop Controller}, calculates the action as a function $u(t) = \pi(r, t)$, given an initial condition $y(t_0) = y_0$. In this case, the controller does not observe the output $y(t)$, and relies on the model to guarantee that the system is driven to the reference. Of course, if there are any external disturbances acting on this configuration, or if the model is not reliable enough, it is not possible to guarantee that the requirements are met. Thus, these type of controllers are not suitable for critical applications, and its use is restricted to systems where deviance from the desired reference can be tolerated. \textbf{[exemplos de aplicações?]}

In contrast, the configuration in \textbf{Fig!!!.b}, known as \textit{Closed-Loop Controller} or \textit{Feedback Controller}, calculates the action as a function $u(t) = \pi(e, t)$, where $e(t) = r(t) - y(t)$ is the error between the reference and the actual response. Now, the controller will observe the system output, trough some sensor device, and compares it to the desired reference in order to calculate a \textit{corrective action}. This feedback property can make the system reject disturbances while still driving it to the desired reference. Thus, the Feedback Controller became the most popular choice of controller configuration in industry for a wide range of applications, even for critical ones.  \textbf{[exemplos de aplicações? + references]}

\section{Chemical Reactive Systems}

A chemical reaction, the transformation of a chemical substance into another, is a process central to chemistry and to nature itself. A reaction equation is a intuitive representation of such transformations. For instance, consider the following equation representing a \textit{synthesis reaction}:
\begin{equation}
    A + 2 B \longrightarrow 3 C + D 
\end{equation} 

In this equation, the compounds $A$ and $2 B$ forms the set of \textit{reactants}, $\mathbb{R}$, while $3 C$ and $D$ forms the set of \textit{products}, $\mathcal{P}$. The coefficients in such equations are the \textit{stoichiometric numbers}, providing an information about proportionality between the quantity of each substances in the reaction. 

Usually the products can be directly used as reactants in another reaction, in which case they can also be referred as a intermediate product (or byproduct), and the equations can be appended in a ``series" representation. In this case, each $k$-th intermediate product forms a set $\mathcal{I}_k$. In addition to a chain of series reactions, there is also the possibility of different reactions to occur in parallel, in the same system. The combination of these sets of reactants, byproducts, products and reactions are often referred as a \textit{chemical reaction network}, and the associated equation can be represented in general form as:
\begin{equation} \label{eq:chemNetwork}
\left\{ \begin{matrix}
    \mathbb{R}^{(1)}  & \longrightarrow & \mathcal{I}^{(1)}_1  &  \longrightarrow & \cdots & \longrightarrow & \mathcal{I}^{(1)}_{M_1} & \longrightarrow & \mathcal{P}^{(1)} \\
    \mathbb{R}^{(2)} & \longrightarrow & \mathcal{I}^{(2)}_1  &  \longrightarrow & \cdots & \longrightarrow & \mathcal{I}^{(2)}_{M_2} & \longrightarrow & \mathcal{P}^{(2)} \\
    \vdots &  & \vdots &  & \vdots &  & \vdots &  & \vdots \\
    \mathbb{R}^{(N)} & \longrightarrow & \mathcal{I}^{(N)}_1  &  \longrightarrow & \cdots & \longrightarrow & \mathcal{I}^{(N)}_{M_N} & \longrightarrow & \mathcal{P}^{(N)} \\
\end{matrix} \right.
\end{equation} 

Moreover, chemical reactions displays a dynamical behavior concerning the speed at which a reaction occurs. This rate of reaction, its \textit{kinetics}, are dependent on the conditions in the environment, such as temperature and pressure, and on some properties of the reaction itself. In the case of a \textit{isothermal process}, i.e., when the temperature in the environment remains constant, this rate can be calculated as a constant $K$, leading to a representation on the form:
\begin{equation}
    \mathbb{R} \overset{K}{\longrightarrow} \mathcal{P}
\end{equation} 

When the temperature in the environment is not constant, the process is said to be \textit{endothermic} or \textit{exothermic} if, respectively, it consumes or produces energy. The kinetics of the reactions in such processes are usually functions of the temperature which, given an activation energy $E$, are assumed to follow the Arrhenius equation:
\begin{equation} \label{eq:arrhenius1}
    K(T) = K_0 e^{-E / T}
\end{equation}

In practice, these chemical reactions are produced by mixing the reactants in some environment with adequate conditions. In order to control the quantities of these substances, actual processes consists in a manipulation of the concentrations of reactants in some container, usually by providing a mass flow of these substances through some fluid. A major interest is to manipulate the reactants in some way to produce a desired concentration of one or more products in the chemical reaction network, allowing this problem to be addressed by a control engineering perspective. A \textit{chemical reactor system}, depicted in \textbf{Fig!!!}, is a system where a controller can manipulate the concentration of some reactants to produce a desired concentration of some products.

[img]

When the process is not isothermal, the occurrence of a reaction contributes to the entropy of the environment, and consequently affects the kinetics of the subsequent ones. To compensate for this, practical applications also try to control the conditions in the environment using instruments external to the reactions themselves. Because of the use of the Arrhenius equation to model these reaction rates, this control is usually implemented through a cooling or heating system coupled to the original reactor system, resulting in the schematic on \textbf{Fig!!!}.

[img]

\section{Motivation}

The use of automatic controllers to impose a desired behaviour to physical systems is a practice ubiquitous in many engineering fields. In the last years, the price of digital computers have been dropping while their performance have been growing. Consequently, digital controllers have became the central key in developments in important and innovative fields such as aeronautics \textbf{[reference]} and autonomous driving \textbf{[reference]}. In parallel, this theory is also useful to understand and bring inspiration from nature itself since, for instance, the mechanisms for temperature regulation observed in vertebrate animals behave as a feedback controller \cite{Heller:1978}.

Most recent developments in Control Theory focus on using Feedback Controllers to achieve \textit{Robust and Optimal Control}. This theory accounts for the design of controllers that deals with uncertainty, either from the model or from the observation of the system, and are able to achieve the control objectives in a \textit{optimal manner}. Despite being a few decades old, these fields have gained a lot of interest in the last years thanks to recent results in \textit{Machine Learning}, particularly in \textit{Reinforcement Learning}, that are having success in using optimization techniques for artificial agents to control themselves in environments loaded with uncertainty \textbf{[reference]}.

Furthermore, the specific application of controlling chemical reactor systems brings benefits from the fact that chemical reactions are present in most biological and industrial processes. In this sense, controllers can be used to guarantee safety constraints, maximize productivity and minimize the use of resources, in such way that is unfeasible without automatic and high performing machinery.

\section{Objectives}

This works aims to provide a self-contained discussion of modelling and control of chemical reactive systems in the perspective of modern control theory. Therefore, the results are focused on \textit{state feedback controllers} modelled in continuous and discrete time, but analysis in the frequency domain is also considered in order to explain some concepts. Several properties of these models, both in the open-loop and closed-loop regime, are summarized in the document and the intention is to have a generalized framework to understand, evaluate and design those systems. Finally, the theory of more advanced methods such as optimal estimation and optimal control is also developed in the same sense.

\section{Chapters Organization}

The chapters of this document are mainly organized in two parts. The first part, comprised by the chapters 2, 3 and 4, builds the necessary theoretical background and provides the mathematical framework for the applications. The second part, comprised by the chapters 5 and 6, describes the experiments and results of applying these methods in real-world applications.

Individually, the chapters are organized as follows: chapter 2 introduces the dynamical models and its several properties with respect to the real system behavior, chapter 3 discusses classical methods in developing automatic controllers and state observers, chapter 4 presents more advanced methods in optimal estimation and optimal control, chapter 5 describes the practical experiments used to validate the previous discussions, chapter 6 summarizes and discusses the results of the experiments and evaluate the several controllers performances and, finally, chapter 7 provides the conclusion of the document and possible future works.

% 2 - Dynamical System Modelling
% ---------------------------------------------------------------
\clearpage
\chapter{Dynamical System Analysis}

This chapter discusses the mathematical models for dynamical systems and their use in response analysis. The sections starts by introducing a procedure to build models from physical principles and presenting equivalent common representations. Next, the response of systems, in a time domain, are analyzed in the light of such models, relating the mathematical structure with the dynamical behavior. Finally, some important properties are defined and proved using these formulations and the system response in a frequency domain is also presented.

\section{Model from First Principles}

A dynamical system is a physical system whose states evolves with time. For this reason, one can represent a dynamical system using the \textit{first principles} from physics itself, and formulate the evolution in time by calculating the rate of change of the states in respect to time. Thus, dynamical models can be equated using differential equations with time derivatives. 

A straightforward procedure to model a system consists in identify the variables of interest and relate them using conservation laws, such as conservation of mass, conservation of energy or conservation of momentum. The resulting differential equations are in the form:
\begin{equation} \label{eq:massCons01}
	\begin{pmatrix}
		\text{Rate of} \\ \text{Accumulation}
	\end{pmatrix} = \begin{pmatrix}
		\text{Mass/Energy/Momentum} \\ \text{entering the System}
	\end{pmatrix} - \begin{pmatrix}
		\text{Mass/Energy/Momentum} \\ \text{leaving the System}
	\end{pmatrix}
\end{equation}

The choice of which conservation law to use depends on the system itself, since the variables of interest can provide dynamics to the system in many forms. Usually, conservation of mass is used to relate dynamics of concentrations and volumes, or other material variables, while conservation of momentum is often used to relate dynamics of motion. Since energy can be converted on form, the conservation laws of this quantity can be used to model several dynamics, such as the rate of change in heat, electrical charges or velocity of a system.

In the case of a chemical reactor system, the variables of interest are the concentrations of the chemical substances in the system. Hence, the rate of accumulation of a substance can be represented using the mass conservation law, or mass balance:
\begin{equation} \label{eq:massCons02}
\begin{split}
	\begin{pmatrix}
		\text{Accumulation} \\ \text{of mass} \\ \text{in the system}
	\end{pmatrix} &= 
	\begin{pmatrix}
		\text{Mass} \\ \text{entering} \\ \text{the System}
	\end{pmatrix} - \begin{pmatrix}
		\text{Mass} \\ \text{leaving} \\ \text{the System}
	\end{pmatrix} \\
	&= \left[ \begin{pmatrix}
		\text{Mass flow} \\ \text{entering} \\ \text{System}
	\end{pmatrix} + \begin{pmatrix}
		\text{Mass} \\  \text{produced} \\ \text{by reactions}
	\end{pmatrix} \right] - \left[ \begin{pmatrix}
		\text{Mass flow} \\ \text{leaving} \\ \text{System}
	\end{pmatrix} + \begin{pmatrix}
		\text{Mass} \\ \text{consumed} \\ \text{by reactions}
	\end{pmatrix} \right]
\end{split}
\end{equation}

\begin{boxed-theorem}{(Mass Balance of Reactors)} \label{th:isoReactSys01}
    Consider a closed isothermal reactor system comprised of a diluted solution of constant volume $V$, whose reactions are described by a chemical reaction network as in Definition \ref{eq:chemNetwork}. The change of mass for any compound $A$ in this reactor is described by the dynamical model:
    \begin{equation} \label{eq:isoModel1}
    		\cfrac{d (\rho_A)}{dt} = q (\rho^{(A)}_{in} - \rho^{(A)}_{out}) + \left( \sum_{\alpha X \rightarrow \beta A} \cfrac{1}{\beta} K_{XA} (\rho_X)^{\alpha} \right) - \left(\sum_{\alpha A \rightarrow \beta X} \cfrac{1}{\beta} K_{AX} (\rho_A)^{\alpha} \right)
    \end{equation}

    \noindent where $\rho^{(A)}_{in}$ and $\rho^{(A)}_{out}$ are the densities of $A$ in the flows entering and leaving the system, respectively, and where $\alpha X \rightarrow \beta A$ and $\alpha A \rightarrow \beta X$ represents the reactions in the network between $A$ and any other compound $X$ with density $\rho_X$, each occurring with kinetic rates $K_{XA}$ and $K_{AX}$, respectively.
\end{boxed-theorem}

\begin{proof}
    First of all, as denoted in \eqref{eq:massCons02}, the mass flow of any substance $A$ entering and leaving the system, $M_{in}$ and $M_{out}$, respectively, given a fluid inflow $F_{in}$ with density $\rho^{(A)}_{in}$ and a fluid outflow $F_{out}$ with $\rho^{(A)}_{out}$, can be calculated as:
    \begin{equation}
    	\begin{matrix}
    		M_{in} = \rho^{(A)}_{in} F_{in} & & M_{out} = \rho^{(A)}_{out} F_{out}
    	\end{matrix}
    \end{equation}
    
    To calculate the mass contribution from the reactions, it is necessarily first to formulate the mass contribution for a single reaction. In this case, consider a reaction between two chemical compounds $X$ and $Y$, with stoichiometric numbers $\alpha$ and $\beta$:
    \begin{equation} \label{eq:simpleEq01}
    	\alpha X \overset{K_{XY}}{\longrightarrow} \beta Y
    \end{equation}
    
    Under the assumption that the reactant is in a dilute solution, the rate of this equation obeys the \textit{law of mass action} \cite{Horn:1972}. Given a constant kinetic rate $K_{XY}$, since the system is isothermal, and the volume of the solution as $V$, the mass of $X$ consumed, $M^{(X)}_\text{cons}$, and the mass of $Y$ produced, $M^{(Y)}_\text{prod}$, are given by the power-laws:
    \begin{equation}
    	\begin{matrix}
    		M^{(X)}_\text{cons} = \cfrac{V}{\beta} K_{XY} (\rho_X)^{\alpha} & & M^{(Y)}_\text{prod} = \cfrac{V}{\alpha} K_{XY} (\rho_X)^{\alpha}
    	\end{matrix}
    \end{equation}
    
    \noindent where $\rho_X$ and $\rho_Y$ are the respective densities of these compounds. Assuming that the network represents a set of reactions occurring within an chemical solution of volume $V$, the mass of a substance $A$ that is consumed and produced by the reactions, named respectively $M_\text{cons}$ and $M_\text{prod}$, are given by summing over the contribution of each reaction on the network where $A$ is either a reactant or a product to any other compound $X$:
    \begin{equation}
    		M_\text{cons} = V \sum_{\alpha A \rightarrow \beta X} \cfrac{1}{\beta} K_{AX} (\rho_A)^{\alpha}\ \ \ \ \  M_\text{prod} = V \sum_{\alpha X \rightarrow \beta A} \cfrac{1}{\beta} K_{XA} (\rho_X)^{\alpha}
    \end{equation}
    
    Finally, packing all together, the mass balance of any substance $A$ in a isothermal chemical reactive system can be represented by the general dynamical model:
    \begin{equation}
    \begin{split}
        \begin{pmatrix}
		\text{Accumulation} \\ \text{of mass} \\ \text{in the system}
	\end{pmatrix} &= \left[ \begin{pmatrix}
		\text{Mass flow} \\ \text{entering} \\ \text{System}
	\end{pmatrix} + \begin{pmatrix}
		\text{Mass} \\  \text{produced} \\ \text{by reactions}
	\end{pmatrix} \right] - \left[ \begin{pmatrix}
		\text{Mass flow} \\ \text{leaving} \\ \text{System}
	\end{pmatrix} + \begin{pmatrix}
		\text{Mass} \\ \text{consumed} \\ \text{by reactions}
	\end{pmatrix} \right] \\
		\cfrac{d (\rho_A V)}{dt} &= \left[ \rho^{(A)}_{in} F_{in} + V \sum_{\alpha X \rightarrow \beta A} \cfrac{1}{\beta} K_{XA} (\rho_X)^{\alpha} \right] - \left[ \rho^{(A)}_{out} F_{out} + V \sum_{\alpha A \rightarrow \beta X} \cfrac{1}{\beta} K_{AX} (\rho_A)^{\alpha} \right]
    \end{split}
    \end{equation}
    
    Since the system is closed, i.e., there are no leaks or unknown sources of fluids, the assumptions of a constant volume implies that $F_{in} = F_{out} = F$. Normalizing each term by the volume and substituting a new variable $q = F/V$ results in:
    \begin{equation} \label{eq:isoModel3}
    		\cfrac{d (\rho_A)}{dt} = q (\rho^{(A)}_{in} - \rho^{(A)}_{out}) + \left( \sum_{\alpha X \rightarrow \beta A} \cfrac{1}{\beta} K_{XA} (\rho_X)^{\alpha} \right) - \left(\sum_{\alpha A \rightarrow \beta X} \cfrac{1}{\beta} K_{AX} (\rho_A)^{\alpha} \right)
    \end{equation}
\end{proof}

Notice some important restrictions to the use of the model just presented. First of all, to calculate the mass contribution of an individual reaction was necessary to use a model which assumes that the reactor system is actually comprised of a dilute solution in some closed container. In industry, this means that the reactor system is actually a tank containing the solution. The inflow and outflow of fluid can be represented by flows through pipes which can be manipulated by some valve or pump. An illustration of such physical system is exhibited at Fig. \ref{fig:tank01a}.

Furthermore, this model accounts for a single substance $A$, but the system is actually a solution of several compounds, each one with a specific concentration. From the model presented, it is visible that it is necessary to compute each concentration $\rho_X$ before actually computing the rate of change in $\rho_A$. However, from the same model, the computation of the rate of change of any $\rho_X$ may depend on $\rho_A$ itself. Therefore, the change of mass inside the whole system is actually the result of a system of differential equations:
\begin{align}	\label{eq:isoSys01}
\begin{cases}
	\hfill \cfrac{d (\rho_{X_1})}{dt} &= f(\rho_{X_1}, \rho_{X_2}, ..., \rho_{X_n}, \rho_{in}^{(X_1)}, \rho_{out}^{(X_1)}, t) \\
	\hfill \cfrac{d (\rho_{X_2})}{dt} &= f(\rho_{X_1}, \rho_{X_2}, ..., \rho_{X_n}, \rho_{in}^{(X_2)}, \rho_{out}^{(X_2)}, t) \\
	& \vdots   \\
	\hfill \cfrac{d (\rho_{X_n})}{dt} &= f(\rho_{X_1}, \rho_{X_2}, ..., \rho_{X_n}, \rho_{in}^{(X_n)}, \rho_{out}^{(X_n)}, t)
\end{cases}
\end{align}

\noindent where $X_1, X_2, ..., X_n$ are the chemical compounds inside the reactor and $f(.)$ is the dynamical model presented in Theorem \ref{th:isoReactSys01}.

\begin{figure}[ht] 
	\centering
	\begin{subfigure}{0.49\textwidth}	
		\includegraphics[width=\textwidth]{chapter2/tank01}
		\caption{$\ \ \ \ \ $}	\label{fig:tank01a}
	\end{subfigure}
	\begin{subfigure}{0.49\textwidth}	
		\includegraphics[width=\textwidth]{chapter2/tank02}
		\caption{$\ \ \ \ \ $} \label{fig:tank01b}
	\end{subfigure}
	
	\caption{schematic representations of industrial reactor tanks for (a) a simple isothermal process and (b) a non-isothermal process with heating/cooling system.} 
	\label{fig:tank01}
\end{figure}

The model discussed so far is very simple and can describe several applications. To account for more complex systems, the same modeling procedure can be applied. For instance, it is possible to extend the description to account for exothermic and endothermic processes, when the temperature inside the system has a dynamical evolution and the dynamics of the reactions starts to depend on it.

When discussing non-isothermal processes, it is also common to discuss heating or cooling systems that tries to impose certain operational conditions to the reactions, as illustrated in Fig. \ref{fig:tank01b}. In exothermic processes, for instance, the heat accumulated in the system tends to grows as the reactions occurs, which can be very dangerous. One approach to regulate the temperature consists in involving the chemical solution, or the container containing it, with a material whose temperature can be manipulated, transferring or absorbing heat by conductance. The temperature of this material can be manipulated by, for instance, running a heated fluid or converting electrical energy to heat energy.

\begin{boxed-theorem}{(Non-isothermal Reactor System)} \label{th:exoReactSys01}
    Consider a closed non-isothermal reactor system comprised of a diluted solution of constant volume $V$. Assume, also, that the system is involved by a cooling/heating system with capacity $Q$ and that the reactions obeys the Arrhenius equation. The change of mass for any compound $A$ in this reactor is described by the dynamical model:
    \begin{equation} \label{eq:exoModel1}
    		\cfrac{d (\rho_A)}{dt} = q (\rho^{(A)}_{in} - \rho^{(A)}_{out}) + \left( \sum_{\alpha X \rightarrow \beta A} \cfrac{1}{\beta} K_{XA} e^{-\frac{E_{XA}}{T}} (\rho_X)^{\alpha} \right) - \left(\sum_{\alpha A \rightarrow \beta X} \cfrac{1}{\beta} K_{AX} e^{-\frac{E_{AX}}{T}} (\rho_A)^{\alpha} \right)
    \end{equation}

    \noindent where $E_{XA}$ and $E_{AX}$ are the activation energy needed for each reaction, and the rest of the parameters are the same as defined in Theorem \ref{th:isoReactSys01}. Furthermore, the change of temperature inside the reactor system, $T$, and in the cooling/heating system, $T_C$, are described by the dynamical models:
    \begin{align} \label{eq:exoModel2}
    \begin{split}
        \cfrac{d(T)}{dt} &= q(T_{in} - T_{out}) + \eta (T_C - T) + \delta \sum_{\alpha A \rightarrow \beta X} K_{AX} e^{-\frac{E_{AX}}{T}} (\rho_A)^{\alpha} \Delta H_{AX} \\
        \cfrac{d(T_C)}{dt} &= \gamma Q + \beta (T - T_C) 
    \end{split}
    \end{align}
    
    \noindent where $T_{in}$ and $T_{out}$ are the temperatures of the fluid inflow and outflow, respectively, $\Delta H_{AX}$ is the energy change from each reaction $\alpha A \rightarrow \beta X$ and $\eta, \delta, \gamma, \beta \in \mathbb{R}$ are proportionality parameters specific to the system and environmental conditions.
\end{boxed-theorem}

A proof of this theorem can be found in Appendix A. The non-isothermal reactor system is a more general model that accounts for the fact that the temperature of the environment is usually not constant. From this assumption, the flow entering and leaving the system are also not assumed to have the same temperature that the fluid inside the reactor. In practical applications, the temperature of the fluid inflow can either be manipulated or measured, where the temperature of the fluid outflow is actually assumed to be equal to the temperature inside the reactor. In addition, the proportionality constants are not functions of any dynamical variable, so they can be calculated before the operation of the system by using the properties of the materials and containers.

In the case of this model, the rate of changes in the chemical concentrations depends on the temperature through the Arrhenius equation. However, the temperature of the reactor itself depends on those concentrations. So, as noted in Equation \eqref{eq:isoSys01}, the dynamical model of the entire reactor is a system of differential equations relating all those quantities.


\section{Mathematical Models of Systems}

The last section presented the foundation for modeling a dynamical system using first principles from physics. Although it was a well-defined formulation, the resulting models are not guaranteed to be practical in a mathematical sense. This is to due to the fact that the differential equations, as evidenced in Equation \eqref{eq:exoModel1}, are usually nonlinear functions of the variables of interest, and the analysis of such functions are quite more challenging. 

In the perspective of control theory, that are two main formats for the model of a system: the \textit{Input-Output} (IO) and the \textit{State-Space} (SS) representations, both depicted in Fig. \ref{fig:model1}. 

\begin{figure}[ht] 
	\centering
	\begin{subfigure}{0.49\textwidth}
		\centering	
		\includegraphics[scale=0.7]{chapter2/model01}
		\caption{}	\label{fig:model01a}
	\end{subfigure}
	\begin{subfigure}{0.49\textwidth}	
	\centering
		\includegraphics[scale=0.7]{chapter2/model02}
		\caption{} \label{fig:model01b}
	\end{subfigure}
	
	\caption{graphical interpretation of (a) Input-Output models and (b) State-Spaces models.} 
	\label{fig:model1}
\end{figure}

\begin{boxed-definition}{(Input-Output Representation)} \label{def:IORepr01}
	An Input-Output (IO) representation of a dynamical system with $p \geq 1$ output variables, represented by $\bm{y}(t) : \mathbb{R} \rightarrow \mathbb{R}^{p}$, and $r \geq 1$ input variables, represented by $\bm{u}(t) : \mathbb{R} \rightarrow \mathbb{R}^{r}$, is the system of differential equations:
	\begin{equation} \label{eq:IERepr01}
	\begin{cases}
		h_1 \left( y_1, \dot{y_1}, ..., y_1^{(n_1)}, u_1, \dot{u}_1, ..., u^{(m_{11})}_1, u_2, \dot{u}_2, ..., u^{(m_{12})}_2, ..., u_r, \dot{u}_r, ..., u^{(m_{1r})}_r, t   \right) = 0 & \\
		h_2 \left( y_2, \dot{y_2}, ..., y_2^{(n_2)}, u_1, \dot{u}_1, ..., u^{(m_{21})}_1, u_2, \dot{u}_2, ..., u^{(m_{22})}_2, ..., u_r, \dot{u}_r, ..., u^{(m_{2r})}_r, t   \right) = 0 & \\
		 \vdots \hfill & \\
		h_p \left( y_p, \dot{y_p}, ..., y_p^{(n_p)}, u_1, \dot{u}_1, ..., u^{(m_{p1})}_1, u_2, \dot{u}_2, ..., u^{(m_{p2})}_2, ..., u_r, \dot{u}_r, ..., u^{(m_{pr})}_r, t   \right) = 0 &
	\end{cases}
	\end{equation}
	
	\noindent where:
	\begin{equation*}
	\begin{matrix}
		\dot{y}(t) = \cfrac{d y(t)}{dt}, & \ddot{y}(t) = \cfrac{d^2 y(t)}{dt^2}, & \cdots, & y^{(n)}(t) = \cfrac{d^n y(t)}{dt^n} \\ \\
		\dot{u}(t) = \cfrac{d u(t)}{dt}, & \ddot{u}(t) = \cfrac{d^2 u(t)}{dt^2}, & \cdots, & u^{(n)}(t) = \cfrac{d^n u(t)}{dt^n}	
	\end{matrix}
	\end{equation*}
\end{boxed-definition}

An input-output representation is a simple model that describes the entire system using only two types of variables, and their derivatives. Therefore, the dimension of these variables and the order of derivatives at each differential equation provides the information about the structure of the model. For instance, in the case where $p = r = 1$ the system can be classified as a \textit{Single-Input Single-Output} (SISO) configuration, whereas it is classified as a \textit{Multiple-Input Multiple-Output} (MIMO) configuration if $p,r > 1$. 

This model presents a cause-and-effect interpretation of the system where the direct relationship between the input and output signal, and its derivatives, are equated as if the system was a processing unit. In practice, the input signals $\bm{u}(t)$ are the manipulated variables of the system, where the output signals $\bm{y}(t)$ are the observations of the controlled variables. This representation brings an easy visualization on how a desired system behavior can be achieved by applying a specific input signal, posing as a practical framework for designing controllers. 

\begin{boxed-definition}{(State-Space Representation)} \label{th:SSRepr01}
	A State-Space (SS) representation of a system with $n \geq 1$ states variables, represented by $\bm{x}(t) : \mathbb{R} \rightarrow \mathbb{R}^{n}$, for $p \geq 1$ output variables, represented by $\bm{y}(t) : \mathbb{R} \rightarrow \mathbb{R}^{p}$, and $r \geq 1$ input variables, represented by $\bm{u}(t) : \mathbb{R} \rightarrow \mathbb{R}^{r}$, is given by the systems of state and output equations:
	\begin{align} \label{eq:SSRepr01}
	\begin{split}
	\textbf{State Equations:}\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  \hfill & \textbf{ Output Equations:} \hfill \\
	\begin{cases}
		\dot{x}_1(t) = f_1(x_1, ..., x_n, u_1, ..., u_r, t) \\
		\dot{x}_2(t) = f_2(x_1, ..., x_n, u_1, ..., u_r, t) \\
		\vdots \\
		\dot{x}_n(t) = f_n(x_1, ..., x_n, u_1, ..., u_r, t)
	\end{cases} \hfill & \begin{cases}
		y_1(t) = g_1(x_1, ..., x_n, u_1, ..., u_r, t) \\
		y_2(t) = g_2(x_1, ..., x_n, u_1, ..., u_r, t) \\
		\vdots \\
		y_p(t) = g_p(x_1, ..., x_n, u_1, ..., u_r, t) \hfill
	\end{cases}
	\end{split}
	\end{align}
	
	\noindent or, in the matrix form:
	\begin{align} \label{eq:SSRepr02}
	\begin{cases}
		\dot{\bm{x}}(t) = \bm{f}(\bm{x}(t), \bm{u}(t), t) \\
		\bm{y}(t) = \bm{g}(\bm{x}(t), \bm{u}(t), t)
	\end{cases}
	\end{align}
\end{boxed-definition}

The State-Space representation is yet another formulation for a dynamical model, but centered in the concept of \textit{state variables}. In a formal definition, the set of state variables is the smallest set of linearly independent variables that can unequivocally determine the value of all the states variables given an initial state $\bm{x}(t_0)$ and a forcing function $\bm{u}(t)$, for any time $t \geq t_0$. In a physical perspective, however, these variables accounts for quantities that can describe the dynamics of the system, such as position or velocities, or they are latent variables that somehow stores intrinsic information about the system behavior. In comparison to the Input-Output representation, this formulation poses a simpler mathematical model, since it is composed by a system of ordinary differential equations and a system of algebraic equations. However, this model presents a semantical improvement over the latter since the inclusion of the state variables expands the internal description of the system. 

In the light of these two formulations, a system can be classified in respect to the model mathematical structure. There are five main properties used for this classification: if the system is causal or non-causal, linear or nonlinear, dynamical or instantaneous, time-invariant or time-varying and with or without delay. The necessary and sufficient conditions for each one of these properties are summarized in Table \ref{table:classes01}.

\begin{table}[!ht]
	\centering
	\begin{tabular}{r | c | c }
	 & \textbf{Input-Output} & \textbf{State-Space} \\
	\hline 
		\textbf{Causal}			& \makecell{$m_{ij} \leq n_k$\\$i \in [1,..., p],\ j \in [1,...,r]$} & Always causal \\
	\hline 
		\textbf{Linear}			& \makecell{$h_i(.) = \sum_{j=0}^{n_i} y^{(j)} + ... \ \ \ \ \ \ \ \ $\\$ \ \ \ \ \ \ \ \ \ \ \ \ ... + \sum_{k=1}^{r} \sum_{l=0}^{m_{ik}} u_k^{(l)}$\\$i \in [1,2,...,p]$} & \makecell{$f_i = \bm{a}_i(t) \bm{x}(t) + \bm{b}_i(t) \bm{u}(t), i = 1,2,...,n$ \\ $g_j = \bm{c}_j(t) \bm{x}(t) + \bm{d}_j(t) \bm{u}(t), j = 1,2,...,p$ \\ $\bm{a}_i,\bm{c}_j \in \mathbb{R}^{1 \times n}$ and $\bm{b}_i, \bm{d}_j \in \mathbb{R}^{1 \times r}$} \\
	\hline 
		\textbf{Dynamical}		& \makecell{$n_i > 0$ or $m_{jk} > 0$\\$i, j \in [1,...,p],\ k \in [1,...,r]$} & $n > 0$ \\
	\hline 
		\textbf{Time-Invariant}	& \makecell{$h_i(y_i(t),...,u_1(t),...,u_r(t)) = 0$\\$i \in  [1,2,...,p]$} & \makecell{$\dot{\bm{x}}(t) = \bm{f}(\bm{x}(t), \bm{u}(t))$ \\ $\bm{y}(t) = \bm{g}(\bm{x}(t), \bm{u}(t))$} \\
	\hline 
		\textbf{Without-Delay}	& \makecell{All the signals share\\the same arguments} & \makecell{All the signals share\\the same arguments} \\
	\end{tabular} 
	\caption{necessary and sufficient conditions for different classes of models.}
	\label{table:classes01}	
\end{table} 

This work focus on dynamical linear systems, since its models are the most well studied in the control theory community. In reality, a physical system is always causal, nonlinear and time-varying \cite{Vidyasagar:2002}, but the models can be assumed differently with fairly accuracy. The benefit of linear systems is that it obeys the superposition principle, and a linear combination of the inputs directly causes the exact same linear combination of the individual outputs. Under the assumption of a linear system, a nice result is that the vectorial functions $\bm{f}(.)$ and $\bm{g}(.)$ of the State-Space representation in \eqref{eq:SSRepr03} reduces to simple matrix forms.

\begin{boxed-definition}{(Linear State-Space Representation)}
	A State-Space representation describing a linear system with state vector $\bm{x}(t) : \mathbb{R} \rightarrow \mathbb{R}^{n}$, output vector $\bm{y}(t) : \mathbb{R} \rightarrow \mathbb{R}^{p}$ and input vector $\bm{u}(t) : \mathbb{R} \rightarrow \mathbb{R}^{r}$ is given by the system of equations: 
	\begin{align} \label{eq:SSRepr04}
	\begin{cases}
		\dot{\bm{x}}(t) = \bm{A}(t) \bm{x}(t) + \bm{B}(t) \bm{u}(t) & \\
		\bm{y}(t) = \bm{C}(t) \bm{x}(t) + \bm{D}(t) \bm{u}(t) &
	\end{cases}
	\end{align}

	\noindent where $\bm{A}(t) : \mathbb{R} \rightarrow \mathbb{R}^{n \times n}$, $\bm{B}(t) : \mathbb{R} \rightarrow \mathbb{R}^{n \times r}$, $\bm{C}(t) : \mathbb{R} \rightarrow \mathbb{R}^{p \times n}$ and $\bm{D}(t) : \mathbb{R} \rightarrow \mathbb{R}^{p \times r}$. In the case of a time-invariant linear system, these matrices becomes constants. 
\end{boxed-definition}

This formulation has the advantages that the time response of the system can be easily calculated and that the analysis of the dynamics follows well-established results from linear algebra applied to the matrices $\bm{A}(t)$, $\bm{B}(t)$, $\bm{C}(t)$ or $\bm{D}(t)$, as well as for the vectors $\bm{x}(t)$ and $\bm{u}(t)$. Furthermore, the physical interpretation of the system through the state variables becomes straightforward in this model, even in the case of latent variables. 

In addition to the State-Space representation, the linear assumption also benefits Input-Output representations. One major analytical tool that can be used in these cases is to transform this model to a frequency domain, using a linear transform operator, in order to simplify the solution for the differential equations. The most popular choice of transformation is the \textit{Laplace transform}, $\mathcal{L}\{ h(t) \}$, which converts functions in time to functions in complex frequencies. Using the properties of this operator, differential equations are converted to simple algebraic equations.

\begin{boxed-theorem}{(Transfer Function)} \label{th:transFun01}
	Given a linear model for a SISO system, with initial conditions $\bm{y}(0^-) \equiv \bm{u}(0^-) \equiv 0$, in the Input-Output formulation:
	\begin{equation}
	\begin{split}
		\alpha_n \cfrac{d^n y(t)}{dt^n} + \cdots + \alpha_{1} \cfrac{d y(t)}{dt} + \alpha_{0} y(t) &= \beta_m \cfrac{d^m u(t)}{dt^m} + \cdots + \beta_{1} \cfrac{d u(t)}{dt} + \beta_{0} u(t)
	\end{split}
	\end{equation}
	
	\noindent Its transfer function, in the Laplace domain, is calculated as:
	\begin{equation} \label{eq:transFun01}
		 G(s) = \cfrac{Y(s)}{U(s)} = \cfrac{\beta_m s^m + \beta_{m-1} s^{m-1} + \cdots + \beta_{1} s + \beta_0}{\alpha_n s^n + \alpha_{n-1} s^{n-1} + \cdots + \alpha_{1} s + \alpha_0}
	\end{equation}
\end{boxed-theorem}

An indirect result of this is that the SS representation can be converted to the IO representation using the Laplace transform operator, leading to a notion of equivalence between the two representations. Notice that the extension to the MIMO case is straightforward: just compute the transfer function between each pair of input and output, leading to the matrix $\bm{G} \in \mathbb{C}^{n \times m}$.

\begin{boxed-theorem}{(Passage from SS to IO)} \label{th:SSToIO}
	Consider a linear and time-invariant system in State-Space form with initial states $\bm{x}(0^-) \equiv 0$ and represented as:
	\begin{align}
	\begin{cases}
		\dot{\bm{x}}(t) = \bm{A} \bm{x}(t) + \bm{u}(t) \\
		\bm{y}(t) = \bm{C} \bm{x}(t) + \bm{D}(t) \\
	\end{cases}		
	\end{align}
	
\noindent The equivalent system in Input-Output representation is given by the transfer function:
	\begin{align}
	\bm{G}(s) = \bm{Y}(s)\bm{U}^{-1}(s) = \bm{C} (s\bm{I} - \bm{A})^{-1} \bm{B} + \bm{D}
	\end{align}
\end{boxed-theorem}
 
\begin{proof}
	Applying the Laplace transfer in both sides of the equation:
	\begin{equation} \label{eq:convertSSIO01}
	\begin{split}
		\mathcal{L} \left\{ \dot{\bm{x}}(t) \right\} &= \bm{A} \mathcal{L} \left\{ \bm{x}(t) \right\} + \bm{B} \mathcal{L} \left\{ u(t) \right\} \\
		s \bm{X}(s) - \dot{\bm{x}}(0^-) &= \bm{A} \bm{X}(s) + \bm{B} \bm{U}(s) \\
		(s\bm{I}  - \bm{A}) \bm{X}(s) &=  \bm{B} \bm{U}(s) \\
		 \bm{X}(s) &= (s\bm{I}  - \bm{A})^{-1} \bm{B} \bm{U}(s)
	\end{split}
	\end{equation}
	
	By applying the same procedure in the output equations, using the previous result, the Laplace transform of the output is:
	\begin{equation} \label{eq:convertSSIO02}
	\begin{split}
		\mathcal{L} \left\{ \bm{y}(t) \right\} &= \bm{C} \mathcal{L} \left\{ \bm{y}(t) \right\} + \bm{D} \mathcal{L} \left\{ u(t) \right\} \\
		\bm{Y}(s)  &= \bm{C} \bm{X}(s) + \bm{D} \bm{U}(s) \\
		\bm{Y}(s)  &= \bm{C} \left( (s\bm{I}  - \bm{A})^{-1} \bm{B} \bm{U}(s) \right) + \bm{D} \bm{U}(s) \\
		\bm{Y}(s)  &= \left( \bm{C} (s\bm{I} - \bm{A})^{-1} \bm{B}   + \bm{D} \right) \bm{U}(s) \\
	\end{split}
	\end{equation}
	
	In conclusion, it is possible to obtain the transfer function matrix $\bm{G}(s) = \bm{Y}(s)\bm{U}^{-1}(s) = \bm{C} (s\bm{I} - \bm{A})^{-1} \bm{B}   + \bm{D}$ as an equivalent representation of the same system.
\end{proof}

Despite of the discussion about the benefits of linear models, it is necessary to account for the fact that physical systems will present, in most situations, nonlinear behavior. For this reason, some effort must be done to develop a linear model that can describe the nonlinear behavior with certain accuracy, even if over some small region of the space. With this motivation, a technique for \textit{linearization} of a nonlinear model is detailed below.

\begin{boxed-theorem}{(Linearization by Taylor Expansion)} \label{th:linearization}
	Consider a nonlinear time-invariant system:
	\begin{equation} \label{eq:SSRepr03}
	\begin{cases}
		\dot{\bm{x}}(t) = \bm{f}(\bm{x}(t), \bm{u}(t)) \\
		\bm{y}(t) = \bm{g}(\bm{x}(t), \bm{u}(t))
	\end{cases}
	\end{equation}
	
\noindent Given steady-state operating points $\bm{x}_o$, $\bm{y}_o$ and $\bm{u}_o$, the dynamics of the system in the neighborhood of these points can be represented by the linear model: 
	\begin{align}
	\begin{cases}
		\Delta \bm{\dot{x}}(t) = \bm{A}\Delta \bm{x}(t) + \bm{B}\Delta \bm{u}(t) & \\
		\hfill \bm{y}(t) = \bm{C}\Delta \bm{x}(t) + \bm{D}\Delta \bm{u}(t) &
	\end{cases}
	\end{align}
	
	\noindent where
	\begin{equation}
	\begin{matrix}
		\bm{A} = \left. \cfrac{\partial \bm{f}}{\partial \bm{x}} \right|_{\bm{x}_o, \bm{y}_o, \bm{u}_o} & \bm{B} = \left. \cfrac{\partial \bm{f}}{\partial \bm{u}} \right|_{\bm{x}_o, \bm{y}_o, \bm{u}_o} & \bm{C} = \left. \cfrac{\partial \bm{g}}{\partial \bm{x}} \right|_{\bm{x}_o, \bm{y}_o, \bm{u}_o} & \bm{D} = \left. \cfrac{\partial \bm{g}}{\partial \bm{u}} \right|_{\bm{x}_o, \bm{y}_o, \bm{u}_o} 
	\end{matrix}
	\end{equation}
	
	\noindent and
	\begin{equation}
	\begin{matrix}
		\Delta \bm{x}(t) = \bm{x}(t) - \bm{x}_o & & \Delta \bm{y}(t) = \bm{y}(t) - \bm{y}_o & & \Delta \bm{u}(t) = \bm{u}(t) - \bm{u}_o
	\end{matrix}
	\end{equation}
\end{boxed-theorem}

\begin{proof}
	Consider a system represented by state equations $\bm{f}(.)$ and output equations $\bm{g}(.)$, with steady-state operation points $\bm{x}_o$, $\bm{y}_o$ and $\bm{u}_o$. Now, consider a very small perturbation $\Delta u(t)$ in the input signal around these operation points. This perturbation will result in small changes in the state and output variables:
	\begin{align}
	\begin{matrix}
		\bm{x}(t) = \bm{x}_o + \Delta \bm{x}(t) & &
		\bm{u}(t) = \bm{u}_o + \Delta \bm{u}(t) & &
		\bm{y}(t) = \bm{y}_o + \Delta \bm{y}(t)
	\end{matrix}
	\end{align}
	
	This results in the following configuration on the State-Space:
	\begin{align}
	\begin{cases}
		\cfrac{d(\bm{x}_o + \Delta \bm{x}(t))}{dt} &= \bm{f}(\bm{x}_o + \Delta \bm{x}(t), \bm{u}_o + \Delta \bm{u}(t) ) \\
		\bm{y}_o + \Delta \bm{y}(t) &= \bm{g}(\bm{x}_o + \Delta \bm{x}(t), \bm{u}_o + \Delta \bm{u}(t) ) \\
	\end{cases}
	\end{align}
	
	\noindent where $d(\bm{x}_o + \Delta \bm{x}(t)) / dt = d(\Delta \bm{x}(t)) / dt$, since $\bm{x}_o$ is constant. The perturbed variables are very close to the operation points, hence the functions $f(.)$ and $g(.)$ can be approximated by a Taylor series expansion, yielding:
	\begin{align}
	\begin{cases}
		\hfill \cfrac{d(\Delta \bm{x}(t))}{dt} &= \bm{f}(\bm{x}_o, \bm{u}_o) + \left. \cfrac{\partial \bm{f}}{\partial \bm{x}}\right\vert_{\bm{x}_o, \bm{y}_o, \bm{u}_o} \Delta \bm{x}(t) + \left. \cfrac{\partial \bm{f}}{\partial \bm{u}}\right\vert_{\bm{x}_o, \bm{y}_o, \bm{u}_o}  \Delta \bm{u}(t) + \text{high order terms} \\ \\
		\bm{y}_o + \Delta \bm{y}(t) &= \bm{g}(\bm{x}_o, \bm{u}_o) + \left. \cfrac{\partial \bm{g}}{\partial \bm{x}}\right\vert_{\bm{x}_o, \bm{y}_o, \bm{u}_o} \Delta \bm{x}(t) + \left. \cfrac{\partial \bm{g}}{\partial \bm{u}}\right\vert_{\bm{x}_o, \bm{y}_o, \bm{u}_o}  \Delta \bm{u}(t) + \text{high order terms} \\
	\end{cases}
	\end{align}
	
	Since the steady-state condition implies zero variation, it is possible to assume $f(\bm{x}_o, \bm{u}_o) = 0$ and $g(\bm{x}_o, \bm{u}_o) = 0$, since they are ordinary differential equations. Truncating in the first order terms and substituting $\Delta \bm{x}(t) = \bm{x}(t) - \bm{x}_o$, $\Delta \bm{u}(t) = \bm{u}(t) - \bm{u}_o$ and $\Delta \bm{y}(t) = \bm{y}(t) - \bm{y}_o$ results in:
	\begin{align}
	\begin{cases}
		\cfrac{d(\Delta \bm{x}(t))}{dt} =\left. \cfrac{\partial \bm{f}}{\partial \bm{x}}\right\vert_{\bm{x}_o, \bm{y}_o, \bm{u}_o} (\bm{x}(t) - \bm{x}_o) + \left. \cfrac{\partial \bm{f}}{\partial \bm{u}}\right\vert_{\bm{x}_o, \bm{y}_o, \bm{u}_o}  (\bm{u}(t) - \bm{u}_o) \\ \\
		\hfill \bm{y}(t) = \left. \cfrac{\partial \bm{g}}{\partial \bm{x}}\right\vert_{\bm{x}_o, \bm{y}_o, \bm{u}_o} (\bm{x}(t) - \bm{x}_o) + \left. \cfrac{\partial \bm{g}}{\partial \bm{u}}\right\vert_{\bm{x}_o, \bm{y}_o, \bm{u}_o}  (\bm{u}(t) - \bm{u}_o) \\
	\end{cases}
	\end{align}
	
	Finally, since all the Jacobians involved are actually matrices of appropriate dimensions, the final linear approximation of the system is the SS model given by:
	\begin{align}
	\begin{cases}
		\Delta \bm{\dot{x}}(t) = \bm{A}\Delta \bm{x}(t) + \bm{B}\Delta \bm{u}(t) & \\
		\hfill \bm{y}(t) = \bm{C}\Delta \bm{x}(t) + \bm{D}\Delta \bm{u}(t) &
	\end{cases}
	\end{align}
\end{proof}

Note that this method can be used to convert non-linear models obtained from the first-principle procedure to a desirable State-Space form, since those models are usually in the non-linear State-Space representation. Consider for instance, a reactor system describing an isothermal process that follows the Van de Vusse reaction scheme \cite{VanDeVusse:1964}:
\begin{align}
\begin{matrix}
	\textbf{Reaction Scheme:}  & & \textbf{Flow parameters:} \\ 
	A\overset{K_{AB}}{\rightarrow} B \overset{K_{BC}}{\rightarrow} C & & \rho_{in}^{(B)}(t) = \rho_{in}^{(C)}(t) = \rho_{in}^{(D)}(t) = 0 \\
	2 A \overset{K_{AD}}{\rightarrow} D & &  \rho_{out}^{(k)}(t) = \rho_k(t),\ k \in \{A, B, C, D\}
\end{matrix}	
\end{align}

Consider $\bm{x} = [\rho_A, \rho_B, \rho_C, \rho_D]^T$ and $u = q$, and consider also that the states are perfectly observed, so that $\bm{y} = \bm{x}$. Using Theorem \ref{th:isoReactSys01},  the state-equation for the nonlinear State-Space representation of this reactor is:
\begin{align}
\begin{cases}
	\dot{x_1}(t) = u(t) (\rho_{in}^{(A)} - x_1(t)) - (K_{AB} x_1(t) + K_{AD} (x_1(t))^2)\\
	\dot{x_2}(t) = -u(t) x_2(t) + K_{AB} x_1(t) - K_{BC} x_2(t) \\
	\dot{x_3}(t) = -u(t) x_3(t) + K_{BC} x_2(t) \\
	\dot{x_4}(t) = -u(t) x_4(t) + \cfrac{1}{2} K_{AD} (x_1(t))^2
\end{cases}
\end{align}

 To select steady-state operation points $\bm{x}_o$ and $\bm{u}_o$, it is necessary to find values for $\bm{x}(t)$ and $u(t)$ that satisfies the system $\dot{\bm{x}}(t) = \bm{0}$. This can be done by analytical formulas, in some cases, by numerical methods or by simply simulating the nonlinear system and measuring these quantities when the states displays zero variation. Finally, the linear matrices $(\bm{A}, \bm{B}, \bm{C}, \bm{D})$ are obtained by deriving each one of these equations in respect to each state and input, resulting:
\begin{align}	\label{eq:isoReact01}
\begin{matrix}
	\bm{A} = \begin{bmatrix}
		-u_o - K_{AB} - 2K_{AC} x_{1o} & 0 & 0 & 0 \\ K_{AB} & -u_o - K_{BC} & 0 & 0 \\ 0 & K_{BC} & -u_o & 0 \\ K_{AD} x_{1o} & 0 & 0 & -u_o
	\end{bmatrix} \hfill & &
	\bm{B} = \begin{bmatrix}
		\rho_{in}^{(A)}-x_{1o} \\ -x_{2o} \\ -x_{3o} \\ -x_{4o} 
	\end{bmatrix} \hfill \\  \\ 
	\bm{C} = \begin{bmatrix}
		1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \\ 0 & 0 & 1 & 0 \\ 0 & 0 & 0 & 1
	\end{bmatrix} \hfill & &
	\bm{D} = \begin{bmatrix}
		0 \\ 0 \\ 0 \\ 0
	\end{bmatrix} \hfill
\end{matrix}
\end{align}

Notice that the response of this model represents the deviations around the given operation points. If the errors in approximating the non-linearities of the actual system are somehow tolerable, this model can still be used as a nominal model to represent all the operations, given that the response is vertically ``correted" as $\bm{x}(t) = \Delta \bm{x}(t) + \bm{x}_o$ (and for initial states $\Delta \bm{x}_0 = \bm{x}(t_0) - \bm{x}_o$ and input signal $\Delta \bm{u}(t) = \bm{u}(t) - \bm{u}_o$). The simulation of both the nonlinear and the linear systems are displayed in Fig. \ref{fig:linResp01}, with the dashed line the linear response of a system given $\bm{x}_o = [6.19, 1.09, 0.60, 1.05]^T$ and $u_0 = 3.03$.

\begin{figure}[ht]
	\centering
	\includegraphics[width=\textwidth]{chapter2/linResp01}
	\caption{comparison between the nonlinear and linear response of the reactor system.}
	\label{fig:linResp01}
\end{figure}

\section{Time Response Analysis}

Once that a model is well-established, it is possible both to simulate the system and to analyze its response, both for a natural or forced regime. This section, then, focus on developing a quantitative understanding of a system behavior through a linear model. The results are focused on continuous-time response of linear and time-invariant (LTI) systems in the form:
\begin{align}
\begin{cases}
	\bm{\dot{x}}(t) = \bm{A} \bm{x}(t) + \bm{B} \bm{u}(t) \\
	\bm{y}(t) = \bm{C} \bm{x}(t) + \bm{D} \bm{u}(t)
\end{cases}
\end{align}

First of all, it is necessary to access some properties of the matrix $\bm{A}$, which describes the natural evolution of the states. 

\begin{boxed-definition}{(State-Transition Matrix)} \label{def:stateTransM}
	Consider a system in State-Space representation with matrix $\bm{A} \in \mathbb{R}^{n \times n}$. Its \textit{State-Transition Matrix}, $e^{\bm{A} t} \in \mathbb{R}^{n \times n}$ , is the converging series:
\begin{equation}
	e^{\bm{A} t} = \bm{I} + \bm{At} + \cfrac{\bm{A}^2 t^2}{2!} + \cfrac{\bm{A}^3 t^3}{3!} + \cdots = \sum_{k=0}^{\infty} \cfrac{A^k t^k}{k!}
\end{equation} 
\end{boxed-definition}

This matrix is central to the computation of the system time response, as it will be shown shortly. Since the matrix $A$ is a square matrix, this operation leads to some useful properties.

\begin{boxed-theorem}{} \label{th:stateTransMProp}
	Consider a matrix exponential as in Definition \ref{def:stateTransM}, for a matrix $\bm{A}  \in \mathbb{R}^{n \times n}$. Then, the following properties holds:
\begin{align}
		1)\ \cfrac{d ( e^{\bm{A} t} )}{dt} = \bm{A} e^{\bm{A} t} & &
		2)\ e^{\bm{A} t} e^{\bm{A} \tau} = e^{\bm{A} (t + \tau)} & &
		3)\ e^{-\bm{A} t} e^{\bm{A} t} = e^{\bm{A} t} e^{-\bm{A} t} = \bm{I}
\end{align}
\end{boxed-theorem}

The proof is direct from Definition \ref{def:stateTransM}, and a detailed discussion of these properties is omitted. Given these results, the calculation of the time response of a system in SS representation becomes straightforward.

\begin{boxed-theorem}{(Lagrange Formula)} \label{th:lagrangeForm}
	Consider a LTI system in State-Space representation. Its response for any time $t \geq t_0$, initial state $\bm{x}(t_0)$ and input signal $\bm{u}(t)$ is given by the solutions of the state and output equations:
	\begin{align}
	\begin{cases}
		\bm{x}(t) = e^{\bm{A}(t - t_0)} \bm{x}(t) + \int_{t_0}^{t} e^{\bm{A}(t - \tau)} \bm{B} \bm{u}(\tau) d \tau \hfill & \\
		\bm{y}(t) = \bm{C} e^{\bm{A}(t - t_0)} \bm{x}(t) + \bm{C} \int_{t_0}^{t} e^{\bm{A}(t - \tau)} \bm{B} \bm{u}(\tau) d \tau + \bm{D} \bm{u}(t) &
	\end{cases}
	\end{align}
\end{boxed-theorem}

\begin{proof}
	First of all, consider a system in State-Space representation with state equation as defined in Equation \eqref{eq:SSRepr03}. Multiplying both sides by $e^{-\bm{A} t}$:
	\begin{equation} \label{eq:lagrTH01}
	\begin{split}
	    e^{-\bm{A} t} \dot{\bm{x}}(t) &= e^{-\bm{A} t} (\bm{A} \bm{x}(t) + \bm{B} \bm{u}(t)) \\
	    e^{-\bm{A} t} \dot{\bm{x}}(t) - \bm{A}e^{-\bm{A} t} \bm{x}(t)  &=  e^{-\bm{A} t} \bm{B} \bm{u}(t)
    \end{split}
	\end{equation}
	
	Using the first assertive in Theorem \ref{th:stateTransMProp}, it is easy to see that $d[e^{-\bm{A} t} x(t)]/dt = e^{-\bm{A} t} \dot{\bm{x}}(t) - \bm{A} e^{-\bm{A} t} \bm{x}(t)$. Substituting this result in \eqref{eq:lagrTH01} and integrating both sides from $t_0$ to $t$:
	\begin{equation} \label{eq:lagrTH02}
	\begin{split}
	    \cfrac{d(e^{-\bm{A} t} \bm{x}(t))}{dt} &= e^{-\bm{A} t} \bm{B} \bm{u}(t) \\
	    \left. e^{-\bm{A} t} \bm{x}(t) \right|^{t}_{t_0}  &= \int_{t_0}^{t} e^{-\bm{A} t} \bm{B} \bm{u}(t) dt \\
	    e^{-\bm{A} t} \bm{x}(t) - e^{-\bm{A} t_0} \bm{x}(t_0)  &= \int_{t_0}^{t} e^{-\bm{A} \tau} \bm{B} \bm{u}(\tau) d\tau
    \end{split}
	\end{equation}
	
	Multiplying both sides by $e^{\bm{A} t}$ and using the second and third assertive from Theorem \ref{th:stateTransMProp}, the state response can be calculated as:
	\begin{equation} \label{eq:lagrTH03}
	\begin{split}
	    e^{\bm{A} t} \left( e^{-\bm{A} t} \bm{x}(t) \right. &- \left. e^{-\bm{A} t_0} \bm{x}(t_0) \right) = e^{\bm{A} t} \int_{t_0}^{t} e^{-\bm{A} \tau} \bm{B} \bm{u}(\tau) d\tau \\
	    \bm{I} \bm{x}(t) &- e^{\bm{A} (t - t_0)} \bm{x}(t_0) = \int_{t_0}^{t} e^{\bm{A}(t - \tau)} \bm{B} \bm{u}(\tau) d\tau \\
	    \bm{x}(t) &= e^{\bm{A} (t - t_0)} \bm{x}(t_0) + \int_{t_0}^{t} e^{\bm{A}(t - \tau)} \bm{B} \bm{u}(\tau) d\tau \\
    \end{split}
	\end{equation}
	
	Finally, substituting \eqref{eq:lagrTH03} into the output equation leads to:
	\begin{equation} \label{eq:lagrTH04}
	\begin{split}
	    \bm{y}(t) &= \bm{C} \left( e^{\bm{A} (t - t_0)} \bm{x}(t_0) + \int_{t_0}^{t} e^{\bm{A}(t - \tau)} \bm{B} \bm{u}(\tau) d\tau \right) + \bm{D} \bm{u}(t) \\ 
	    \bm{y}(t) &= \bm{C} e^{\bm{A}(t - t_0)} \bm{x}(t) + \bm{C} \int_{t_0}^{t} e^{\bm{A}(t - \tau)} \bm{B} \bm{u}(\tau) d \tau + \bm{D} \bm{u}(t) 
    \end{split}
	\end{equation}
\end{proof}

When discussing the response of a system, the focus is actually directed to the state equation describing its dynamics, since the output equation only represents an observation of the system through the states. In this sense, the Lagrange formula exposes the nice characteristic of linear systems that the total response is a composition of two separated actions:
\begin{equation}
    \bm{x}(t) = \bm{x}_{\text{n}}(t) + \bm{x}_{\text{f}}(t) 
\end{equation}

\noindent where the natural response, $\bm{x}_{\text{n}}(t)$, corresponds to the state-transition matrix multiplication term and the forced response, $\bm{x}_{\text{f}}(t)$, corresponds to the integral term. This concept is visualized in Fig. \ref{fig:linResp02} for the total response of the first two states of the model derived in Equation \eqref{eq:isoReact01}, given the operation points $\bm{x}_o = [6.19, 1.09]$ and $u_o = 3.03$, excited with a step input $u(t) = 3$, $t \in [0, 1.2]$. In this plot, the solid line represents the total response, whereas the dashed and dotted lines represents the natural and forced response, respectively. It is easy to verify that the decomposition of the total response is equal to the sum of those independent components.

\begin{figure}[ht]
	\centering
	\includegraphics[width=\textwidth]{chapter2/linResp02}
	\caption{simulation of the total response decomposition for the two first states of the model from \eqref{eq:isoReact01} shown separately (left) and in a single visualization (right) in which the steady-state point is indicated by a circle.}
	\label{fig:linResp02}
\end{figure}

The only problem remaining to fully characterize the dynamical response of a system is to compute the state-transition matrix, which can be done in several ways \cite{Moler_VanLoan:2003}. A specific method, known as the \textit{Sylvester expansion}, is an analytical solution that brings an interesting understanding of the system behavior through the state-state matrix $A$.

\begin{boxed-theorem}{(Sylvester expansion)} \label{th:sylvester01}
    Consider a matrix exponential function $f(\bm{A}) = e^{\bm{A} t}$ for any square matrix $\bm{A} \in \mathbb{R}^{n \times n}$, whose distinct eigenvalues are $\bm{\lambda} \in \mathbb{R}^{m},\ m \leq n,$ with associated multiplicity vector $\bm{\nu} \in \mathbb{R}^m$ such that $\sum_j \nu_j = n$. The result of this function can be expanded as:
    \begin{equation} \label{eq:sylvester01}
        f(\bm{A}) = e^{\bm{A} t} = \beta_0(t) \bm{I} + \beta_1(t) \bm{A} + \beta_2(t) \bm{A}^2 + ... + \beta_{n-1}(t) \bm{A}^{n-1} = \sum_{i=0}^{n-1} \beta_i(t) \bm{A}^i
    \end{equation} 
    
    \noindent where $\beta_i(t) : \mathbb{R} \rightarrow \mathbb{R}$, $i \in [1,2,...,n-1]$, are scalar functions of time that solves the linear system:
    \begin{equation} \label{eq:sylvester02}
        \bm{V} \bm{\beta} = \bm{\eta}
    \end{equation} 
    
    \noindent for the parameter matrix $\bm{\beta} = [\beta_0(t), \beta_1(t), ..., \beta_n(t)]^T$, and the vector of modes $\bm{\eta} = [\eta_1, \eta_2, ..., \eta_m]^T$ and the confluent Vandermonde matrix $\bm{V} = [V_1, V_2, ..., V_m]^T$ given as
    \begin{align*}
	    \eta_i & = \begin{bmatrix} e^{\lambda_i t} & te^{\lambda_i t} & t^2e^{\lambda_i t} & \cdots & t^{\nu_i-1}e^{\lambda_i t} \end{bmatrix}^T \\ \\
    	V_j 	& = \begin{bmatrix}
            1 & \lambda_j & \lambda_j^2 & \cdots & \lambda_j^{(\nu_j - 1)} & \cdots & \lambda_j^{n-1} \\
            0 & 1 & 2\lambda_j & \cdots & (\nu_j - 1) \lambda_j^{(\nu_j - 1)} & \cdots & (n-1)\lambda_j^{n-2} \\
            \vdots & \vdots & \vdots & \ddots & \vdots & \ddots & \vdots \\
            0 & 0 & 0 & \cdots & (\nu_j - 1)! & \cdots & \cfrac{(n - 1)!}{(n - \nu_j)!}\lambda_j^{n-\nu_j} \\
        \end{bmatrix}\
    \end{align*} 
\end{boxed-theorem}

The proof of this expansion is somewhat extensive, but a detailed discussion can be found in \cite{Chen:1998}. Basically, the expansion in Equation \eqref{eq:sylvester01} is a direct application of the Cayley-Hamilton theorem \cite{Atiyah:2018} and the linear system in Equation \eqref{eq:sylvester02} is a result of the Sylvester's matrix theorem  \cite{Horn:2012}.

From the expansion presented in Theorem \ref{th:sylvester01}, it is possible to understand the relationship between the state-transition matrix $e^{\bm{At}}$ and each eigenvalue $\lambda$ of the matrix $\bm{A}$, also known as the \textit{poles} of the system. First of all, notice that the formulation of the linear system that defines the parameters $\beta_0(t), \beta_1(t), ..., \beta_{n-1}(t)$ implies that each one of these functions are linear combinations of the exponentials $e^{\lambda_i t}$ for each eigenvalue $\lambda_i,\ i=1,2,...m$. These exponentials are known as the \textit{modes} of the matrix $\bm{A}$. Since the Sylvester expansion is linear in those parameters, it is possible to conclude that the state-transition matrix, and consequently the response of a system, is a linear combination of the modes.

Consider, for the sake of illustration, the same reactor model from Equation \eqref{eq:isoReact01}, but considering only the first two states (since they are independent of the others). Let $\bm{x}_o = [6.19, 1.09]^T$ and $u_0 = 3.03$, just as before. The resulting matrix $\bm{A}$ and state-transition matrix $e^{\bm{A} t}$ are shown below, where is easy to see that $\bm{\lambda} = [-5.93, -4.70]$, since $\bm{A}$ is diagonal:
\begin{align} \label{eq:stateRespEx01}
    \bm{A} = \begin{bmatrix} 
    	-5.93  &        0 \\
	    0.83   &  -4.70 
    \end{bmatrix} && e^{\bm{A} t} = \begin{bmatrix} 
    	e^{-5.93 t}  &        0 \\
	    0.68 e^{-4.7 t} - 0.68 e^{-5.93 t}  &  e^{-4.70 t} 
    \end{bmatrix}
\end{align}

A simulation in time, shown in Fig \ref{fig:stateTrans01}, shows the evolution of each element of $e^{\bm{A} t}$ for a given time interval. Considering only the natural response $\bm{x}_n(t)$, i.e., setting $\bm{u}(t) \equiv 0,\ t \in [t_0, t]$, it is evident that the actual response of each state in the system is a row-wise weighted sum of these elements, where the weights are given by the initial state $\bm{x}(t_0)$. Therefore, the $(i, j)$ element of this matrix describes how the $j$-th state affects the response of the $i$-th state.

\begin{figure}[ht]
	\centering
	\includegraphics[width=\textwidth]{chapter2/stateTrans01}
	\caption{simulation of the state-transition matrix $e^{\bm{A} t}$ in Equation \eqref{eq:stateRespEx01} for $t \in [0,2]$}
	\label{fig:stateTrans01}
\end{figure}

Now, attention must be drawn to the case where the eigenvalues are not real, but complex and conjugate. Despite that the Sylvester expansion is still defined as in Theorem \ref{th:sylvester01}, this case introduces a slightly different interpretation of the modes contributions to the natural response.

\begin{boxed-theorem}{} \label{th:sylvester02}
    Consider the same expansion defined in Theorem \ref{th:sylvester01}. Consider, now, that the matrix $\bm{A}$ has two distinct eigenvalues $\lambda_c, \lambda_c' \in \mathbb{C}$ in the form $\lambda_c, \lambda_c' = \alpha \pm j \omega$. In this case, the linear system solved by the parameters $\beta_0(t), \beta_1(t), ..., \beta_{n-1}(t)$ will have two equations:
    \begin{align} \label{eq:sylvEq01}
    \begin{cases}
        \beta_0 + \alpha \beta_1 + \alpha^{2} \beta_2 + ... + \alpha^{n-1} \beta_{n-1} = e^{\alpha t} cos(\omega t) & \\
        \hfill 0 + \omega \beta_1 + \omega^{2} \beta_2 + ... + \omega^{n-1} \beta_{n-1} = e^{\alpha t} sin(\omega t) &
    \end{cases}
    \end{align}
\end{boxed-theorem}

\begin{proof}
    Consider the matrix $\bm{A}$ with eigenvalues as specified and the Sylvester expansion as presented. In this case, there will be two equations in the system:
    \begin{align} 
    \begin{cases}
        \beta_0 + \lambda_c \beta_1 + \lambda_c^2  \beta_2 + ... + \lambda_c^{n-1} \beta_{n-1} = e^{\lambda_c t} & \\
        \beta_0 + \lambda_c' \beta_1 + (\lambda_c')^{2} \beta_2 + ... + (\lambda_c')^{n-1} \beta_{n-1} = e^{\lambda_c' t} &
    \end{cases}
    \end{align}
    
    Since the eigenvalues are complex and conjugate, it has that $\lambda_c + \lambda'_c = 2 \mathbb{R}e[\lambda_c] = 2 \alpha$ and $\lambda_c - \lambda'_c = 2j \mathcal{I}m[\lambda_c] = 2j \omega$. Moreover, the Euler identity $e^{\alpha \pm j \omega} = e^{\alpha t}(cos(\omega) \pm j sin(\omega))$ shows that $e^{\lambda} + e^{\lambda'} = 2 e^{\alpha t} cos(\omega t)$ and $e^{\lambda} - e^{\lambda'} = 2 e^{\alpha t} sin(\omega t)$. In this case, summing the two rows and subtracting the first row by the second one results in:
    \begin{align} 
    \begin{cases}
        \beta_0 + 2 \alpha \beta_1 + 2 \alpha^2  \beta_2 + ... + 2 \alpha^{n-1} \beta_{n-1} = 2 e^{\alpha t} cos(\omega t) & \\
        0 + 2j \omega \beta_1 + 2j \omega^{2} \beta_2 + ... + 2j \omega^{n-1} \beta_{n-1} = 2j e^{\alpha t} sin(\omega t) &
    \end{cases}
    \end{align}
    
    Finally, dividing the first row by $2$ and the second row by $2j$ results in \eqref{eq:sylvEq01}.
\end{proof}

From the same reasons stated before, this result implies that the actual response of the system will have sinusoidal components that produces oscillations in the response. The modes associated with complex and conjugate eigenvalues are classified as \textit{pseudo-periodic}, since they are composed by an exponential growth (or decay) enveloping a sinusoidal function. Consider, again for the sake of illustration, the following toy example:
\begin{align} \label{eq:stateRespEx02}
    \bm{A} = \begin{bmatrix} 
    	 -0.1  &  \hfill 0.5 \\
	    -0.5   &  -0.1 
    \end{bmatrix} && e^{\bm{A} t} = \begin{bmatrix} 
    	e^{-0.1 t} cos(0.5t)  &    e^{-0.1 t} sin(0.5t) \\
	    -e^{-0.1 t} sin(0.5t)  &  e^{-0.1 t} cos(0.5t)
    \end{bmatrix}
\end{align}

The elements of the resulting state-transition matrix are simulated for a specific time-interval and shown in Fig. \ref{fig:stateTrans02}. It is possible to see, in this case, the pseudo-periodic behavior of the complex conjugate modes, where the dashed lines represents the exponential envelope. 

\begin{figure}[ht]
	\centering
	\includegraphics[width=\textwidth]{chapter2/stateTrans02}
	\caption{simulation of the state-transition matrix $e^{\bm{A} t}$ in Equation \eqref{eq:stateRespEx02} for $t \in [0,50]$}
	\label{fig:stateTrans02}
\end{figure}

The previous discussion on the modes of matrix $\bm{A}$ introduced the importance of the eigenvalues of this matrix in analyzing the system response. The analysis, however, was focused on the natural response $\bm{x}_n(t)$, whereas the forced response $\bm{x}_f(t)$ was deliberately omitted. Now, the analysis focus the opposite case. Consider, for instance, the response of the first state for the two systems described by the matrices $(\bm{A}^{(1)}, b^{(1)})$ and $(\bm{A}^{(2)}, b^{(2)})$ given below, which are more complete descriptions of the systems in \eqref{eq:stateRespEx01} and \eqref{eq:stateRespEx02}. Considering initial states $\bm{x}^{(1)}(0) \equiv \bm{x}^{(2)}(0) \equiv 0$ and the input signals $\bm{u}^{(1)}(t) \equiv \bm{u}^{(2)}(t) \equiv 1$, for time $t \in [0, 60)$, the evolution of these states are shown in Fig. \ref{fig:forcedResponse}.
\begin{equation} \label{eq:isoSys02}
\begin{matrix}
    \bm{A}^{(1)} = \begin{bmatrix} 
    	-5.93  &      0 \\
	    \hfill 0.83   &  -4.70 
    \end{bmatrix} & b^{(1)} = \begin{bmatrix} 3.81 \\ -1.09 \end{bmatrix} & & & \bm{A}^{(2)} = \begin{bmatrix} 
    	 -0.1  &  \hfill 0.5 \\
	    -0.5   &  -0.1 
    \end{bmatrix} & b^{(2)} = \begin{bmatrix} 1 \\ 1 \end{bmatrix}
\end{matrix}
\end{equation}

\begin{figure}[ht]
	\centering
	\includegraphics[width=\textwidth]{chapter2/forcedResponse}
	\caption{one-state forced response of the two systems from \eqref{eq:isoSys02}.}
	\label{fig:forcedResponse}
\end{figure}

Since $\bm{A}^{(1)}$ is diagonal and $\bm{A}^{(2)}$ has a single pair of complex conjugate eigenvalues, it is possible to consider that those are respectively the characteristic responses of aperiodic and pseudo-periodic modes to an unitary step input. Since any signal can be decomposed by a sequence of step signals, the forced response to an unitary step is the default evolution used in literature to characterize the behavior of modes (and ultimately, of systems) in respect to some specifications of the transient response defined below.

\begin{boxed-definition}{(Unit-Step Response Specifications)} \label{def:responseParameters}
	Given a mode $e^{\lambda t}$ associated with the eigenvalue $\lambda \in \mathbb{R}$, its contribution to the response has a time constant ($\tau$) defined as
	\begin{equation}
		\tau = - \cfrac{1}{\lambda}
	\end{equation}	
	
	Furthermore, given pseudo-periodic modes $e^{\lambda t}$ and $e^{\lambda' t}$ of the matrix $\bm{A}$ associated with the eigenvalues $\lambda,\lambda' = \alpha \pm j \omega$, their contribution to the response has a time constant ($\tau$), a natural frequency ($\omega_n$) and a damping coefficient ($\zeta$) defined as:
	\begin{equation}
	\begin{matrix}
		\tau = - \cfrac{1}{\alpha} & & & \omega_n = \sqrt{\alpha^2 + \omega^2} & & & \zeta = - \cfrac{\alpha}{\omega_n}
	\end{matrix}
	\end{equation}
	
\end{boxed-definition}   

The specifications just defined provides a quantitative way to describe the response of a system in terms of time and frequencies. The time constant, for instance, is a quantity that represents the time needed for the mode to lost $63\%$ of its initial value, since $e^{\lambda \tau} = e^{-1} = 0.37$. A greater value of a time constant indicates that the system is able to ``discharge" energy faster. The damping coefficient, in turn, provides an information about the intensity of the peak in the pseudo-periodic responses, which is known as \textit{overshoot} (or \textit{undershoot} in the case that of a negative peak) and the natural frequency represents the oscillation of the response before reaching steady-state. From the perspective of control theory, these are some of the specifications used to define desirable transient responses to a controlled system.

Notice that the response specifications are always functions of the real and imaginary parts of the discussed eigenvalues. This brings the possibility of a visualization in the complex plane to interpret how each eigenvalue contributes to the total response. A straightforward notion is that the closer an eigenvalue is to the imaginary axis, the faster is its contribution. Similarly, the furthest an eigenvalue is to the real axis, the more oscillatory is its contribution. Finally, a vector from the origin of the plane to a complex eigenvalue has a norm equal to the natural frequency ($\omega_n$) and the cosine of the angle formed with the imaginary axis is equal to the damping factor ($\zeta$). A simulation of the contributions from different eigenvalues are shown in Fig. \ref{fig:eigen01}.

\begin{figure}[ht]
	\centering
	\includegraphics[width=\textwidth]{chapter2/eigen01}
	\caption{eigenvalues of a system and the forced response associated with their modes.}
	\label{fig:eigen01}
\end{figure}

\section{Similarity Transformations}

A State-Space representation can be interpreted through a system of coordinates. A state, in this context, represents a vector as visualized through this reference. Under the assumption of a linear time-invariant system, there is an intuition that is possible to change the representation of the states by changing this system of coordinates through some linear transformation, obtaining a different model to the same system. This is the motivation for the discussion in this section.

First of all, consider a brief reflection about the geometrical interpretation of a State-Space model for a physical system. Let a state-vector in an arbitrary time $t$ be $\bm{x}(t) = [1, 3]^T$, defined in the $\mathbb{R}^{2}$ space, as shown in the left side of Fig. \ref{fig:similarity01} in a Cartesian coordinate system. It is possible to associate to this vector an orthonormal basis $\bm{I} \in \mathbb{R}^2$, the 2-dimensional identity matrix, such that the vector $\bm{x}(t)$ observed through this basis standard basis is equal to itself. This concept provides the possibility to associate any other arbitrary basis to represent a state-vector and visualize the states through this perspective. When the basis is not orthogonal, a change in the state-vector with a direction parallel to a component of the basis, i.e., a change in only one element of this vector, produces a change in other directions if observed through the original orthonormal basis. This is an interesting result, since it shows the interactions between two state variables through a basis, making it possible to observe mutual changes in those variables from a single direction. The right side of Fig. \ref{fig:similarity01} illustrates the vector $\bm{x}(t)$ as referenced through the basis $\bm{Q} = [\bm{q}_1, \bm{q}_2]^T$, for $\bm{q}_1 = [3, 1]^T$ and $\bm{q}_1 = [2, 2]^T$, given as: 
\begin{equation}
	\bm{x}(t) = \begin{bmatrix} 1 \\ 3 \end{bmatrix} = \begin{bmatrix} 3 & 2 \\ 1 & 2 \end{bmatrix} \begin{bmatrix} -1 \\ 2 \end{bmatrix} = \bm{G}\bm{z}(t)
\end{equation}

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{chapter2/similarity01}
    \caption{visualization of a basis transformation applied to a vector.}
    \label{fig:similarity01}
\end{figure}

In the State-Space formulation, the matrix $\bm{A}$ represents a linear function that maps state-vectors from $\mathbb{R}^{n}$ to itself. When applying a new basis to represent the state-vectors, it is intuitive that the mapping performed by this function also changes so that it still represents the same linear combination of the states.

\begin{boxed-theorem}{(Similarity Transformation)}
	Consider a system in SS representation described by the matrices $(\bm{A}, \bm{B}, \bm{C}, \bm{D})$ and a nonsingular transformation matrix $\bm{P} \in \mathbb{R}^{n \times n}$. An equivalent representation for the transformation $\bm{z}(t) = \bm{P} \bm{x}(t)$ is:
	\begin{align}
	\begin{cases}
		\dot{\bm{z}}(t) = \tilde{\bm{A}} \bm{z}(t) + \tilde{\bm{B}} \bm{u}(t) & \\
		\bm{y}(t) = \tilde{\bm{C}} \bm{z}(t) + \tilde{\bm{D}} \bm{u}(t)
	\end{cases}	
	\end{align}
	
	\noindent where:
	\begin{equation}
		\begin{matrix}
			\tilde{\bm{A}} = \bm{P} \bm{A} \bm{P}^{-1} & & \tilde{\bm{B}} = \bm{P} \bm{B} & & \tilde{\bm{C}} = \bm{C} \bm{P}^{-1} & & \tilde{\bm{D}} = \bm{D}
		\end{matrix}
	\end{equation}
\end{boxed-theorem}

\begin{proof}
    Consider a SS representation and any nonsingular matrix $\bm{P} \in \mathbb{R}^{n \times n}$. Making $\bm{z}(t) = \bm{P} \bm{x}(t)$ leads to $\bm{x}(t) = \bm{P}^{-1} \bm{z}(t)$. Substituting this in the state equation results in:
    \begin{equation}
    \begin{split}
        \dot{\bm{x}}(t) &= \bm{A} \bm{x}(t) + \bm{B} \bm{u}(t) \\
        \bm{P}^{-1} \dot{\bm{z}}(t) &= \bm{A} \bm{P}^{-1} \bm{z}(t) + \bm{B} \bm{u}(t) \\
        \bm{I} \dot{\bm{z}}(t) &= \bm{P} \bm{A} \bm{P}^{-1} \bm{z}(t) + \bm{P} \bm{B} \bm{u}(t) \\
        \dot{\bm{z}}(t) &= \tilde{\bm{A}} \bm{z}(t) + \tilde{\bm{B}} \bm{u}(t)
    \end{split}
    \end{equation}
    
    Thus, substituting $\bm{x}(t) = \bm{P}^{-1} \bm{z}(t)$ in the output equation results in:
    \begin{equation}
    \begin{split}
        \bm{y}(t) &= \bm{C} \bm{x}(t) + \bm{D} \bm{u}(t) \\
        \bm{y}(t) &= \bm{C} \bm{P}^{-1} \bm{y}(t) + \bm{D} \bm{u}(t) \\
        \bm{y}(t) &= \tilde{\bm{C}} \bm{z}(t) + \tilde{\bm{D}} \bm{u}(t)
    \end{split}
    \end{equation}
\end{proof}

By this theorem is it clear that, after transforming the state-vector, the entire dynamical model $(\bm{A}, \bm{B}, \bm{C}, \bm{D})$ changes. This would imply that the analysis of the original system, for its properties and time response, is not valid for the similar transformed system. However, as discussed before, these transformations accounts for the same system when observed through a different reference basis. Therefore, it is expected that the model presents the same analysis results, as demonstrated below.

\begin{boxed-theorem}{} \label{th:simTrans01}
    Consider a system in State-Space form with matrix $\bm{A}$. Consider also a similarity transformation $\bm{z}(t) = \bm{P} \bm{x}(t)$ that results in a similar matrix $\tilde{\bm{A}} = \bm{P} \bm{A} \bm{P}^{-1}$. In this case, $\bm{A}$ and $\tilde{\bm{A}}$ have the same set of eigenvalues.
\end{boxed-theorem}

\begin{proof}
    The eigendecomposition problem is defined as $\bm{A} \bm{v} = \bm{\lambda} \bm{v}$. From the similarity transformation, $\tilde{\bm{A}} = \bm{P} \bm{A} \bm{P}^{-1}$ leads to $\bm{A} = \bm{P}^{-1} \tilde{\bm{A}} \bm{P}$. Substituting this in the eigendecomposition:
    \begin{align}
    \begin{split}
        \bm{P}^{-1} \tilde{\bm{A}} \bm{P} \bm{v} & = \bm{\lambda} \bm{v} \\
        \tilde{\bm{A}} \bm{P} \bm{v} & =  \bm{\lambda} \bm{P} \bm{v}
    \end{split}
    \end{align}
   
    Considering the transformed eigenvector $\tilde{\bm{v}} = \bm{P} \bm{v}$, it is clear that $\tilde{\bm{A}} \tilde{\bm{v}} = \bm{\lambda} \tilde{\bm{v}}$, implying that the matrices $\bm{A}$ and $\tilde{\bm{A}}$ shares the same set of eigenvalues $\bm{\lambda}$.
\end{proof}

It is clear from past results that the fact that both the matrices shares the same set of eigenvalues directly implies that they provide the same dynamical responses and, as will be shown later, the same general properties. Therefore, the similarity transformation consists in a method to produce new State-Spaces representations that emphasizes some geometrical perspective of the model, hopefully in some perspective that helps analyze a specific property, without actually changing the relationship of the original model with the physical system.

The use of similarity transformations can also benefits the computation of functions of the matrices of the State-Space representation, given that they impose a desirable structure to this matrix. With this motivation, a popular transformation that provides a new representation with computational advantages is the Similarity transformation.

\begin{boxed-theorem}{(Diagonalization)}
	Consider a $n$-dimensional system in State-Space form represented by the matrices $(\bm{A}, \bm{B}, \bm{C}, \bm{D})$, such that the matrix $\bm{A}$ has $n$ distinct real eigenvalues, i.e., $\bm{\lambda} \in \mathbb{R}^n$. Performing the transformation $\bm{z}(t) = \bm{V} \bm{x}(t)$, where $\bm{V} = [\bm{v}_1, \bm{v}_2, ..., \bm{v}_n]$ is the modal matrix composed by the eigenvectors $\bm{v}_i \in \mathbb{R}^n$, $i \in [1, ..., n]$, of matrix $\bm{A}$, the resulting transformed matrix $\bm{\Lambda} = \bm{V} \bm{A} \bm{V}^{-1}$ is diagonal.
\end{boxed-theorem} 

\begin{proof}
	Since the eigenvalues are real and distinct, the eigenvectors must be linearly independent, proving that the inverse $\bm{V}^{-1}$ always exist and that it is a feasible transformation matrix. Using the identity for the eigendecomposition of matrix $\bm{A}$:
	\begin{align}
	\begin{split}
		\bm{\lambda} \bm{v} &= \bm{A} \bm{v} \\
		\begin{bmatrix} \lambda_1 \bm{v}_1 & \lambda_2 \bm{v}_2 & \cdots & \lambda_n \bm{v}_n \end{bmatrix} &= \begin{bmatrix} \bm{A} \bm{v}_1 & \bm{A} \bm{v}_2 & \cdots & \bm{A} \bm{v}_n  \end{bmatrix} \\
		\begin{bmatrix} \bm{v}_1 & \bm{v}_2 & \cdots & \bm{v}_n \end{bmatrix} \begin{bmatrix} \lambda_1 & 0 & \cdots & 0 \\ 0 & \lambda_2 & \cdots & 0 \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \cdots & \lambda_n  \end{bmatrix} & = \bm{A} \begin{bmatrix} \bm{v}_1 & \bm{v}_2 & \cdots & \bm{v}_n \end{bmatrix} \\
		\begin{bmatrix} \lambda_1 & 0 & \cdots & 0 \\ 0 & \lambda_2 & \cdots & 0 \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \cdots & \lambda_n  \end{bmatrix} & = \begin{bmatrix} \bm{v}_1 & \bm{v}_2 & \cdots & \bm{v}_n \end{bmatrix}^{-1} \bm{A} \begin{bmatrix} \bm{v}_1 & \bm{v}_2 & \cdots & \bm{v}_n \end{bmatrix} \\
		\bm{\Lambda}  &= \bm{V}^{-1} \bm{A} \bm{V}
	\end{split}
	\end{align}
	
	Concluding that $\bm{\Lambda}$ is a diagonal matrix which elements are the eigenvalues of matrix $\bm{A}$.
\end{proof}

This result can be easily extended to the case where the eigenvalues are conjugate complex pairs, but each pair is distinct. A model with a diagonal matrix $\bm{A}$ has the nice property that the evolution of the states are decoupled, in the sense that each state evolution is a linear function of itself. A geometrical interpretation of this transformation is that the eigenvectors of this matrix produces a basis that encode information about the interaction between those states, while the interaction in the original formulation was the linear combination of the modes. 

In this diagonalization procedure, the resulting elements of the matrix $\bm{\Lambda}$ are the very own eigenvalues of the original matrix $\bm{A}$, which allows for a direct interpretation of the system response by just visualizing this matrix. Furthermore, it is easy to verify that the state-transition matrix for the transformed matrix, $e^{\bm{\Lambda} t}$, is also a diagonal matrix whose elements are the modes of the system, and can be easily computed:

\begin{align}
\begin{split}
	e^{\bm{\Lambda} t} & = \sum_{k=0}^{\infty} \cfrac{A^k t^k}{k!	}  = \sum_{k=0}^{\infty} \cfrac{t^k}{k!} \begin{bmatrix} \lambda_1^k & 0 & \cdots & 0 \\ 0 & \lambda_2^k & \cdots & 0 \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \cdots & \lambda_n^k  \end{bmatrix} = \begin{bmatrix} \cfrac{t^k\lambda_1^k}{k!} & 0 & \cdots & 0 \\ 0 & \cfrac{t^k\lambda_2^k}{k!} & \cdots & 0 \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \cdots & \cfrac{t^k\lambda_n^k}{k!} \end{bmatrix} \\ 
	&= \begin{bmatrix} e^{\lambda_1 t} & 0 & \cdots & 0 \\ 0 & e^{\lambda_2 t} & \cdots & 0 \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \cdots & e^{\lambda_n t} \end{bmatrix}
\end{split}
\end{align}

In the case that the eigenvalues are not all distinct, it may be not possible to design a modal matrix in the same way, since the eigenvectors could not be all linearly independent, and the matrix would not form a basis. In those cases, however, it is still possible to design a generalized modal matrix that transform the original matrix $\bm{A}$ to a quasi-diagonal matrix $\bm{J}$, where there will be decoupled block of states. This similarity transformation is known as the Jordan form \cite{Strang:2016}, and it generalizes the notion of diagonalization for any arbitrary matrix.

\section{Stability, Controlability and Observability}

When moving from a discussion of the models in the perspective of dynamical system analysis to a perspective of control theory, it is necessary to define and analyze some important properties of a system. These properties are characteristic to the system, analyzed through a model, but they account directly to questions relating the control objectives and the instrumentation, as it will be shown later.

The first property to be discussed consists in the stability of a system. An instable system, as the name suggests, is a system whose response does not converge to a specific value and rather oscillates or grows unbounded. In physical scenarios, unstable systems are problematic, since their response to external stimuli can result in dangerous situations to itself and, maybe, to the environment around it. Because of this, determining the stability of a system is a crucial procedure into analyzing a system that will be controlled. Under the several quantitative methods to determine if a system is indeed stable, given a mathematical model, a popular and practical one is the Bounded-Input Bounded-Output (BIBO) stability criteria.

\begin{boxed-definition}{(BIBO Stability)}
	A dynamical system is defined as BIBO stable if every bounded input stimuli $| \bm{u}(t) | \leq \epsilon < \infty$ produces in it a bounded output response $| \bm{y}(t) | \leq \delta < \infty$.
\end{boxed-definition}

The main result behind this criteria is that the natural response of a system should vanish as time evolves, i.e., $\bm{x}(t) \equiv 0$ as $t \to \infty$. This result is very intuitive from Theorem \ref{th:lagrangeForm}, since the vanishing of the natural response implies that $e^{\bm{A} t} \equiv 0$ as $t \to \infty$ and the forced response is expected to be bounded, if $\bm{u}(t)$ is bounded. Since the state-transition matrix is a linear combination of the modes, and the modes are exponential functions of the eigenvalues of the matrix $\bm{A}$, it is possible to determine a condition for stability in the light of these quantities.

\begin{boxed-theorem}{(BIBO Stability in SS)} \label{th:BIBOStab}
	A system in State-Space form, represented by a matrix $\bm{A} \in \mathbb{R}^{n \times n}$ with eigenvalues $\bm{\lambda} \in \mathbb{R}^n$, is BIBO stable if and only if $\mathbb{R}e[\lambda_i] < 0,\ \forall i \in [1,2,...,n]$.
\end{boxed-theorem}

A detailed proof of this theorem can be found in Appendix A. First of all, note that this criteria depends only on the eigenvalues of matrix $\bm{A}$, so the stability property of a system is invariant to any similarity transformation, since $\bm{A}$ and any transformed matrix $\tilde{\bm{A}} = \bm{P} \bm{A} \bm{P}^{-1}$ shares the same eigenvalues. From the previous results it is also known that the real part of the eigenvalues, independent of their multiplicity or domain, appears as the arguments of the exponential functions that are the system modes. Therefore, an eigenvalue with a negative real part will produce a mode that is a exponential decay, as this theorem indicates. By the same argument, if the matrix $\bm{A}$ has at least one eigenvalue $\lambda_j = 0$ such that $\mathbb{R}e[\lambda_i] \leq 0,\ \forall i \in [1,2,...,n]$, then the mode associated with this eigenvalue is a constant and the natural response becomes bounded. This configuration is known as a marginally stable condition, in the BIBO perspective. The time response of a $2$-nd order system is shown Fig. \ref{fig:stability01} for three different poles configurations, given an unitary step.

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{chapter2/stability01}
    \caption{stability of forced responses given the positions of the system poles.}
    \label{fig:stability01}
\end{figure} 

Later chapters will discuss the possibility of stabilize an unstable system through a controller. There are, however, some restrictions to the possibility of controlling or not the states of a system, which includes the necessity of discussing \textit{controllability}. The controllability of a system states whether it is possible to calculate an input signal that drive the system to any arbitrary state or not, given some time restriction. This property accounts exclusively for this possibility, in the sense that it does not account for the operational feasibility of actually applying this input signal into a physical system, since it may need more energy than an actuator can produce. 

\begin{boxed-definition}{(Controllability)}
	A system in State-Space form with matrices $(\bm{A}, \bm{B})$ is said to be controllable if, for any initial state $\bm{x}(t_0) = \bm{x}_0$ and terminal state $\bm{x}(T) = \bm{x}_T$, $T < \infty$, there exists an input signal $\bm{u}(t)$, $t \in [t_0, T]$, that can transfer $\bm{x}(t_0)$ to $\bm{x}(T)$. Otherwise, the system is said to be uncontrollable. 
\end{boxed-definition}

There are several methods to analyze the controllability of a system given a mathematical model and the definition above. A popular criteria introduces the concept of a controllability matrix and has a nice geometrical interpretation.

\begin{boxed-theorem}{(Controllability in SS)}
	Consider a system in linear State-Space form with matrices $(\bm{A}, \bm{B})$ and the controllability matrix $\bm{\mathcal{C}} \in \mathbb{R}^{n \times nr}$ defined as:
	\begin{equation}
		\bm{\mathcal{C}} = \begin{bmatrix} \bm{B} & \bm{A} \bm{B} & \bm{A}^2 \bm{B} & \cdots & \bm{A}^{n-1} \bm{B} \end{bmatrix}
	\end{equation}
	
	\noindent The system is controllable if and only if $\bm{\mathcal{C}}$ has full row rank.
\end{boxed-theorem}   

An intuition behind this theorem is that the full row rank condition implies that $\mathcal{C}$ has $n$ linearly independent columns, therefore these columns can be used as a basis for what is known as the \textit{controllable subspace}. To better understand that, consider the following forced solution $\bm{x}_f(t)$ given by the Lagrange formula:
\begin{equation}
	\bm{x}_f(t) = \int_{0}^{t} e^{\bm{A} (t-\tau)} \bm{B} \bm{u}(\tau) d\tau
\end{equation}

From the Cayley-Hamilton theorem, shown in the Sylvester expansion at Theorem \ref{th:sylvester01}, it is possible to represent $e^{\bm{A}(t-\tau)}$ as a linear combination of scalars $\beta_i(t-\tau)$ and powers of the matrix $\bm{A}^i$, $i \in [0, 1,..., n-1]$. Thus, using this theorem and substituting $\tau_2 = t - \tau$ for an easier manipulation, the forced response can be represented as:
\begin{align}
\begin{split}
	\bm{x}_f(t) &= \int_{0}^{t} \left( \sum_{i=0}^{n-1} \beta_i(\tau_2) \bm{A}^i \right) \bm{B} \bm{u}(t - \tau_2) d\tau_2 = \sum_{i=0}^{n-1} \left( \bm{A}^i \bm{B} \right) \int_{0}^{t} \beta_i(\tau_2) \bm{u}(t - \tau_2)  \\
		&= \sum_{i=0}^{n-1} \left( \bm{A}^i \bm{B} \right) \tilde{\beta}_i(\bm{u}, t)
\end{split}
\end{align}

\noindent where $\bm{A}^i \bm{B}$ are the columns of the matrix $\bm{\mathcal{C}}$ and $\tilde{\beta}_i(\bm{u}, t)$ is a function that depends only on the input signal $\bm{u}(t)$ and time $t$. This result implies that the unforced response $\bm{x}_f(t)$ is a linear combination given by the columns of $\bm{\mathcal{C}}$. If $\bm{\mathcal{C}}$ has $n$ linearly independent columns, than this linear combination spans the entire $n$-dimensional space, i.e., the entire state space, and thus any desirable state vector $\bm{x}^*$ can be reached. If the column rank of $\bm{\mathcal{C}}$ is less than $n$, then only a subspace of smaller dimension can be reached through the forced response.

While the discussion on controllability concerns the possibility of driving a system to a desirable state through an actuator signal, there is also the necessity to discuss the possibility of determining the internal state of a system given the output signal $\bm{y}(t)$. This property, known as \textit{observability}, comes from the fact that any output of a system, related to the states through the matrix $\bm{C}$, may be a combination of states, and that some states may not even be present in the output signal. In conclusion, it is necessary to know if it is possible to reconstruct $\bm{x}(t)$ directly through $\bm{y}(t)$. 

\begin{boxed-definition}{Observability}
	A system in State-Space form with matrices $(\bm{A}, \bm{C})$ is said to be observable if, given an input signal $\bm{u}(t)$ and output signal $\bm{y}(t)$, over the interval $t \in [t_0, T]$, it is possible to uniquely determine the value of the initial state $\bm{x}(t_0)$. Otherwise, the system is said to be unobservable.
\end{boxed-definition}

Similarly to the controllability property, there are several ways to analyze the observability of a system, given a mathematical model. A popular criteria introduces the concept of a observability matrix.

\begin{boxed-theorem}{(Observability in SS)}
	Consider a system in linear State-Space form with matrices $(\bm{A}, \bm{C})$ and the observability matrix $\bm{\mathcal{O}} \in \mathbb{R}^{nq \times n}$ defined as:
	\begin{equation}
		\bm{\mathcal{O}} = \begin{bmatrix} \bm{C} \\ \bm{C} \bm{A} \\ \bm{C} \bm{A}^2 \\ \vdots \\ \bm{C} \bm{A}^{n-1} \end{bmatrix}
	\end{equation}
	
	\noindent The system is observable if and only if $\bm{\mathcal{O}}$ has full column rank.
\end{boxed-theorem}   

The interpretation of this theorem follows the same intuition of before: if the matrix $\bm{\mathcal{O}}$ has full column rank, then it can be used as a basis to span a subspace with the same dimension as the State-Space. In fact, the proof of both theorems follows the same procedures and there is a direct relationship between controllability and observability, known as the Theorem of Duality.

The concepts of controllability and observability just presented, together with the conditions to fulfill these properties, were first introduced by \cite{Kalman:1960}. The geometrical interpretations of both theorems may suggest a practical solution for the cases where a system is uncontrollable or unobservable. In the first case, the solution would be to add specific actuators to the system, in the condition that they are linearly independent between themselves and the ones actually in operation. The same procedure can be done to solve the unobservable problem, but adding more sensors instead. Those procedures would change the matrices $\bm{B}$ and $\bm{C}$, without changing the system dynamics, and could ensure the necessary conditions in matrices $\bm{\mathcal{C}}$ and $\bm{\mathcal{O}}$. Of course, the implementation of such instrumentation may not be practical, due to technical or economical constraints. Of course, if including these additional devices is not feasible, one can still control and observe a given subset of the state variables.

\section{Frequency Response Analysis}

Although the response of dynamical systems are naturally perceived in time, there are advantages of analyzing the models in a frequency domain perspective. This analysis differs from a simple time domain analysis from the fact that, in a steady-state regime, the response of a linear system for a sinusoidal input is itself sinusoidal, with the same frequency but different amplitude and phase, as illustrated at Fig. \ref{fig:freq01}.

\begin{figure}[ht] 
	\centering
	\begin{subfigure}{0.25\textwidth}	
		\centering
		$u(t) = M_i cos(\omega t + \phi_i)$\par\medskip
		\includegraphics[scale=0.55]{chapter2/freq01_1}
	\end{subfigure}
	\begin{subfigure}{0.38\textwidth}	
		\centering
		\includegraphics[scale=0.6]{chapter2/freq01_2}
	\end{subfigure}
	\begin{subfigure}{0.25\textwidth}	
		\centering
		$y(t) = M_o cos(\omega t + \phi_o)$\par\medskip
		\includegraphics[scale=0.55]{chapter2/freq01_3}
	\end{subfigure}
	
	\caption{illustration of the steady-state response of LTI systems to sinusoidal inputs.}
	\label{fig:freq01}
\end{figure}

A common representation is the phasor representation, where $M \angle \phi = M cos(\omega t + \phi)$. In the context of SISO Input-Output models, the response of the system can be summarized by a transfer function which is also a phasor:
\begin{equation}
    g(t) = \cfrac{y(t)}{u(t)} = \cfrac{M_o \angle \phi_o}{M_i \angle \phi_i} = M_g \angle \phi_g
\end{equation}

\noindent where $M_g = M_o / M_i$ and $\phi_g = \phi_o - \phi_i$. Notice that this formulation makes the time-dependance implicit in the system response, since it is periodic in this case. For this reason, the system response can be visualized as a function of frequency rather than a function of time, and the properties of the system can be accessed in this way. The two most popular techniques for frequency response analysis are Bode plots \cite{Bode:1945} and Nyquist diagrams \cite{Nyquist:1932}. The first is a direct plot of $M_g(\omega)$ and $\phi_g(\omega)$ for several values of $\omega$, making $M_g(\omega) = 20 log \left| G(j\omega) \right|$ and $\phi_g(\omega) = \angle G(j\omega)$, where $G(j\omega)$ is a transfer function of a system evaluated for an input signal with exclusively oscillatory components. The Nyquist diagram, in the other hand, is a direct phasor visualization obtained by applying the Argument Principle to a contour containing the entire right-hand side of the complex plane. Both visualizations are depicted in Fig. \ref{fig:freq02}, for a Transfer function obtained by applying the transformation of Theorem \ref{th:SSToIO} into the system from \eqref{eq:stateRespEx01}:
\begin{equation} \label{eq:IOSys01}
	\bm{G}(s) = \begin{bmatrix}
		\cfrac{3.81}{s + 5.92} & \cfrac{-1.09s - 3.33}{s^2 + 10.62s + 27.84}
	\end{bmatrix}
\end{equation}

\begin{figure}[ht]
	\centering
	\includegraphics[width=\textwidth]{chapter2/freq02}
	\caption{visualization of the two-states system in \eqref{eq:IOSys01} in Bode plots (left) and Nyquist diagrams (right). The blue and orange lines represents the states $x_1$ and $x_2$, respectively.}
	\label{fig:freq02}
\end{figure}

The immediate advantage of these visualizations is that is not necessary to compute an entire simulation of this system, until it reaches steady-state, to be able to perform analysis, which is really critic for high-dimensional systems with slow time-constants. In addition to that, these visualizations (specially the Bode plot) can be easily sketched by hand with fairly accuracy, allowing for some understanding of the system without need for solving differential equations or the inverse Laplace transforms. For these reasons, frequency responses methods for analyzing systems were ubiquitous for many years in industry applications, and some properties assessments, such as closed-loop stability, are still better understood under this formulation, as it will be shown in later chapters.

% 3 - Controller Design
% ---------------------------------------------------------------
\clearpage
\chapter{Controller Synthesis}

This chapter discusses the general results and properties for the design of dynamical controllers, focusing on feedback architectures. The devices are motivated and formulated using the State-Space model for dynamical systems, so the feedback is performed on the state response rather than the system output. For this reason, the results in this section focus on these equations, where the output equations is made implicit.

\section{State Feedback Controllers}

In modern control theory, advances in computer performance and in the methods themselves have made the design of controllers using State-Space models feasible for real-world applications. This is usually desirable since, as shown in the latter chapter, these kind of models provides a practical solution to understand dynamical system response and properties, so it is natural to want a controller design technique that accounts for that representation. The most basic, yet most popular, feedback controller used in those settings is the \textit{Full-State Feedback Controller}, defined below. 

\begin{boxed-definition}{Full-State Feedback}
	Given a linear system in State-Space representation, the input signal $\bm{u}(t)$ is calculated through feedback of the states as application of the linear control law:
	\begin{equation}
		\bm{u(t)} = \pi(\bm{r}, \bm{x}, t) = \bm{r}(t) - \bm{K} \bm{x}(t)
	\end{equation}
	
	\noindent where $\bm{r} : \mathbb{R} \rightarrow \mathbb{R}^{n}$ is a state reference signal that the system must follows and $\bm{K} \in \mathbb{R}^{r \times n}$ is the \textit{feedback gain matrix}.
\end{boxed-definition}

The control law $\pi(.)$ is linear and time-invariant, which makes the analysis of the closed-loop system similar to the one used in open-loop configurations. A schematic of the closed-loop system is shown at Fig. \ref{fig:feedback01}. Of course, this is a choice of control law, and feedback controllers can also be defined using nonlinear or time-dependent functions. 

[img]

Notice that this new definition for the calculation of $\bm{u}(t)$ allows for the following closed-loop representation of the system:
\begin{align}
\begin{split}
	\dot{\bm{x}}(t) &= \bm{A} \bm{x}(t) + \bm{B} \left( \bm{r}(t) - \bm{K} \bm{x}(t) \right) \\
	\dot{\bm{x}}(t) &= \left( \bm{A} - \bm{B} \bm{K} \right) \bm{x}(t) + \bm{B} \bm{r}(t)
\end{split}
\end{align}

From this is clear that the inclusion of a feedback controller in the loop is equivalent to transform an open-loop system into a new system $(\bm{A}_{cl}, \bm{B})$, with $\bm{A}_{cl} = \bm{A} - \bm{B} \bm{K}$, whose manipulated variables is a reference signal $\bm{r}(t)$ but the controlled variables are still the same. Since $\bm{K}$ is an arbitrary matrix, it is possible to change the behavior of the closed-loop system, and consequently the controlled variables response, by designing this matrix. To understand better the capabilities of the state feedback, consider the following theorems.

%\begin{boxed-theorem}
%	Given any matrix $\bm{K} \in \mathbb{R}^{r \times n}$, the closed-loop system described by matrices $(\bm{A}-\bm{B}\bm{K}, \bm{B})$ is controllable if and only if the open-loop system $(\bm{A}, \bm{B})$ is controllable.
%\end{boxed-theorem} 
%
%\begin{proof}
%	From definition, the controllability matrix $\bm{\mathcal{C}}_{cl}$ of the closed-loop system is given by:
%	\begin{equation}
%		\bm{\mathcal{C}}_{cl} = \begin{bmatrix} \bm{B} & (\bm{A}-\bm{B}\bm{K})\bm{B} & (\bm{A}-\bm{B}\bm{K})^2 \bm{B} & \cdots & (\bm{A}-\bm{B}\bm{K})^{n-1} \bm{B} \end{bmatrix}
%	\end{equation}
%	
%	It is possible to factorize this matrix as:
%	\begin{equation}
%		\bm{\mathcal{C}}_{cl} = \bm{\mathcal{C}} 
%		\begin{bmatrix} \bm{I} & -\bm{K} \bm{B} & -\bm{K} (\bm{A} - \bm{B}\bm{K})\bm{B} & \cdots & -\bm{K} (\bm{A} - \bm{B}\bm{K})^{n-3}\bm{B} & -\bm{K} (\bm{A} - \bm{B}\bm{K})^{n-2}\bm{B} \\ 
%		0 & \bm{I} & -\bm{K} \bm{B} & \cdots & -\bm{K} (\bm{A} - \bm{B}\bm{K})^{n-4}\bm{B} & -\bm{K} (\bm{A} - \bm{B}\bm{K})^{n-3}\bm{B} \\ 
%		\vdots & \vdots & \vdots & \iddots & \vdots & \vdots \\
%		0 & 0 & 0 & \cdots & -\bm{K} \bm{B} & -\bm{K} (\bm{A} - \bm{B}\bm{K})\bm{B} \\
%		0 & 0 & 0 & \cdots & \bm{I} & -\bm{K} \bm{B} \\
%		0 & 0 & 0 & \cdots & 0 & \bm{I} \end{bmatrix}
%	\end{equation}
%	
%	Notice that the multiplication $\bm{K} \bm{B} \in \mathbb{R}^{1 \times r}$ and $\bm{I} \in \mathbb{R}^{r \times r}$. Since the rightmost matrix is upper-triangular, and has no zeros in the main diagonal, the rank of $\bm{\mathcal{C}}$ and $\bm{\mathcal{C}}_{cl}$ are equal. Therefore, if $\bm{\mathcal{C}}$ has full row rank, so has $\bm{\mathcal{C}}_{cl}$, proving the statement.
%\end{proof}

\begin{boxed-theorem}{(Controller Canonical Form)} \label{th:controlCanon}
	If a SISO system in State-Space representation is controllable, then by applying the transformation $\bm{z}(t) = \bm{P}\bm{x}(t)$, for a matrix $\bm{P}$ calculated as the inverse of:
	\begin{equation}
		\bm{P}^{-1} = \bm{\mathcal{C}} \begin{bmatrix}
		1 & \alpha_1 & \cdots  & \alpha_{n-1} \\
		0 & 1 & \cdots & \alpha_{n-2} \\
		\vdots & \vdots & \ddots & \vdots \\
		0 & 0 & \cdots &1
		\end{bmatrix}
	\end{equation}
	
	\noindent where $[\alpha_1, \alpha_2, ..., \alpha_{n-1}]$ are the $n-1$ first coefficients of the characteristic polynomial $\Delta(s) = det(s\bm{I} - \bm{A})$, the resulting representation is in the \textit{controller canonical form} given as:
	\begin{align}
	\begin{cases}
		\dot{\bm{z}}(t) = \begin{bmatrix}
			-\alpha_1 & -\alpha_2 & \cdots & -\alpha_{n-1} & -\alpha_n \\
			1 & 0 & \cdots & 0 & 0 \\
			\vdots & \vdots & \ddots & \vdots & \vdots \\
			0 & 0 & \cdots & 1 & 0 
		\end{bmatrix} \bm{z}(t) + \begin{bmatrix}
			1 \\ 0 \\ \vdots \\ 0
		\end{bmatrix} u(t) \\
		y(t) = \begin{bmatrix} \beta_1 & \beta_2 & \cdots & \beta_n \end{bmatrix} \bm{z}(t)
	\end{cases}
	\end{align}
\end{boxed-theorem} 

Details for the proof of this theorem can be found in \textbf{[reference]}. An equivalent result can be proved for MIMO systems \textbf{[reference]}, but the result is very verbose and does not highlight the main results for the state-feedback. Using the canonical form just presented, it is possible to discuss a strong result for the state feedback controller.

\begin{boxed-theorem}{(Pole-Placement Method)} \label{th:polePlace}
	If a system in State-Space representation is controllable, then by state feedback using a gain matrix $\bm{K} \in \mathbb{R}^{r \times n}$ the eigenvalues of $\bm{A}_{cl}=\bm{A}-\bm{B}\bm{K}$, the poles of the closed-loop system, can arbitrarily be assigned anywhere in the complex plane, given that complex conjugate eigenvalues are assigned in pairs.
\end{boxed-theorem} 

\begin{proof}
	Consider that the system is controllable. In this case, it can be converted to the controller canonical form of Theorem \ref{th:controlCanon}. Substituting $\bm{z}(t) = \bm{P} \bm{x}(t)$ results in the following control law for the state feedback:
	\begin{equation}
		u(t) = r(t) - \bm{K} \left( \bm{P}^{-1} \bm{z}(t) \right) = r(t) - \tilde{\bm{K}} \bm{z}(t)
	\end{equation}
	
	Applying the state feedback, the transformed closed-loop is given by:
	\begin{equation} \label{eq:fdbckContrCanon}
	\tilde{\bm{A}}_{cl} = \bm{P} (\bm{A} - B \bm{K}) \bm{P}^{-1} = \bm{P} \bm{A} \bm{P}^{-1} - \bm{P} B \bm{K} \bm{P}^{-1} = \tilde{\bm{A}} - \tilde{B} \tilde{\bm{K}}
	\end{equation}	 
	
	From Theorem \ref{th:simTrans01} it is known that $\bm{A}_{cl}$ and $\tilde{\bm{A}}_{cl}$ shares the same set of eigenvalues, and, therefore, the same characteristic equations. Consider this characteristic equation in the form:
	\begin{equation}
		\Delta(s) = det(s\bm{I} - \bm{A}) = s^n + \alpha_1 s^{n-1} + \alpha_2 s^{n-2} + \cdots + \alpha_{n-1} s + \alpha_n
	\end{equation}
	
	Given a desired a set of coefficients $[\tilde{\alpha}_1, \tilde{\alpha}_2, ..., \tilde{\alpha}_n]$ of a characteristic polynomial whose roots are the desired closed-loop eigenvalues, define the transformed feedback gain matrix as:
	\begin{equation}
		\tilde{\bm{K}} = \begin{bmatrix} \tilde{\alpha}_1 - \alpha_1 & \tilde{\alpha}_2 - \alpha_2 & \cdots & \tilde{\alpha}_n - \alpha_n \end{bmatrix}
	\end{equation}
	
	Plugging this in \eqref{eq:fdbckContrCanon}, it is easy to see that the resulting representation is:
	\begin{align} \label{eq:SSFdbckControlCanon}
	\begin{cases}
		\dot{\bm{z}}(t) = \begin{bmatrix}
			-\tilde{\alpha}_1 & -\tilde{\alpha}_2 & \cdots & -\tilde{\alpha}_{n-1} & -\tilde{\alpha}_n \\
			1 & 0 & \cdots & 0 & 0 \\
			\vdots & \vdots & \ddots & \vdots & \vdots \\
			0 & 0 & \cdots & 1 & 0 
		\end{bmatrix} \bm{z}(t) + \begin{bmatrix}
			1 \\ 0 \\ \vdots \\ 0
		\end{bmatrix} u(t) \\
		y(t) = \begin{bmatrix} \beta_1 & \beta_2 & \cdots & \beta_n \end{bmatrix} \bm{z}(t)
	\end{cases}
	\end{align} 
	
	\noindent whose characteristic polynomial is now described by the designed coefficients to yield the desirable eigenvalues. Since $\tilde{\bm{A}}_{cl}$ and $\bm{A}_{cl}$ shares the same set of eigenvalues, it is concluded that it is possible to assign the system poles directly through matrix $\tilde{\bm{K}}$.
\end{proof}

Notice, from that procedure, that an ``original" feedback gain matrix can be obtained as $\bm{K} = \tilde{\bm{K}} \bm{P}$ and still yield the same eigenvalues assignment directly in $\bm{A}_{cl}$ (since $\bm{P}$ is just a linear transformation). This theorem has the direct result that, under full-state feedback, the transient response of a linear system can be completely determined by including a controller, which is described by this matrix $\bm{K}$. This result is still preserved for MIMO systems, although the design of $\bm{K}$ is not so straightforward since it is not unique for a desired set of eigenvalues in this case \textbf{[reference]}. 

Using the parameters from Definition \ref{def:responseParameters}, the positions of the closed-loop system poles can be evaluated given desirable operations, and the matrix $\bm{K}$ can be hand-designed to meet these requirements. This method is known as the \textit{Pole-Placement method} for control synthesis. The algorithm below summarizes a simple procedure of designing an appropriate feedback gain matrix given desirable pole positions.

\begin{algorithm}[ht]
	\caption{Pole-Placement Method for SISO Systems}	
	\SetAlgoLined
	\SetKwInOut{Input}{Input}
	\SetKwInOut{Output}{Output}
	
	\Input{state-space model $(\bm{A}, B)$ and a set of $n$ desired eigenvalues $\bm{\lambda}^*$.}
	\Output{feedback gain matrix $\bm{K}$.}
	\vskip0.25cm
	
	Calculate $[\alpha_1, \alpha_2, ..., \alpha_n]$ as the coefficients of the polynomial $\Delta(s) = det(s\bm{I} - \bm{A})$;
	
	Let $\bm{P}^{-1} = \begin{bmatrix} B & \bm{A} B & \bm{A}^2 B & \cdots & \bm{A}^{n-1} B \end{bmatrix} \begin{bmatrix}
		1 & \alpha_1 & \cdots  & \alpha_{n-1} \\
		0 & 1 & \cdots & \alpha_{n-2} \\
		\vdots & \vdots & \ddots & \vdots \\
		0 & 0 & \cdots &1
		\end{bmatrix}$;
	
	Let $\bm{P} = \left( \bm{P}^{-1} \right)^{-1}$;
	
	Calculate $[\tilde{\alpha}_1, \tilde{\alpha}_2, ..., \tilde{\alpha}_n]$ as the coefficients of the polynomial $\Delta_{cl}(s) = \prod_{i=1}^n (s - \lambda^*_i)$;
	
	Let $\tilde{\bm{K}} = \begin{bmatrix} \alpha_1 - \tilde{\alpha}_1 & \alpha_2 - \tilde{\alpha}_2 & \cdots & \alpha_n - \tilde{\alpha}_n \end{bmatrix}$;
	
	Return $\bm{K} = \tilde{\bm{K}} \bm{P}$
\end{algorithm} 

Albeit being a simples formula, this method can be used in several applications to yield controllers capable of matching performance requisites. Of course, the designer must take into account that, besides the eigenvalue assignment allows for the whole complex plane, a careless choice of eigenvalues could result in unpractical controllers, with very aggressive or oscillatory input signals. For this reason, it is necessary some knowledge of the instruments limits before designing the matrix $\bm{K}$.

[example]

[fig]

\section{Regulation and Reference Tracking}

When discussing controller synthesis it is also necessary to account for which objective this device is expected to fulfill. In this case, there are two main classifications of controllers based on the operation that they impose to the system: regulators and tracking (or servo) controllers. In the case of state-feedback, these two classes of controllers differs only by what type of reference signal $\bm{r}(t)$, for an operation in a time interval $t \in [t_0, t_f]$, the system is expected to follow. The following statements gives a formal definition of a controller for regulation:

\begin{boxed-definition}{(Regulator)} \label{def:regulator}
	If a state-feedback controller has to make a system follows the reference $\bm{r}(t) \equiv 0$, as $t \to \infty$, it is said to be a \textit{regulator}. In this case, the closed-loop state equation and equivalent solutions reduces to the following:
		\begin{align}
	\begin{matrix*}[l]
	\textbf{State Equation:} \hfill & & & \textbf{Lagrange solution:} \hfill \\
	\dot{\bm{x}}(t) = \left( \bm{A} - \bm{B} \bm{K} \right) \bm{x}(t)  & & &
	\bm{x}(t) = e^{(\bm{A} - \bm{B} \bm{K}) t} \bm{x}(t_0) \hfill
	\end{matrix*}
	\end{align}
\end{boxed-definition}

Of course, if the feedback gain matrix impose that all poles of the system are in the left-half plane, the closed-loop is stable and the natural response will eventually converge to zero (Theorem \ref{th:BIBOStab}). Therefore, all stable feedback controllers are able to impose regulation to a system, and the characteristics of the transient response can be fully determined by the matrix $\bm{K}$. These type of controllers are used to make systems goes from nonzero initial states to the zero-state $\bm{x}(t) = \bm{0}$ and stays there, meaning that the the controller can also be used to reject disturbances. Now, one may wonder if this operation is too restrictive in the sense that the zero-state is not the desirable state in many control objectives, as is the case of reactor systems: a zero-state means that no chemical substances are being produced. However, it is common to have linear systems that are 	linearized versions of nonlinear models, using the approximation from Theorem \ref{th:linearization}, meaning that the regulator actually is to impose $\Delta \bm{x}(t) = \bm{x}(t) - \bm{x}_o = \bm{0}$, i.e., drives the system to the steady-state operation point $\bm{x}_o$ and reject disturbances. For the sake of illustration, two regulators for the reactor system in \eqref{eq:isoSys02} are shown in Fig. \ref{fig:regulator01}, demonstrating how state-feedback can guarantee a specific constant production of chemical substances.

[fig]

In contrast, the control objective could be to follow a non-constant signal $\bm{r}(t)$, or to follow a constant signal different from the zero-state, giving rise to the tracking or servomechanism controllers. A more complete discussion is needed in such cases, since there is a possibility that state-feedback is not capable of actually performing this tracking. To understand this question, consider, for simplicity, that the system must follow a constant reference $\bm{r}(t) = a$. Consider, now, an Input-Output conversion of a closed-loop SISO State-Space model, which from \eqref{eq:SSFdbckControlCanon} directly results in the transfer function:
\begin{equation}
	G(s) = \cfrac{Y(s)}{R(s)} = \cfrac{\beta_1 s^{n-1} + \beta_2 s^{n-2} + \cdots + \beta_{n-1} s + \beta_n}{s^{n} + \tilde{\alpha}_1 s^{n-1} + \tilde{\alpha}_2 s^{n-2} + \cdots + \tilde{\alpha}_{n-1} s + \tilde{\alpha}_n}
\end{equation}

From that formulation it is clear that the response $Y(s) = G(s)R(s)$ will yield a perfect tracking if $G(s) = 1$. Moreover, if the system has to track asymptotically track this reference, this operation can be evaluated as time $t \to \infty$ or, equivalently, as the frequency $s \to 0$. Plugging this limit in the transfer function implies that a perfect tracking is always possible if $G(0) = \beta_n /  \tilde{\alpha}_n = 1$, which is not guaranteed a priori. A possible solution is to transform the reference with as $\tilde{r}(t) = F r(t)$, so that $Y(s) = G(s)\tilde{R}(s) = G(s) F R(s)$, resulting that:
\begin{equation}
	G(0) F = 1 \Rightarrow F = \cfrac{\tilde{\alpha}_n}{\beta_n}
\end{equation}

\noindent which allows for perfect asymptotically tracking in all cases but when $\beta_n = 0$. This same reasoning can easily be extended to MIMO systems (the gain $F$ turns into a matrix). In the case of non-constant references, the same intuition could still be used, but the analysis and design of $F$ becomes more complex \textbf{[reference]}. This, however, allows for the definition of tracking controllers.

\begin{boxed-definition}{(Tracking Controllers)} \label{def:tracking}
	If a state-feedback controller has to make a system track any step reference $\bm{r}(t) \neq \bm{0}$, as $t \to \infty$, it is said to be a \textit{tracking controller}. In this case, one has to apply the \textit{feedforward gain} $F$ to correct the reference as $\tilde{\bm{r}}(t) = \bm{F}\bm{r}(t)$, resulting in the following closed-loop state equation and equivalent solution:
	\begin{align}
	\begin{matrix*}[l]
	\textbf{State Equation:} \hfill & & \textbf{Lagrange solution:} \hfill \\
	\dot{\bm{x}}(t) = \left( \bm{A} - \bm{B} \bm{K} \right) \bm{x}(t) + \bm{B} \bm{F} \bm{r}(t)  & &
	\bm{x}(t) = e^{(\bm{A} - \bm{B} \bm{K}) t} \bm{x}(t_0) + \int_{t_0}^{t} e^{(\bm{A} - \bm{B} \bm{K}) (t - \tau)} \bm{B} \bm{F} \bm{r}(\tau) d \tau \hfill
	\end{matrix*}
	\end{align}
\end{boxed-definition}

Despite being a feasible solution, there are still problems with this definition of tracking controllers. For instance, if the system is subject to a \textit{constant additive disturbance}, which as not anticipated in the model, the resulting operation will not yield a perfect tracking. The simulations in Fig. \ref{fig:tracking01} shows the three cases for a tracking controller given the feedforward correction of the reference.

[fig]

The problem of the previous formulation for a tracking controller is that it is not robust to actions that happens outside the model. A direct cause of this is the fact that the feedforward gain $\bm{F}$ does not benefits from the real-time corrective action of the state-feedback, but rather is calculated \textit{off-line} using the model properties. Therefore, a way to ensure a more robust operation could be to insert real-time information about the tracking error directly to the feedback corrective action. With this motivation, a new formulation of the tracking controller is given below.

\begin{boxed-definition}{(Robust Tracking Controllers)} \label{def:robustTracking}
	Given a State-space system and augmented state $\bm{x}_a(t)$ defined as:
	\begin{equation}
		\bm{x}_a(t) = \int_{0}^{t} \bm{r}(\tau) - \bm{C} \bm{x}(\tau) d\tau \Longrightarrow \dot{\bm{x}}_a(t) = \bm{r}(t) - \bm{C} \bm{x}(t)
	\end{equation}
	
	A robust tracking (or servo) controller, defined by the gain $\tilde{\bm{K}} = \begin{bmatrix} \bm{K} & \bm{K}_a \end{bmatrix}$, is the one which operates on the following augmented version of the original system:
	\begin{align} \label{eq:augmentedSystem}
	\begin{cases}
		\begin{bmatrix}
			\dot{\bm{x}}(t) \\
			\dot{\bm{x}}_a(t)
		\end{bmatrix} &= \begin{bmatrix}
			\bm{A} + \bm{B} \bm{K} & \bm{B} \bm{K}_a \\ - \bm{C} & \bm{0}
		\end{bmatrix} \begin{bmatrix}
			\bm{x}(t) \\
			\bm{x}_a(t)
		\end{bmatrix} + \begin{bmatrix}
			\bm{0} \\
			\bm{1}
		\end{bmatrix} \bm{r}(t)
		\\
		\hfill \bm{y}(t) &= \begin{bmatrix}
			\bm{C} & \bm{0}
		\end{bmatrix} \begin{bmatrix}
			\bm{x}(t) \\
			\bm{x}_a(t)
		\end{bmatrix}
	\end{cases}
	\end{align}
	
	or, equivalently:
	\begin{align}
	\begin{cases}
		\tilde{\bm{x}}(t) = \tilde{\bm{A}} \tilde{\bm{x}}(t) + \tilde{\bm{B}} \tilde{\bm{r}}(t) \\
		\bm{y}(t) = \tilde{\bm{C}} \tilde{\bm{x}}(t) \hfill
	\end{cases}
	\end{align}
\end{boxed-definition}

[fig]

Since the augmented state $\bm{x}_a(t)$ represents an integral of the tracking error until a time $t$, this formulation is usually characterized as imposing ``integral action" to the controller. The schematic at Fig. \ref{fig:tracking02} illustrates how an integrator can be included to the block diagram of the control loop. Therefore, it must be discussed if the new gain $\tilde{\bm{K}}$ still preserves the eigenvalue assignment property of regular state-feedback gains, so that this imposed regulator would work.

\begin{boxed-theorem}
	If the system described by matrices $(\bm{A}, \bm{B})$ is controllable and its transfer functions $\bm{G}(s)$ has no zero at $s = 0$, then the eigenvalues of the augmented matrix $\tilde{\bm{A}}$ can be assigned arbitrary by the feedback gain $\tilde{\bm{K}}$.
\end{boxed-theorem}

\begin{proof}
	Without loss of generality, consider a SISO controllable system. After the augmentation, the controllability matrix $\tilde{\bm{\mathcal{C}}}$ is calculated as:
	\begin{align}
	\begin{split}
		\tilde{\bm{\mathcal{C}}} &= \begin{bmatrix}
			B & \bm{A} B & \bm{A}^2 B & \bm{A}^3 B & \cdots & \bm{A}^{n-1} B \\
			0 & -C B & -C \bm{A} B & -C \bm{A}^2 B & \cdots & -C \bm{A}^{n-2} B
		\end{bmatrix} \\
		&=
			\begin{bmatrix}
				1 & -\alpha_1 & -\alpha_1^2 - \alpha_2 & -\alpha_1(\alpha_1^2 - \alpha_2) + \alpha_2 \alpha_1 - \alpha_3 & \cdots & \Delta_2(\alpha_1,...,\alpha_n) \\
				0 & 1 & -\alpha_1 & -\alpha_1^2 - \alpha_2  & \cdots & \Delta_3(\alpha_1,...,\alpha_n) \\
				0 & 0 & 1 & -\alpha_1  & \cdots & \Delta_1(\alpha_1,...,\alpha_n) \\
				0 & 0 & 0 & 1 &  \cdots & \Delta_4(\alpha_1,...,\alpha_n) \\
				\vdots & \vdots & \vdots & \vdots & \ddots & \vdots \\
				0 & 1 & -\beta_1 & -\beta\alpha_1 - \alpha_2  & \cdots & \Delta_n(\alpha_1,...,\alpha_n) \\
			\end{bmatrix}
	\end{split}
	\end{align}
	
	\noindent where $\Delta_i(\alpha_1,...,\alpha_n)$ is a polynomial created to save space in this representation. By inspection of this matrix, it is possible to discover a pattern between the rows. Since elementary operations between the rows ${r_1, r_2, ..., r_n}$ doesn't change the matrix row rank, the last row of the matrix can be transformed as $r_n = r_n + r_{n-1}\beta_{n-2} + r_{n-2}\beta_{n-3} + \cdots + r_{2}\beta_{1}$. The result is the triangular matrix in the form:
	\begin{align}
	\begin{split}
		\tilde{\bm{\mathcal{C}}} &= 
			\begin{bmatrix}
				1 & -\alpha_1 & -\alpha_1^2 - \alpha_2 & -\alpha_1(\alpha_1^2 - \alpha_2) + \alpha_2 \alpha_1 - \alpha_3 & \cdots & \Delta_2(\alpha_1,...,\alpha_n) \\
				0 & 1 & -\alpha_1 & -\alpha_1^2 - \alpha_2  & \cdots & \Delta_3(\alpha_1,...,\alpha_n) \\
				0 & 0 & 1 & -\alpha_1  & \cdots & \Delta_1(\alpha_1,...,\alpha_n) \\
				0 & 0 & 0 & 1 &  \cdots & \Delta_4(\alpha_1,...,\alpha_n) \\
				\vdots & \vdots & \vdots & \vdots & \ddots & \vdots \\
				0 & 0 & 0 & 0  & \cdots & \beta_n \\
			\end{bmatrix}
	\end{split}
	\end{align}
	
	Since $\bm{G}(s)$ has no zeros at $s = 0$, then $\beta_n \neq 0$, meaning that $\tilde{\bm{\mathcal{C}}}$ is nonsingular and, therefore has full row rank. This concludes that the augmented system $(\tilde{\bm{A}}, \tilde{\bm{B}})$ is controllable and, from Theorem \ref{th:polePlace}, the eigenvalues of $\tilde{\bm{A}}$ can be assigned anywhere in the complex plane.
\end{proof}

A possible intuition on how this system performs the robust tracking and disturbance rejection can be taken from the fact that the first row of \eqref{eq:augmentedSystem} is basically a regulator, albeit from the term $\bm{B} \bm{K}_a \bm{x}_a(t)$. Because of this, a control action will always be applied whenever $\bm{x}_a(t) \neq \bm{0}$, i.e., when there is an error between the reference and the output signal, following the direction that minimizes this difference. When $\bm{x}_a(t) = \bm{0}$, this equation reduces to a simple regulator, and the disturbances are expected to be rejected. A more quantitative analysis on why this controller yields both robust tracking and disturbance rejection can be found in \textbf{[reference]}. Some simulations of closed-loop systems for tracking are shown in Fig. \ref{fig:tracking03} for a non-constant reference.

[fig]


\section{Deterministic State Observers}

Until now, the state feedback was discussed in the perspective that the device has direct to the real value of all states of the system. This is assumption is actually unrealistic, since the states are only observed through the output signal $\bm{y}(t)$, that maps the states through the matrix $\bm{C}$, which itself is not assumed to be always equal to the identity matrix. In practice, this means that some states could not be measured, due to technical difficulties or economic reasons, or that the instrumentation available is not perfect, and the observations are prone to deviate from the real value. In reactor systems, for instance, is hard to measure the actual value of chemical compounds concentrations in small scales, and the measuring process itself could be very slow or simply unpractical in operational conditions \textbf{[reference]}. Since the state-vector is necessary for the state-feedback to compute the input to the system, this section discusses how to develop devices that can reconstruct information about the states from the observations of the available sensor.

A device that generates a state-vector $\bm{x}(t)$ from the output signal $\bm{y}(t)$ is known as \textit{state observer}, or \textit{state estimator} in some cases. Amongst the several possible configurations, a very practical and popular one is the \textit{Luenberger observer}, which is defined below.

\begin{boxed-definition}{(Luenberger Observer)} \label{def:luenberger}
	Given a system in State-Space with output signal $\bm{y}(t) : \mathbb{R} \rightarrow \mathbb{R}^p$ and a observer gain $\bm{L} \in \mathbb{R}^{n \times p}$, the estimated state-vector $\hat{\bm{x}}(t)$ is represented by the observer system:
	\begin{equation}
		\dot{\hat{\bm{x}}}(t) = \bm{A} \hat{\bm{x}}(t) + \bm{B} \bm{u}(t) + \bm{L} \left( \bm{y}(t) - \bm{C} \hat{\bm{x}}(t) \right)
	\end{equation}
	
	\noindent or, equivalently:
	\begin{equation} \label{eq:luenberger02}
		\dot{\hat{\bm{x}}}(t) = \left( \bm{A} - \bm{L} \bm{C} \right) \hat{\bm{x}}(t) + \bm{B} \bm{u}(t) + \bm{L} \bm{y}(t)
	\end{equation}
\end{boxed-definition}

The observer system works as a parallel system that is simulated alongside with the actual system, as illustrate in Fig. \ref{fig:luenberger01}. The expected result is that the observer yields $\hat{\bm{x}}(t) = \bm{x}(t)$, as time $t \to \infty$. Alternatively, it is possible to create a variable $\bm{e}(t) = \bm{x}(t) - \hat{\bm{x}}(t)$ such that, using \eqref{eq:luenberger02}:
\begin{align}
\begin{split}
	\dot{\bm{e}} &= \bm{x} - \hat{\bm{x}} \\ 
		&= \left( \bm{A} \bm{x} + \bm{B} \bm{u} \right) - \left( \left( \bm{A} - \bm{L} \bm{C} \right) \hat{\bm{x}} + \bm{B} \bm{u} + \bm{L} \bm{C} \bm{x} \right) \\
		&= \left( \bm{A} - \bm{L} \bm{C} \right) \bm{x} - \left( \bm{A} - \bm{L} \bm{C} \right) \hat{\bm{x}} \\
		&= \left( \bm{A} - \bm{L} \bm{C} \right) \left( \bm{x} - \hat{\bm{x}} \right) \\
		&= \left( \bm{A} - \bm{L} \bm{C} \right) \bm{e}
\end{split}
\end{align}

\noindent which implies that the observer asymptotically tracks the actual state-vector if $\bm{e}(t) = \bm{0}$ as $t \to \infty$. Analyzing the equation above, it is intuitive to notice that this result can be guaranteed if all the eigenvalues of matrix $\bm{A}_{obs} = \bm{A} - \bm{L} \bm{C}$ have negative real parts. The following theorem relates this statement with the choice of a gain $\bm{L}$.

[fig]

\begin{boxed-theorem}
	If a system in State-Space representation is observable, then by a Luenberger observer with gain matrix $\bm{L} \in \mathbb{R}^{n \times p}$ the eigenvalues of $\bm{A}_{obs} = \bm{A} - \bm{L} \bm{C}$ can arbitrarily be assigned anywhere in the complex plane, given that complex conjugate eigenvalues are assigned in pairs.
\end{boxed-theorem} 

\begin{proof}
	Consider that a State-Space with matrices $(\bm{A}, \bm{C})$ is observable. From the Duality Theorem \textbf{[reference]} if the pair $(\bm{A}, \bm{C})$ is observable then the pair $(\bm{A}^T, \bm{C}^T)$ is controllable. In this case, it is possible to design 	a gain matrix $\bm{K}$ to assign the eigenvalues of $\tilde{\bm{A}}_{obs} = \bm{A}^T - \bm{C}^T \bm{K}$ in any desirable points in the complex space. Since the eigenvalues of a matrix are invariant to the transpose operation, the design of $K$ can also place the eigenvalues of the matrix $(\tilde{\bm{A}}_{obs})^T = \bm{A} - \bm{K}^T \bm{C}$. Therefore, making $\bm{L} = \bm{K}^T$ establishes the theorem.
\end{proof}

The procedure stated in this proof presents the similarities between closed-loop observers, such as the Luenberger observer, and closed-loop controllers as the state-feedback. Basically, the same design considerations that concerns state-feedback are important in the design of the observer gain $\bm{L}$. For instance, the eigenvalues of $\tilde{\bm{A}}_{obs} = \bm{A}^T - \bm{C}^T \bm{K}$ can be assigned such that the time evolution of the error $\bm{e}(t)$ has a desirable time constant, damping coefficient or natural frequency. In conclusion, the state-vector $\bm{x}(t)$, in this conditions, can be reconstructed by using a observer gain that guarantees that each eigenvalue of $\bm{A}_{obs}$ is on the right-half side of the complex plane. Some simulations of a Luenberger observer for different values of $\bm{L}$ are shown in Fig. \ref{fig:observer01}, considering a system in open-loop conditions.

[img]

As stated before, one of the main reasons to develop an observer is to allows for state-feedback controllers to access the values of the state-vector in order to calculate an appropriate action to follow the reference signal. If a controller can only access the estimated state-vector $\tilde{\bm{x}}(t)$, it is possible to define a State-Space formulation for a closed-loop based on feedback from estimated states.

\begin{boxed-definition}{(Feedback from Estimated States)} \label{def:fdbckLuenberger}
	Given a system in State-Space representation whose state-vector is reconstructed from a Luenberger observer of gain $\bm{L} \in \mathbb{R}^{n \times p}$ and input signal is calculated through state-feedback with gain $\bm{K} \in \mathbb{R}^{n \times r}$, its time evolution can be represented through the model:
	\begin{align} \label{eq:fdbckLuenberger01}
	\begin{cases}
		\dot{\bm{x}}(t) = \bm{A} \bm{x}(t) - \bm{B} \bm{K} \hat{\bm{x}}(t) + \bm{B} \bm{r}(t) \\
		\dot{\hat{\bm{x}}}(t) = \left(\bm{A} - \bm{L} \bm{C} - \bm{B} \bm{K} \right) \hat{\bm{x}}(t) + \bm{B} \bm{r}(t) + \bm{L} \bm{y}(t) 
	\end{cases}
	\end{align}
\end{boxed-definition} 

A schematic for this formulation of feedback from estimated states is shown Fig. \ref{fig:observer02}. In fact, this schematic summarizes several different control architectures that includes both feedback action and state estimation, and it will be the reference whenever this work mentions physical control loops and instrumentation.

[fig]

Notice, now, that the formulation just defined imposes that the dynamics of the estimated state $\hat{\bm{x}}(t)$ is dependent both in $\bm{K}$ and $\bm{L}$, which are arbitrary matrices chosen by the control designer. This leads to the possible conclusion that the choice of $\bm{K}$ is now restricted by the effect that it will produce in the choice of $\bm{L}$, which is not true. The following theorem, known as the Separation Principle \textbf{[reference]}, states that design of these two gains are independent.

\begin{boxed-theorem}{(Separation Principle)} \label{th:separationPrinciple}
	Given a system in State-Space with a Luenberger observer of gain $\bm{L}$ and state-feedback controller of gain $\bm{K}$, the closed-loop eigenvalues contributions of $(\bm{A} - \bm{B}\bm{K})$ are independent from those of $(\bm{A} - \bm{L}\bm{C})$.
\end{boxed-theorem}

\begin{proof}
	Consider a feedback from estimated states as defined in \eqref{eq:fdbckLuenberger01}. That controller-estimator system can be rewritten as a single state equation:
	\begin{equation}
	\begin{bmatrix} \dot{\bm{x}} \\ \dot{\hat{\bm{x}}}	\end{bmatrix}
	=
	\underbrace{\begin{bmatrix}
		\bm{A} & - \bm{B} \bm{K} \\
		\bm{L} \bm{C} & \bm{A} - \bm{L} \bm{C} - \bm{B} \bm{K}
	\end{bmatrix}}_{\tilde{\bm{A}}} \begin{bmatrix} \bm{x} \\ \hat{\bm{x}} \end{bmatrix}
	+
	\underbrace{\begin{bmatrix}	\bm{B} \\ \bm{B} \end{bmatrix}}_{\tilde{\bm{B}}} \bm{r}
\end{equation} 

Consider, now, the following similarity transformation $\bm{z}(t) = \bm{P} \bm{x}(t)$:
\begin{equation}
	\underbrace{\begin{bmatrix}
		\bm{I} & 0 \\ \bm{I} & -\bm{I}
	\end{bmatrix}}_{\bm{P}} \begin{bmatrix}
		\bm{x} \\ \hat{\bm{x}}
	\end{bmatrix} = \begin{bmatrix}
		\bm{x} \\ \bm{x} - \hat{\bm{x}}
	\end{bmatrix} = \begin{bmatrix}
		\bm{x} \\ \bm{e}
	\end{bmatrix} 
\end{equation}

Since $\bm{P} = \bm{P}^{-1}$, and this is a valid similarity transformation that does not alters the system eigenvalues, the equivalent system for state $\bm{z}(t)$ is obtained as:
\begin{equation}
	\begin{bmatrix} \dot{\bm{x}} \\ \dot{\bm{e}}	\end{bmatrix}
	=
	\begin{bmatrix}
		\bm{A} - \bm{B} \bm{K} & - \bm{B} \bm{K} \\
		\bm{0} & \bm{A} - \bm{L} \bm{C}
	\end{bmatrix} \begin{bmatrix} \bm{x} \\ \bm{e} \end{bmatrix}
	+
	\begin{bmatrix}	\bm{B} \\ \bm{0} \end{bmatrix} \bm{r}
\end{equation} \vskip0.2cm

Since the matrix obtained is block triangular, it is possible to conclude that the system in such configuration has eigenvalues that are contributions from the eigenvalues of $\left( \bm{A} - \bm{B} \bm{K} \right)$ and $\left( \bm{A} - \bm{L} \bm{C} \right)$ separately.
\end{proof}

The Separation Principle is a nice results that further motivates the topology of Fig. \ref{fig:observer02}, since it explicitly states that the design of the controller and the state observer can be done separately. Thus, any structure that obeys the state feedback formulation can be used as a controller and the same is valid for the observer device. In the next chapter, this result will be explored to motivate the use of more advanced control and state estimation techniques without having to redefine the analytical tools and intuitions built for traditional state-feedback controllers from pole-placement methods.

\section{Properties of State-Feedback Controllers}

The last section introduces the first considerations into applying state-feedback in real-world systems, given limitations on the instruments and uncertainty on the environment. Basically, a mathematical analysis of such closed-loop controllers allows for a full characterization of the system behavior, but the real system will exhibit a different response due to these limitations and, essentially, due to possible external disturbances. Therefore, it is desirable to anticipate these variations and discuss the properties of the closed-loop system in the sense of robustness and stability margins. Since this goal requires that the system response is evaluated in as general as possible context, the discussion in this section relies on frequency response analysis, which consider a broader class of input signals: sinusoids of any frequency. Consider the representation of closed-loop systems shown in Fig. \ref{fig:properties01}, which consists of a simplified version of Fig. \ref{fig:feedback01} in the Laplace frequency domain considering only the state response.

[fig - tickz]

Using block diagram algebra and Theorem \ref{th:SSToIO}, it is possible to associate a forward-path transfer function $\bm{G}_{f}(s)$ given as \textbf{[reference]}:
\begin{equation} \label{eq:fdbckForwardTrnsfer}
	\bm{G}_{f}(s) =  \bm{K}^{T} \left(s \bm{I} - \bm{A} \right)^{-1} B 
\end{equation}

Now, it is possible to characterize the properties of this quantity which relates the state-feedback gain $\bm{K}$ with the system disturbance $\bm{D}_x(s)$ and sensor disturbance $\bm{D}_e(s)$. To facilitate the definitions and discussion, the results are shown for single-state single-input systems, so $\bm{G}_f(s)$ is a scalar function, where the extension for $n > 1$ states is intuitive in most cases. The first property to be discussed, then, considers the stability of closed-loop feedback controllers. Consider the following closed-loop stability criterion from a Bode plot visualization.

\begin{boxed-theorem}{(Bode stability criterion)}
    Consider a feedback system whose closed-loop transfer function is defined, assuming perfect measuring sensors, as:
    \begin{equation}
        T(s) = \cfrac{K G(s)}{1 + K G(s)}
    \end{equation}
    
    The closed-loop system is said to be stable if $\| G(j \omega_{pc}) \leq 0 \|$, where $\omega_{pc}$ is the \textit{phase crossover frequency} obtained such that $\angle G(j \omega_{pc}) = -180º$.
\end{boxed-theorem}

Additionally, it is possible to define a stability criterion through a Nyquist diagram of the closed-loop system.

\begin{boxed-theorem}{(Nyquist criterion)}
    Consider a system with feedforward transfer function as defined in \eqref{eq:fdbckForwardTrnsfer}. Now, let $P$ and $Z$ be respectively the number of poles of $G_{f}(s)$ and zeros of $1 + G_{f}(s)$ that are in the right-half plane. In this case, the Nyquist contour shall clockwise encircle the point $s = -1$ a number of times $N$ such that $N = Z - P$.
\end{boxed-theorem}

A detailed proof of both criterion can be found in \textbf{[reference]}. The introduction of these stability evaluation techniques may seem redundant, given that the closed-loop BIBO stability can still be characterized from Theorem \ref{th:BIBOStab}, but their graphical nature allows for a easy understand of how disturbances can affect the stability of state-feedback systems. Consider, for instance, the Bode plot shown in Fig. \ref{fig:properties02} of a SISO version (excluding the second state) of the closed-loop system in Fig. \ref{fig:regulator01}, but submitted to a constant disturbance of $D_x = ?$. It is possible to see that the disturbance alone can produce a closed-loop unstable system. 

[fig]

Of course, not all disturbances observed in real operations are strong enough to bring any reasonable stable controller to an unstable condition. However, depending on the choice of the gain $\bm{K}$, some controllers can be more prone to these undesired problems than others. This motivates the discussion on stability margins.

\begin{boxed-definition}{(Stability Margins)}
    Given a closed-loop system with transfer function $T(s)$, the \textit{Gain Margin} ($GM$) is defined as a factor of how much a gain can be increased before the system becomes unstable, and is equated as:
    \begin{equation}
        GM = \cfrac{1}{|T(j \omega_{pc})|}
    \end{equation}
    
    \noindent where $\omega_{pc}$ is the phase crossover frequency such that $\angle T(j\omega_{pc}) = -180º$ (or when a Nyquist diagram crosses the point $s = -1$). In addition, the \textit{Phase Margin} ($PM$) is defined as how much phase lag can be added to $T(s)$ the system becomes unstable, and is equated as:
    \begin{equation}
        PM = \angle T(j \omega_{gc})
    \end{equation}
    
    \noindent where $\omega_{gc}$ is the \textit{gain crossover frequency} such that $\|T(j\omega_{gc})\| = 0 dB$. 
\end{boxed-definition}

An illustration of these definitions in both Bode plots and Nyquist diagrams is shown in Fig. \ref{fig:properties03}, for the same system as the last figure. If a closed-loop system has small Gain Margin, it is clear that its stability is not robust to gain uncertainties, while a small Phase Margins implies that its stability is not robust to time delay uncertainties in the control actions. Since high gain controllers are usually beneficial for performance requirements, it is clear that they also can lead to disastrous operations in uncertain environments \textbf{[reference]}. Therefore, the design of state-feedback gains must account for these quantities, and a trade-off between performance and robustness is always necessary for this formulation. 

% The first property to be discussed is that of sensitivity \textbf{[reference]}. 

% \begin{boxed-definition}{(Sensitivity)} \label{def:sensitivity}
% 	Consider a SISO system with state-feedback controller of gain $\bm{K}$ whose forward transfer function $\bm{G}_{f}(s)$ is given by \eqref{eq:fdbckForwardTrnsfer}. The \textit{sensitivity} function of this controlled system, denoted by the matrix $\bm{S}$, is defined as the transfer function from the system disturbances $\bm{D}_x(s)$ to the system total response, and it is equated as:
% 	\begin{equation}
% 		\bm{S}(s) = \left( \bm{I} + \bm{G}_f(s) \right)^{-1} = \cfrac{1}{1+G_f(s)}
% 	\end{equation}
	
% 	Additionally, the \textit{complementary sensitivity} function, denoted by the matrix $\bm{T}$, is defined as the transfer function from the reference to the state response, and it is equated as:
% 	\begin{equation}
% 		\bm{T}(s) = \left( \bm{I} + \bm{G}_f(s) \right)^{-1} \bm{G}_f(s) = \cfrac{G_f(s)}{1+G_f(s)}
% 	\end{equation}
% \end{boxed-definition}

% This quantity states an important trade-off that has to be made when the feedback gain $\bm{K}$ is applied to a system subject to disturbances. To understand this, notice that:
% \begin{equation}
% 	\bm{S} + \bm{T} = I
% \end{equation}

% Since both these quantities are transfer functions, a value of either one that is equal to the identity implies a perfect operation. Moreover, those values are directly affect by the increase or decrease of $\bm{K}$. This leads to the following observations:

% \begin{enumerate}
% 	\item a
% 	\item b
% 	\item c
% 	\item d
% \end{enumerate}

% 4 - Optimal Control and Estimation
% ---------------------------------------------------------------
\clearpage
\chapter{Optimal Control and Estimation}

a

\section{General Formulation}

The last chapter introduced the notion of controller synthesis as an engineering procedure to be done ``by hand" from a designer with some knowledge about the system and the control environment. This approach, despite being very popular and practical, introduces some design issues that make it difficult to generalize a controller to different systems within a same class or, more clearly, to MIMO configurations. Thus, a more general and automatic procedure to control synthesis is desirable.

With this motivation, the concept of \textit{Optimal Control} \textbf{[references]} was introduced as an alternative strategy for controlling dynamical systems that determines the necessary action by optimizing a cost function (or maximizing a reward function). Usually, these formulations are data-driven methods that autonomously produces optimal input signals given a desired objective and restrictions, and can be easily generalized to different systems.

\begin{boxed-definition}{(Optimal Control)} \label{def:optimalControl}
Given a system in State-Space formulation, with state-vector signal $\bm{x} : \mathbb{R} \rightarrow \mathbb{R}^{n}$, and a reference signal $\bm{r} : \mathbb{R} \rightarrow \mathbb{R}^{n}$, the input signal $u(t) \in \mathbb{R}^r$, for any time $t$, is calculated by an optimal control through an optimal control law $\pi^* : \mathbb{R}^{n \times n \times 1} \rightarrow \mathbb{R}^r$ as:
    \begin{equation}
        \bm{u}(t) = \pi^*(\bm{x}, \bm{r}, t) = \min_{\bm{u}} J(\bm{x}, \bm{r}, t)
    \end{equation}
    
\noindent where $J : \mathbb{R}^{n \times n \times 1} \rightarrow \mathbb{R}$ is known as a \textit{cost function} of the states and reference signals.
\end{boxed-definition}

First of all, note that this optimization can be converted to maximizing a function $\bm{V}$ by making $\bm{V} = -\bm{J}$, so this document will only refers to optimization as minimizing some cost function. Basically, the problem of finding an optimal control law, or optimal control policy, $pi^*(.)$ cares both for the choice of the cost function $J$ and for what optimization technique will be used to determine the value of $u(t)$ that achieve this minimum. This problem differs from standard optimization problems in data science because not only the data is usually obtained online from the system, but it is dependent through time and constrained by the dynamics of the model and optimal policy action. Thus, the solutions for this optimization are usually obtained through Calculus of Variations \textbf{[reference]} or, as is the approach used in this work, through Dynamic Programming \textbf{[reference]}.

To facilitate the discussion and analysis of optimal controllers, consider a subclass of these controllers (that is still very general) defined below by a specific choice of functional for the cost function.

\begin{boxed-definition}{(Finite-Horizon Optimal Regulators)} \label{def:finiteHorizonOC}
    Consider a controller setup as in Definition \ref{def:optimalControl}. A \textit{Finite-Horizon Optimal Regulators} is defined as any controller whose optimal policy over a time interval $t \in [t_0, T]$ minimizes the cost functional:
    \begin{equation}
        J = \int_{t_0}^T l(\bm{x}, \bm{u}, \tau) d \tau + l_f(\bm{x}, T)
    \end{equation}
    
    \noindent where $l(.) : \mathbb{R}^{n \times r \times 1} \rightarrow \mathbb{R}$ and $l_f(.) : \mathbb{R}^{n} \rightarrow \mathbb{R}$ are, respectively, the trajectory and terminal \textit{loss functions}. In the case that $t_0 = 0$, $T$ is also known as the \textit{control horizon}.
\end{boxed-definition}

This formulation presents a notion of, basically, optimize for an trajectory $P^* = [\bm{x}(t_0), \cdots, \bm{x}(T)]$ which is optimal given the loss functions, and then find the control input that can achieve this trajectory. As will be shown later, this is a very feasible strategy for controllable linear systems. In a optimization notation, this problem can also be presented as the following \textit{program}: 
\begin{align}
\begin{matrix*}[l]
	\textbf{minimize} & \int_{t_0}^T l(\bm{x}, \bm{u}, \tau) d \tau + l_f(\bm{x}, T) \\
	\hfill \textbf{s.t.} & \dot{\bm{x}}(t) = \bm{f}(\bm{x}, \bm{u}, t)  \\
				& \bm{u}(t) = \pi(\bm{x}(t_0), \cdots, \bm{x}(t))
\end{matrix*}
\end{align}

Now, the discussion turns to how to solve this general problem. In this work, the solution for the optimal control will follow the same dynamic programming formulation as in \textbf{[reference]}. The first necessary effort, then, is to define an important partial differential equation known as the Hamilton-Jacobi equation.

\begin{boxed-theorem}{(Hamilton-Jacobi equation)} \label{th:hamiltonJacobi}
	Consider a finite-horizon cost function in the form of Definition \ref{def:finiteHorizonOC}, for a system described by the state-equation $\dot{\bm{x}} = \bm{f}(\bm{x}, \bm{u}, t)$. Consider also that the loss $l(.)$ and state function $\bm{f}$ are smooth on their parameters. Then, minimizing any functional in the form of $J$ is equivalent to minimize the solution of the \textit{Hamilton-Jacobi equation}, which is given by the partial differential equation:
	\begin{equation}
		\cfrac{\partial V^*}{\partial t} = - \min_{u(t)} \left[ l(\bm{x}, \bm{u}, t) + \cfrac{\partial V^*}{\partial x} \bm{f}(\bm{x}, \bm{u}, t)  \right]
	\end{equation}
	
	\noindent and the boundary condition:
	\begin{equation}
		V^*(\bm{x}, T) = l_f(\bm{x}(T))
	\end{equation}
\end{boxed-theorem}

\begin{proof}
	First of all, consider the restatement of the cost functional as the function $V(.)$:
	\begin{equation}
		V(\bm{x}, \bm{u}, t_0) = \int_{t_0}^T l(\bm{x}, \bm{u}, \tau) d \tau + l_f(\bm{x}(T))
	\end{equation}
	
	Minimizing this cost functional over control inputs $\bm{u}(t_0), \cdots, \bm{u}(T)$ consists in evaluating the optimal cost:
	\begin{equation}
		V^*(\bm{x}, t_0) = \min_{\bm{u}(t_0), \cdots, \bm{u}(T)} \left[ \int_{t_0}^T l(\bm{x}, \bm{u}, \tau) d \tau + l_f(\bm{x}(T)) \right]
	\end{equation}
	
	Now, consider any $t \in [t_0, T]$ and $t_r \in [t, T]$. Since the original control action $\bm{u}(t), \cdots, \bm{u}(T)$ can be obtained through the concatenation of $\bm{u}(t), \cdots, \bm{u}(t_r)$ and $\bm{u}(t_r), \cdots, \bm{u}(T)$, the optimal cost in this interval can be represented in the recursive form:
	\begin{equation}
	\begin{split}
	V^*(\bm{x}, t) &= \min_{\bm{u}(t), \cdots, \bm{u}(T)} \left[ \int_{t}^T l(\bm{x}, \bm{u}, \tau) d \tau + l_f(\bm{x}(T)) \right] \\
		&= \min_{\bm{u}(t), \cdots, \bm{u}(t_r)} \left\{ \min_{\bm{u}(t_r), \cdots, \bm{u}(T)} \left[ \int_{t}^{t_r} l(\bm{x}, \bm{u}, \tau) d \tau + \int_{t_r}^{T} l(\bm{x}, \bm{u}, \tau) d \tau + l_f(\bm{x}(T)) \right] \right\} \\
		&= \min_{\bm{u}(t), \cdots, \bm{u}(t_r)} \left\{ \int_{t}^{t_r} l(\bm{x}, \bm{u}, \tau) d \tau + \min_{\bm{u}(t_r), \cdots, \bm{u}(T)} \left[ \int_{t_r}^{T} l(\bm{x}, \bm{u}, \tau) d \tau + l_f(\bm{x}(T)) \right] \right\} \\
		&= \min_{\bm{u}(t), \cdots, \bm{u}(t_r)} \left\{ \int_{t}^{t_r} l(\bm{x}, \bm{u}, \tau) d \tau + V^*(\bm{x}, t_r) \right\}
	\end{split}
	\end{equation}
	
	Without loss of generalization, let $t_r = t + \delta t$, where $\delta t$ is a small number. Since $l(.)$ is a smooth function, the right-hand side of the recursive form above can be expanded by a Taylor series expansion:
	\begin{equation}
	\begin{split}
		V^*(\bm{x}, t) = \min_{\bm{u}(t), \cdots, \bm{u}(t+\delta t)} & \biggl\{ \delta t l(\bm{x}, \bm{u}, t + \delta t) \biggr. \\ 
		& \left. + V^*(\bm{x}, t) + \cfrac{\partial V^*(\bm{x}, t)}{\partial \bm{x}} \cfrac{d \bm{x}(t)}{dt} \delta t + \cfrac{\partial V^*(\bm{x}, t)}{\partial t} \delta t + O(\delta t)^2  \right\}
	\end{split}
	\end{equation}
	
\noindent where $O(\delta t)^2$ denotes the high order terms. Since the terms $V^*(\bm{x}, t)$ and $(\partial V^*/\partial t) \delta t$ does not depend on $\bm{u}(t)$, they can be taken out of the minimization. Rearranging the terms and substituting $d \bm{x} / dt = \bm{f}(\bm{x}, \bm{u}, t)$ results in:
	\begin{equation}
		\cfrac{\partial V^*}{\partial t}(\bm{x}, t) =  - \min_{\bm{u}(t), \cdots, \bm{u}(t+\delta t)} \left\{ l(\bm{x}, \bm{u}, t + \delta t)  + \cfrac{\partial V^*(\bm{x}, t)}{\partial \bm{x}} \bm{f}(\bm{x}, \bm{u}, t) + O(\delta t)^2  \right\}
	\end{equation}
	
	Finally, making $\delta t \to 0$ results in:
	\begin{equation}
		\cfrac{\partial V^*}{\partial t} =  - \min_{\bm{u}(t)} \left\{ l(\bm{x}, \bm{u}, t)  + \cfrac{\partial V^*}{\partial \bm{x}} \bm{f}(\bm{x}, \bm{u}, t) \right\}
	\end{equation}
	
	To establish the theorem it remains to derive the boundary condition. This result, however, is direct from the form of the cost function, since $V^*(\bm{x}, T) = l_f(\bm{x}(T))$ can not be changed through any more control action inside the time horizon.
\end{proof}

[Comments on that the optimal control only depends on the instant, and on the Principle of Optimality]

[Motivation for LQR]

\section{Linear Quadratic Regulator (LQR)}

a

\section{Optimal State Estimators}

a

\section{Linear Quadratic Gaussian (LQG)}

a

\section{Robustness and Stability Analysis}


% 5 - Methodology
% ---------------------------------------------------------------
\clearpage
\chapter{Methodology}

a

% 6 - Results and Discussion
% ---------------------------------------------------------------
\clearpage
\chapter{Results and Discussion}

a

% 7 - Conclusion
% ---------------------------------------------------------------
\clearpage
\chapter{Conclusion}

a

% Bibliography
% ---------------------------------------------------------------
\clearpage
\addcontentsline{toc}{chapter}{Bibliography}

\bibliographystyle{apalike}
\bibliography{citations}

% A - Apêndice A
% ---------------------------------------------------------------
\clearpage
\addcontentsline{toc}{chapter}{Appendix A - Proof of Theorems}
\chapter*{Appendix A - Proof of Theorems}

\section*{Chapter 2}

\begin{proof}{\textbf{(Theorem \ref{th:exoReactSys01})}}
    Considering that the reactions obeys the Arrhenius equation, the dynamical model for the non-isothermal reactor is a direct application of Theorem \ref{th:isoReactSys01} when assuming that the kinetics are in the form:
    \begin{equation}
    	K_{XY} = K_{XY}(T) = K_{XY} e^{-\frac{E_{XY}}{T}} 
    \end{equation}
    
    \noindent with $T$ being the temperature in Kelvins and $E_{XY}$ being the activation energy needed for a reaction $X \rightarrow Y$ to occur.

	In respect to the change in temperatures, the model is obtained by a analysis of the conservation of heat, an energy that obeys this principle: 
	\begin{equation} \label{eq:jacket01}
		\begin{pmatrix}
			\text{Accumulation} \\ \text{of heat}
		\end{pmatrix} = \begin{pmatrix}
			\text{Heat entering} \\ \text{the System}
		\end{pmatrix} - \begin{pmatrix}
			\text{Heat leaving} \\ \text{the System}
		\end{pmatrix}
	\end{equation}
	
	Consider the temperature inside the reactor. Since the system is closed, and involved by the heating/cooling system, this quantity is a result of a change in heat given by the flow of fluid entering and leaving the system, the direct transfer of heat by conduction from the contact with the cooling/heating system and the entropy contribution from the reactions. In this case, the conservation law becomes:	
	\begin{equation}
	\begin{split}
		\begin{pmatrix}
			\text{Accumulation} \\ \text{of heat}
		\end{pmatrix} &= \begin{pmatrix}
			\text{Heat entering} \\ \text{the System}
		\end{pmatrix} - \begin{pmatrix}
			\text{Heat leaving} \\ \text{the System}
		\end{pmatrix} \\
		 &= \begin{pmatrix}
			\text{Heat transfer} \\ \text{from mass-flow}
		\end{pmatrix} + \begin{pmatrix}
			\text{Heat transfer} \\ \text{from regulator}
		\end{pmatrix} + \begin{pmatrix}
			\text{Entropy} \\ \text{contribution} \\ \text{from reactions}
		\end{pmatrix}
	\end{split}
	\end{equation}
	
	From Fourier's law \textbf{[seek reference]}, the transfer of heat by convection between the fluids, $h_{conv}$ , and by the conduction between the systems, $h_{cond}$, obeys the proportionality:
	\begin{equation}
		\begin{matrix}
			h_{conv} \sim T_{in} - T_{out} & & h_{cond} \sim T_C - T
		\end{matrix}
	\end{equation}	 	
	
	The entropy contribution from a reaction $\alpha X \rightarrow \beta Y$, denoted as $S_{XY}$, is proportional to the concentration of $\rho_X$ consumed multiplied by the energy that it liberates or absorbs:
	\begin{equation}
		S_{XY} \sim K_{XY} e^{-\frac{E_{XY}}{T}} (\rho_X)^{\alpha} \Delta H_{XY}
	\end{equation}

	All the proportionality can be turned into equalities by imposing real constant factors that are calculated without the dynamical variables. In the case of the heat transfer by convection, the change in temperature is directly given by the ratio of volume entering the system. Plugging all together, and summing the entropy contribution from each reaction, the  accumulation of heat is modeled as:
	\begin{equation}
		\cfrac{d(T)}{dt} = q(T_{in} - T_{out}) + \eta (T_C - T) + \delta \sum_{\alpha A \rightarrow \beta X} K_{AX} e^{-\frac{E_{AX}}{T}} (\rho_A)^{\alpha} \Delta H_{AX}
	\end{equation}
	
	Consider the heating/cooling system involving the reactor system. From the choice of design of this apparatus, it is possible to directly manipulate the temperature of its material using a cooling/heating capacity $Q$ up to a real factor of $\gamma$. Similar to the temperature inside the container, there is the conduction of heat between the healing/cooling system and the walls of the container for the reactor. Therefore, the model of heat accumulation for this quantity is given by:
	\begin{equation}
		\cfrac{d(T_C)}{dt} = \gamma Q + \beta (T - T_C)
	\end{equation}
\end{proof}



\begin{proof}{\textbf{(Theorem \ref{th:transFun01})}}
	Applying the Laplace transform in both sides of the equation, and using some properties of this operator, the result is:

	\begin{equation} 
	\begin{split}
	    \mathcal{L} \left\{\alpha_n \cfrac{d^n y(t)}{dt^n} + \cdots + \alpha_{1} \cfrac{d y(t)}{dt} + \alpha_{0} y(t) \right\}  &= \mathcal{L} \left\{ \beta_m \cfrac{d^m u(t)}{dt^m} + \cdots + \beta_{1} \cfrac{d u(t)}{dt} + \beta_{0} u(t) \right \}  \\
	    \alpha_0 Y(s) + \sum_{i=1}^{n} \alpha_i \left(s^i Y(s) - \sum^{i-1}_{j = 0} s^j \cfrac{d^j y(0^-)}{dt^j} \right) &= \beta_0 U(s) + \sum_{k=1}^{m} \beta_i \left(s^i U(s) - \sum^{k-1}_{l = 0} s^l \cfrac{d^l u(0^-)}{dt^l} \right)
	\end{split}
	\end{equation}
	
	By the assumption that all the initial conditions are zero, $y(0^-) = u(0^-) = 0$: 
	\begin{equation} 
	    \alpha_0 Y(s) + \sum_{i=1}^{n} \alpha_i s^i Y(s) = \beta_0 U(s) + \sum_{k=1}^{m} \beta_i s^i U(s)
	\end{equation}
	
	Factoring the left side by $\bm{Y}(s)$ and the right side by $\bm{U}(s)$, and doing some basic algebra, the transfer function $G(s)$, between these variables is:
	\begin{equation} 
	 G(s) = \cfrac{Y(s)}{U(s)} = \cfrac{\beta_m s^m + \beta_{m-1} s^{m-1} + \cdots + \beta_{1} s + \beta_0}{\alpha_n s^n + \alpha_{n-1} s^{n-1} + \cdots + \alpha_{1} s + \alpha_0}
	\end{equation}
\end{proof}

% ---------------------------------------------------------------
% End document
% ---------------------------------------------------------------

\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Drafts:
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% Figure:
% \begin{figure}[ht]
% 	\centering
% 	\includegraphics[trim={0cm 0cm 0cm 0cm},clip,scale=1]{nameFigure}
% 	\caption{caption of the figure.}
% 	\label{fig:nameFigure}
% \end{figure} \vskip0.25cm
%
%%%%% Equation:
% \begin{equation} \label{eq:nameEquation}
% \begin{split}
%	 X = 1 + 1
% \end{split}
% \end{equation} \vskip0.25cm
%
%%%% Table:
% \begin{table}[hp]
% 	\centering
% 	\begin{tabular}{l | c c }
% 	Principal & Coluna1 & Coluna2 \\
% 	\hline 
% 	ABC	& 1 & 2 \\
% 	DFG	& 3 & 4 \\
% 	HIJ	& 5 & 6 \\
% 	\end{tabular} 
% 	\caption{caption of the table.}
% 	\label{table:nameTable}	
% \end{table} \vskip0.25cm