% ---------------------------------------------------------------
% Preamble
% ---------------------------------------------------------------
\documentclass[a4paper,11pt]{book}

\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage[margin=1in,a4paper,pdftex]{geometry}
\usepackage[protrusion=true,expansion=true]{microtype} 
\usepackage{amsmath,amsfonts,amsthm,amssymb}
\usepackage{rotating}
\usepackage[colorlinks=true, linkcolor=blue, urlcolor=blue, anchorcolor=blue, citecolor=black]{hyperref}
\usepackage[all]{hypcap}
\usepackage{color}
\usepackage{listings}
\usepackage[ruled]{algorithm2e}
\usepackage{cite}
\usepackage{makecell}

\numberwithin{figure}{chapter}
\numberwithin{equation}{chapter}
\numberwithin{table}{chapter}

\newtheorem{theorem}{Theorem}[chapter]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}

\theoremstyle{definition}
\newtheorem{definition}{Definition}[chapter]

\makeatletter
\setlength{\@fptop}{0pt}
\makeatother

\usepackage{graphicx}
\graphicspath{ {imgs/} }

\lstset{
    backgroundcolor=\color[rgb]{0.86,0.88,0.93},
    language=matlab, keywordstyle=\color[rgb]{0,0,1},
    basicstyle=\footnotesize \ttfamily,breaklines=true,
    escapeinside={\%*}{*)}
}

% --------------------------------------------------------------------
% Definitions
% --------------------------------------------------------------------
\newcommand{\HRule}[1]{\rule{\linewidth}{#1}} 

\makeatletter                       
\def\printtitle{
    {\centering \@title\par}}
\makeatother                                    

\makeatletter 
\def\printauthor{
    {\centering \large \@author}}               
\makeatother                            

% ---------------------------------------------------------------
% Metadata 
% ---------------------------------------------------------------
\title{ \normalsize \textsc{Course Conclusion Paper - DRAFT} 
        \\[2.0cm]             
        \HRule{0.5pt} \\              
        \LARGE \textbf{\uppercase{Dynamical Modelling and Control of Chemical Reactive Systems}}
        \HRule{2pt} \\[0.5cm]  
}

\author{
        Otacílio Bezerra Leite Neto\\   
        Federal University of Ceará\\  
        Department of Teleinformatics Engineering\\
        \texttt{minhotmog@gmail.com} \\
}

\begin{document}
% ---------------------------------------------------------------
% Maketitle
% ---------------------------------------------------------------
\thispagestyle{empty}       % Remove page numbering on this page

\printtitle                 % Print the title data as defined above
    \vfill
\printauthor                % Print the author data as defined above
\newpage

% ---------------------------------------------------------------
% Begin document
% ---------------------------------------------------------------
% Set page numbering to begin on this page
\thispagestyle{empty}   
\tableofcontents

% 1 - Introduction
% ---------------------------------------------------------------
\clearpage
\setcounter{page}{1}
\chapter{Introduction}

This chapter presents the main problem in discussion and the basic concepts concerning its formulation and solutions, which are detailed further in the next chapters. This is a work on Control Theory and its application to Chemical Reactive Systems, therefore the discussion will follow the notation common to the literature of this field, and a "modern" approach to this theory is explored. 

The sections are organized as follows: Section 1.1 provides general definitions for control systems engineering, Section 1.2 discuss chemical reactive systems and its importance in both industry and academia, Sections 1.3 and 1.4 describes the motivation and justification of this work, respectively, and Section 1.5 details the subsequent chapters in this document.

\section{Control Systems Engineering}

The discipline of Control Systems Engineering deals with the design of devices, named \textit{controllers}, that are integrated to a physical system (a \textit{dynamical system}, in most cases) in order to impose a desired behavior to this system. To achieve this goal, the discipline covers topics ranging from applied mathematics, such as dynamical systems theory and signal processing, to a more engineering discussion, regarding instrumentation and implementation of these controllers in a real-life plant or individual system. 

A system, in a broad physical sense, is defined as a ensemble of interacting components that responds to external stimuli producing a determined dynamical response, and whose individual parts are not able to produce the same functionality by their own. Thus, the first essential element in Control Theory is a mathematical model of the system of interest. One such model is the \textit{Input-Output Representation}, as shown in \textbf{fig!!!}, in which an input stimuli, a signal $u(t)$, acts on the system producing an output response, a signal $y(t)$, described by the following differential equation:
\begin{equation} \label{eq:01-01}
\begin{split}
    \alpha_n \cfrac{d^n y(t)}{dt^n} + \alpha_{n-1} & \cfrac{d^{n-1} y(t)}{dt^{n-1}} + \cdots + \alpha_{1} \cfrac{d y(t)}{dt} + \alpha_{0} y(t) = \\
    & \beta_m \cfrac{d^m u(t)}{dt^m} + \beta_{m-1} \cfrac{d^{m-1} u(t)}{dt^{m-1}} + \cdots + \beta_{1} \cfrac{d u(t)}{dt} + \beta_{0} u(t)
\end{split}
\end{equation}

[fig]

In this representation, the input $u(t)$ is called the \textit{manipulated variable}, since it represents a arbitrary stimuli that can be given directly by human action or a by an automatic controller, while the output $y(t)$ is called the \textit{controlled variable}, since it can only be modified indirectly through $u(t)$. This also leads to a \textit{cause-and-effect} interpretation of the system.

A model can provide a quantitative understanding of the system that is useful both to access some response specifications and to design controllers to modify them based on some requirements. In the case of the model in Equation \eqref{eq:01-01}, it is possible to calculate the response $y(t)$, and its derivatives, resulting from any specific action $u(t)$. Besides, a model can be used to perform computer simulations, in order to visualize the dynamical behavior of the system without actually manipulating it, since real experiments could be expensive or even damage the system. Consider, for instance, a schematic and a simulation for a model representing a mass-spring-damper system, shown at \textbf{!!!!}.

[fig]

In this simulation, the \textit{rise time}, \textit{peak time}, \textit{overshoot ratio} and \textit{steady-state value} are examples of response specifications that can be defined to describe the system behavior to a external stimuli (in this case, a constant force of unit magnitude). These specified parameters are characteristic to responses of a class of systems known as \textit{underdamped second-order systems}, that will be discussed further in the document. 

A controller is used to calculate, for a time $t \in \left[ t_0, t_N\right)$, the necessary input $u(t)$ to produce an output $y(t)$ as close as possible to a desired reference signal $r(t)$. There are two common configurations, shown in \textbf{Fig!!!}, of how to connect the controller to the system.

[fig]

The configuration in \textbf{Fig!!!.a}, known as \textit{Open-Loop Controller}, calculates the action as a function $u(t) = \pi(r, t)$, given an initial condition $y(t_0) = y_0$. In this case, the controller does not observe the output $y(t)$, and relies on the model to guarantee that the system is driven to the reference. Of course, if there are any external disturbances acting on this configuration, or if the model is not reliable enough, it is not possible to guarantee that the requirements are met. Thus, these type of controllers are not suitable for critical applications, and its use is restricted to systems where deviance from the desired reference can be tolerated. \textbf{[exemplos de aplicações?]}

In contrast, the configuration in \textbf{Fig!!!.b}, known as \textit{Closed-Loop Controller} or \textit{Feedback Controller}, calculates the action as a function $u(t) = \pi(e, t)$, where $e(t) = r(t) - y(t)$ is the error between the reference and the actual response. Now, the controller will observe the system output, trough some sensor device, and compares it to the desired reference in order to calculate a \textit{corrective action}. This feedback property can make the system reject disturbances while still driving it to the desired reference. Thus, the Feedback Controller became the most popular choice of controller configuration in industry for a wide range of applications, even for critical ones.  \textbf{[exemplos de aplicações? + references]}

\section{Chemical Reactive Systems}

A chemical reaction, the transformation of a chemical substance into another, is a process central to chemistry and to nature itself. A reaction equation is a intuitive representation of such transformations. For instance, consider the following equation representing a \textit{synthesis reaction}:
\begin{equation}
    A + 2 B \longrightarrow 3 C + D 
\end{equation} 

In this equation, the compounds $A$ and $2 B$ forms the set of \textit{reactants}, $\mathcal{R}$, while $3 C$ and $D$ forms the set of \textit{products}, $\mathcal{P}$. The coefficients in such equations are the \textit{stoichiometric numbers}, providing an information about proportionality between the quantity of each substances in the reaction. 

Usually the products can be directly used as reactants in another reaction, in which case they can also be referred as a intermediate product (or byproduct), and the equations can be appended in a "series" representation. In this case, each $k$-th intermediate product forms a set $\mathcal{I}_k$. In addition to a chain of series reactions, there is also the possibility of different reactions to occur in parallel, in the same system. The combination of these sets of reactants, byproducts, products and reactions are often referred as a \textit{chemical reaction network}, and the associated equation can be represented in general form as:
\begin{equation} \label{eq:chemNetwork}
\left\{ \begin{matrix}
    \mathcal{R}^{(1)}  & \longrightarrow & \mathcal{I}^{(1)}_1  &  \longrightarrow & \cdots & \longrightarrow & \mathcal{I}^{(1)}_{M_1} & \longrightarrow & \mathcal{P}^{(1)} \\
    \mathcal{R}^{(2)} & \longrightarrow & \mathcal{I}^{(2)}_1  &  \longrightarrow & \cdots & \longrightarrow & \mathcal{I}^{(2)}_{M_2} & \longrightarrow & \mathcal{P}^{(2)} \\
    \vdots &  & \vdots &  & \vdots &  & \vdots &  & \vdots \\
    \mathcal{R}^{(N)} & \longrightarrow & \mathcal{I}^{(N)}_1  &  \longrightarrow & \cdots & \longrightarrow & \mathcal{I}^{(N)}_{M_N} & \longrightarrow & \mathcal{P}^{(N)} \\
\end{matrix} \right.
\end{equation} 

Moreover, chemical reactions displays a dynamical behavior concerning the speed at which a reaction occurs. This rate of reaction, its \textit{kinetics}, are dependent on the conditions in the environment, such as temperature and pressure, and on some properties of the reaction itself. In the case of a \textit{isothermal process}, i.e., when the temperature in the environment remains constant, this rate can be calculated as a constant $K$, leading to a representation on the form:
\begin{equation}
    \mathcal{R} \overset{K}{\longrightarrow} \mathcal{P}
\end{equation} 

When the temperature in the environment is not constant, the process is said to be \textit{endothermic} or \textit{exothermic} if, respectively, it consumes or produces energy. The kinetics of the reactions in such processes are usually functions of the temperature which, given an activation energy $E$, are assumed to follow the Arrhenius equation:
\begin{equation} \label{eq:arrhenius1}
    K(T) = K_0 e^{-E / T}
\end{equation}

In practice, these chemical reactions are produced by mixing the reactants in some environment with adequate conditions. In order to control the quantities of these substances, actual processes consists in a manipulation of the concentrations of reactants in some container, usually by providing a mass flow of these substances through some fluid. A major interest is to manipulate the reactants in some way to produce a desired concentration of one or more products in the chemical reaction network, allowing this problem to be addressed by a control engineering perspective. A \textit{chemical reactor system}, depicted in \textbf{Fig!!!}, is a system where a controller can manipulate the concentration of some reactants to produce a desired concentration of some products.

[img]

When the process is not isothermal, the occurrence of a reaction contributes to the entropy of the environment, and consequently affects the kinetics of the subsequent ones. To compensate for this, practical applications also try to control the conditions in the environment using instruments external to the reactions themselves. Because of the use of the Arrhenius equation to model these reaction rates, this control is usually implemented through a cooling or heating system coupled to the original reactor system, resulting in the schematic on \textbf{Fig!!!}.

[img]

\section{Motivation}

The use of automatic controllers to impose a desired behaviour to physical systems is a practice ubiquitous in many engineering fields. In the last years, the price of digital computers have been dropping while their performance have been growing. Consequently, digital controllers have became the central key in developments in important and innovative fields such as aeronautics \textbf{[reference]} and autonomous driving \textbf{[reference]}. In parallel, this theory is also useful to understand and bring inspiration from nature itself since, for instance, the mechanisms for temperature regulation observed in vertebrate animals behave as a feedback controller \cite{Heller:1978}.

Most recent developments in Control Theory focus on using Feedback Controllers to achieve \textit{Robust and Optimal Control}. This theory accounts for the design of controllers that deals with uncertainty, either from the model or from the observation of the system, and are able to achieve the control objectives in a \textit{optimal manner}. Despite being a few decades old, these fields have gained a lot of interest in the last years thanks to recent results in \textit{Machine Learning}, particularly in \textit{Reinforcement Learning}, that are having success in using optimization techniques for artificial agents to control themselves in environments loaded with uncertainty \textbf{[reference]}.

Furthermore, the specific application of controlling chemical reactor systems brings benefits from the fact that chemical reactions are present in most biological and industrial processes. In this sense, controllers can be used to guarantee safety constraints, maximize productivity and minimize the use of resources, in such way that is unfeasible without automatic and high performing machinery.

\section{Objectives}

This works aims to provide a self-contained discussion of modelling and control of chemical reactive systems in the perspective of modern control theory. Therefore, the results are focused on \textit{state feedback controllers} modelled in continuous and discrete time, but analysis in the frequency domain is also considered in order to explain some concepts. Several properties of these models, both in the open-loop and closed-loop regime, are summarized in the document and the intention is to have a generalized framework to understand, evaluate and design those systems. Finally, the theory of more advanced methods such as optimal estimation and optimal control is also developed in the same sense.

\section{Chapters Organization}

The chapters of this document are mainly organized in two parts. The first part, comprised by the chapters 2, 3 and 4, builds the necessary theoretical background and provides the mathematical framework for the applications. The second part, comprised by the chapters 5 and 6, describes the experiments and results of applying these methods in real-world applications.

Individually, the chapters are organized as follows: chapter 2 introduces the dynamical models and its several properties with respect to the real system behavior, chapter 3 discusses classical methods in developing automatic controllers and state observers, chapter 4 presents more advanced methods in optimal estimation and optimal control, chapter 5 describes the practical experiments used to validate the previous discussions, chapter 6 summarizes and discusses the results of the experiments and evaluate the several controllers performances and, finally, chapter 7 provides the conclusion of the document and possible future works.

% 2 - Dynamical System Modelling
% ---------------------------------------------------------------
\clearpage
\chapter{Dynamical System Analysis}

This chapter discuss the mathematical models for dynamical systems and its use in response analysis. The sections starts by introducing a procedure to build models from physical principles and presenting equivalent common representations. Next, the response of systems, both in time domain and frequency domain, are analyzed in the light of such models, relating the mathematical structure with the dynamical behavior. Finally, some important properties are defined and proved using this formulation.

\section{Model from First Principles}

A dynamical system is a physical system whose states evolves with time. For this reason, one can represent a dynamical system using the \textit{first principles} from physics itself, and formulate the evolution in time by calculating the rate of change of the states in respect to time. Thus, dynamical model can be equated using differential equations, with time derivatives. 

A straightforward procedure to model a system consists in identify the variables of interest and relate them using conservation laws, such as conservation of mass, conservation of energy or conservation of momentum. The resulting differential equations are in the form:
\begin{equation}
	\begin{pmatrix}
		\text{Rate of} \\ \text{Accumulation}
	\end{pmatrix} = \begin{pmatrix}
		\text{Mass/Energy/Momentum} \\ \text{entering the System}
	\end{pmatrix} - \begin{pmatrix}
		\text{Mass/Energy/Momentum} \\ \text{leaving the System}
	\end{pmatrix}
\end{equation}

The choice of which conservation law to use depends on the system itself, since the variables of interest can provide dynamics to the system in many forms. Usually, conservation of mass is used to relate dynamics of concentrations and volumes, or other material variables, while conservation of momentum is often used to relate dynamics of motion. Since energy can be converted on form, the conservation laws of this quantity can be used to model several dynamics, such as the rate of change in heat, electrical charges or velocity of a system.

In the case of a chemical reactor system, the variables of interest are the concentrations of the chemical substances in the system. Hence, the rate of accumulation of a substance can be represented using the mass conservation law, or mass balance:
\begin{equation}
\begin{split}
	\begin{pmatrix}
		\text{Accumulation} \\ \text{of mass} \\ \text{in the system}
	\end{pmatrix} &= 
	\begin{pmatrix}
		\text{Mass} \\ \text{entering} \\ \text{the System}
	\end{pmatrix} - \begin{pmatrix}
		\text{Mass} \\ \text{leaving} \\ \text{the System}
	\end{pmatrix} \\
	&= \left[ \begin{pmatrix}
		\text{Mass flow} \\ \text{entering} \\ \text{System}
	\end{pmatrix} + \begin{pmatrix}
		\text{Mass} \\  \text{produced} \\ \text{by reactions}
	\end{pmatrix} \right] - \left[ \begin{pmatrix}
		\text{Mass flow} \\ \text{leaving} \\ \text{System}
	\end{pmatrix} + \begin{pmatrix}
		\text{Mass} \\ \text{consumed} \\ \text{by reactions}
	\end{pmatrix} \right]
\end{split}
\end{equation}

From definition, mass is a quantity obtain by integrating the density (or concentration) $\rho$ of a material trough a volume $V$. If the density is assumed constant throughout this volume, the result is the simple equation:
\begin{equation}
	M = \int_V \rho dV = \rho \int_V dV = \rho V
\end{equation}

Hence, the mass flow of any substance $A$ entering and leaving the system, $M_{in}$ and $M_{out}$, respectively, given a fluid inflow $F_{in}$ with density $\rho_{in}$ and a fluid outflow $F_{out}$ with $\rho_{out}$, can be calculated as:
\begin{equation}
	\begin{matrix}
		M_{in} = \rho_{in} F_{in} & & M_{out} = \rho_{out} F_{out}
	\end{matrix}
\end{equation}

To calculate the mass contribution from the reactions, it is necessarily to formulate the mass contribution for a single reaction, first. In this case, consider a reaction between two chemical compounds $A$ and $B$, with stoichiometric numbers $s_{a}$ and $s_{b}$:
\begin{equation} \label{eq:simpleEq01}
	s_{a} A \overset{K_{AB}}{\longrightarrow} s_{b} B
\end{equation}

Under the assumption that the reactant is in a dilute solution, the rate of this equation obeys the \textit{law of mass action} \textbf{[seek reference]}. Given the kinetic rate $K_{AB}$ and the volume of the solution $V$, and considering the constant concentrations $\rho_A$ and $\rho_B$, the mass of $A$ consumed, $M^{(A)}_\text{cons}$, and the mass of $B$ produced, $M^{(B)}_\text{prod}$, are given by the power-law:
\begin{equation}
	\begin{matrix}
		M^{(A)}_\text{cons} = \cfrac{V}{s_B} K_{AB} (\rho_A)^{s_{a}} & & M^{(B)}_\text{prod} = \cfrac{V}{s_A} K_{AB} (\rho_A)^{s_{a}}
	\end{matrix}
\end{equation}

Now, consider the generalized form of a chemical reaction network, defined in Equation \eqref{eq:chemNetwork}. It is possible to obtain an equivalent representation after converting a chain of series equations in parallel equations, since each step of the series reactions also occurs simultaneously:
\begin{equation} \label{eq:newChemNetwork}
\left\{ \begin{matrix}
    \mathcal{R}^{(1)}  \longrightarrow & \cdots \longrightarrow & \mathcal{I}^{(1)}_{M_1} \longrightarrow & \mathcal{P}^{(1)}
\end{matrix} \right. \Longleftrightarrow \left\{ \begin{matrix}
    \mathcal{R}^{(1)}  & \longrightarrow & \mathcal{I}^{(1)}_1  \\ 
    \mathcal{I}^{(1)}_1 & \longrightarrow & \mathcal{I}^{(1)}_2 \\
	 & \vdots & \\
	\mathcal{I}^{(1)}_{M_1} & \longrightarrow & \mathcal{P}^{(1)}
\end{matrix} \right.
\end{equation} 

Thus, it is possible to convert the entire network into direct reactions in the form $\mathcal{R} \rightarrow \mathcal{P}$. In this sense, define the new reactant set as $\mathcal{SR} = \mathcal{R}^{(i)} \cup \mathcal{I}_1^{(i)} \cup \cdots \cup \mathcal{I}_{M_i}^{(i)},\ i = 1,2,...,N$, and similarly define the new product set as $\mathcal{SP} = \mathcal{P}^{(i)} \cup \mathcal{I}_1^{(i)} \cup \cdots \cup \mathcal{I}_{M_i}^{(i)},\ i = 1,2,...,N$. 

If each individual reactant set and product set are singleton, i.e., all the parallel reactions are in the form of Equation \eqref{eq:simpleEq01}, it is easy to calculate the mass contribution to a substance due to the entire network of reactions. Let $\mathcal{R}_A$ be the set of all reactions where a substance $A$ is a reactant in the network, and let $\mathcal{P}_A$ be the set of all reactions where the same substance $A$ is a product, after converting the entire network to the parallel form of Equation \eqref{eq:newChemNetwork}. More formally, define these sets as: 
\begin{equation}
	\begin{matrix}
		\mathcal{R}_A = \left\{ s_A A \overset{K_{AX}}{\rightarrow} s_X X,\ \forall A \in \mathcal{SR} \right\} & & \mathcal{P}_A = \left\{ s_X X \overset{K_{XA}}{\rightarrow} s_A A,\ \forall A \in \mathcal{SP} \right\}
	\end{matrix}
\end{equation}

Assuming that the network represents a set of reactions occurring within an chemical solution of volume $V$, the mass of a substance $A$, with concentration $\rho_A$, that is consumed and produced by the reactions, $M^{(A)}_\text{cons}$ and $M^{(B)}_\text{prod}$, respectively, are given by the summation:
\begin{equation}
		M_\text{cons} = V \sum_{\mathcal{R_A}} \cfrac{1}{s_X} K_{AX} (\rho_A)^{s_{A}}\ \ \ \ \  M_\text{prod} = V \sum_{\mathcal{P_A}} \cfrac{1}{s_A} K_{XA} (\rho_X)^{s_{X}}
\end{equation}

Finally, packing all together, the mass balance of any substance $A$ in a isothermal chemical reactive system can be represented by the general dynamical model:
\begin{equation}
		\cfrac{d (\rho_A V)}{dt} = \left[ \rho_{in} F_{in} + V \sum_{\mathcal{P_A}} \cfrac{1}{s_A} K_{XA} (\rho_X)^{s_{X}} \right] - \left[ \rho_{out} F_{out} + V \sum_{\mathcal{R_A}} \cfrac{1}{s_X} K_{AX} (\rho_A)^{s_{A}} \right]
\end{equation}

In real processes, the fluid flows $F_{out}$ and $F_{in}$ are manipulated variables of the system. A common practice is to operate using $F_{out} = F_{in} = F$ so that the volume of the chemical solution becomes constant, assuming that there are no leaks and that the system is closed. This is a desired condition because it eliminates the need to model the dynamics of the volume, usually not the variable of interest. In this case, the model can be simplified by normalizing all the terms by the volume and defining a new variable $q = F/V$ so that:
\begin{equation} \label{eq:isoModel1}
		\cfrac{d (\rho_A)}{dt} = q (\rho_{in} - \rho_{out}) + \left( \sum_{\mathcal{P_A}} \cfrac{1}{s_A} K_{XA} (\rho_X)^{s_{X}} \right) - \left(\sum_{\mathcal{R_A}} \cfrac{1}{s_X} K_{AX} (\rho_A)^{s_{A}} \right)
\end{equation}

This is a simple model that can describe several applications, and the same modeling procedure can be used to describe more complex systems. In addition to this realization, it is possible to extend the description to account for exothermic and endothermic processes. In this case, the kinetics constants $K_{AB}$ becomes functions of the temperature in the system, following the Arrhenius equation presented in Equation \eqref{eq:arrhenius1} and rewritten here:
\begin{equation} \label{eq:arrhenius2}
	K_{AB}(T) = K_{AB_0} e^{-E_{AB} / T}
\end{equation}

In this formula, the term $K_{AB_0}$ is the frequency factor and $E_{AB}$ is the activation energy necessary for such reaction to occur. Notice that, in the case that the temperature $T$ is constant, the kinetic rate is also constant and be calculated using this equation. By substituting \eqref{eq:arrhenius2} into \eqref{eq:isoModel1}, the resulting and more general model is:
\begin{equation} \label{eq:isoModel2}
		\cfrac{d (\rho_A)}{dt} = q (\rho_{in} - \rho_{out}) + \left( \sum_{\mathcal{P_A}} \cfrac{1}{s_A} K_{XA_0} e^{-E_{XA} / T} (\rho_X)^{s_{X}} \right) - \left(\sum_{\mathcal{R_A}} \cfrac{1}{s_X} K_{AX_0} e^{-E_{AX} / T} (\rho_A)^{s_{A}} \right)
\end{equation}

When discussing non-isothermal processes, it is also common to discuss heating or cooling systems that tries to impose certain operational conditions to the reactions. In exothermic processes, for instance, the heat accumulated in the system tends to grows as the reactions occurs, which can be very dangerous. Therefore, it is useful to model the evolution in time of these systems and its relationships with the previous model.

One approach to regulate the temperature consists in involving the chemical solution, or the container containing it, with a material whose temperature can be manipulated, transferring heat by conductance. The temperature of this material can be manipulated by, for instance, running a heated fluid or converting electrical energy to heat energy. Then, the dynamics of temperature inside this regulator system can be formulated by conservation of heat energy:
\begin{equation} \label{eq:jacket01}
\begin{split}
	\begin{pmatrix}
		\text{Accumulation} \\ \text{of heat}
	\end{pmatrix} &= \begin{pmatrix}
		\text{Heat entering} \\ \text{the System}
	\end{pmatrix} - \begin{pmatrix}
		\text{Heat leaving} \\ \text{the System}
	\end{pmatrix} \\
	\cfrac{d (T_R)}{dt} &= Q + \beta (T - T_R)
\end{split}
\end{equation}

In this model, the term $Q$ accounts for the direct heat manipulated to the material (e.g., trough a fluid or electrical energy) while the term $\beta (T - T_R)$ represents the heat transfer from this system to the original reactive one. Using the same conservation law, it is possible to describe the evolution of the temperature of the chemical solution in the reactive system. In this case, however: 
\begin{equation}
\begin{split}
	\begin{pmatrix}
		\text{Accumulation} \\ \text{of heat}
	\end{pmatrix} &= \begin{pmatrix}
		\text{Heat entering} \\ \text{the System}
	\end{pmatrix} - \begin{pmatrix}
		\text{Heat leaving} \\ \text{the System}
	\end{pmatrix} \\
	 &= \begin{pmatrix}
		\text{Heat transfer} \\ \text{from mass-flow}
	\end{pmatrix} + \begin{pmatrix}
		\text{Heat transfer} \\ \text{from regulator}
	\end{pmatrix} + \begin{pmatrix}
		\text{Entropy} \\ \text{contribution} \\ \text{from reactions}
	\end{pmatrix}
\end{split}
\end{equation}

In this case, the heat transfer direction is oriented from the material with higher temperature to the one with lower temperature. The flow of fluid entering the reactive system can contribute to the heat if its temperature is different from that of the solution, in addition to the contribution from the heating or cooling system itself. The third contribution, however, is provided by the energy released or absorbed from each chemical reaction. For a simple reaction, such as the one in Equation \eqref{eq:simpleEq01}, the temperature \textbf{[seek reference]}. 

[..]

\section{Mathematical Models of Systems}

The last section presented the basis for modeling a dynamical system using first principles from physics. Although it was a well-defined formulation, the resulting models from that procedure are not guaranteed to be practical in a mathematical sense. This is to due to the fact that the differential equations, as evidenced in Equation \eqref{eq:isoModel2}, are usually non-linear functions of the variables of interest, and the analysis of such functions are quite more challenging. 

In the perspective of control theory, that are two main formats for the model of a system: the \textit{Input-Output} (IO) and the \textit{State-Space} (SS) representations, both depicted in Figure \textbf{!!!}. 

[img]

The first representation, as already discussed, is a cause-and-effect interpretation of a system in which the model maps a input signal, denoted as $u(t) : \mathcal{R} \rightarrow \mathcal{R}$, directly to a output signal, denoted as $y(t) : \mathcal{R} \rightarrow \mathcal{R}$. It is formulated as the differential equation:
\begin{equation} \label{eq:IORepr01}
\begin{split}
    \alpha_n \cfrac{d^n y(t)}{dt^n} + \alpha_{n-1} \cfrac{d^{n-1} y(t)}{dt^{n-1}} &+ \cdots + \alpha_{1} \cfrac{d y(t)}{dt} + \alpha_{0} y(t) = \\
    & \beta_m \cfrac{d^m u(t)}{dt^m} + \beta_{m-1} \cfrac{d^{m-1} u(t)}{dt^{m-1}} + \cdots + \beta_{1} \cfrac{d u(t)}{dt} + \beta_{0} u(t)
\end{split}
\end{equation}

\noindent where the parameters $\alpha_0, \alpha_1, ..., \alpha_n$ and $\beta_0, \beta_1, ..., \beta_m$ are individual functions of any domain $\mathcal{D}$, so that $\alpha_i : \mathcal{D}_i \rightarrow \mathcal{R}, i = 1,2,...,n$ and $\beta_j : \mathcal{D}_j \rightarrow \mathcal{R}, j = 1,2,...,m$. 

In practice, the input signal $u(t)$ is given by a manipulated variable, where the output signal $y(t)$ is the result in the controlled variable. This is known as a \textit{Single-Input Single-Output} (SISO) configuration. To represent a configuration where there are $r$ manipulated variables influencing $p$ controlled variables, i.e., $\mathbf{u}(t) : \mathcal{R} \rightarrow \mathcal{R}^r$ and $\mathbf{y}(t) : \mathcal{R} \rightarrow \mathcal{R}^p$, the IO representation consists in having a differential equation for each pair $(u_i(t), y_j(t)),\ i = 1,2,...,r,\ j = 1,2,...,p$. The result is a matrix of differential equations describing a \textit{Multiple-Input Multiple-Output} (MIMO) configuration.

The State-Space representation is yet another formulation for a dynamical model, but centered in the concept of \textit{state variables}, denoted $\mathbf{x}(t) : \mathcal{R} \rightarrow \mathcal{R}^n$. Those are variables that stores informations about the intrinsic state of the system, and can be used to determine the output $\mathbf{y}(t)$ given any input $\mathbf{u}(t)$, similarly to the IO representation. This model is formulated as a set of $n$ ordinary differential equations describing the evolution of the states and a single algebraic equation describing the output as observed through the states: 
\begin{align} \label{eq:SSRepr01}
\begin{cases}
	\dot{\mathbf{x}}(t) &= \mathbf{f}(\mathbf{x}(t), u(t), t) \\
	y(t) &= g(\mathbf{x}(t), u(t), t) 	
\end{cases} \Leftrightarrow \begin{cases}
	\dot{x}_1(t) &= f_1(x_1(t), x_2(t), \cdots, x_n(t), u(t), t) \\
	\dot{x}_2(t) &= f_2(x_1(t), x_2(t), \cdots, x_n(t), u(t), t) \\
	 \vdots \\
	\dot{x}_n(t) &= f_n(x_1(t), x_2(t), \cdots, x_n(t), u(t), t) \\
	y(t) &= g(x_1(t), x_2(t), \cdots, x_n(t), u(t), t) 
\end{cases}
\end{align}

\noindent where $\dot{x}_i(t) = d(x_i(t))/dt,\ i \in \{1,2,..,n\},$ and $\mathbf{f}$ is a vectorial function describing the internal behavior of the system through the states. A nice property of the SS representation is that the extension to the MIMO configuration is done by augmenting the original formulation with more algebraic output equations, and changing the parameters to include the new input variables. Therefore, the number of state equations does not depends on the number of other variables:
\begin{align} \label{eq:SSRepr02}
\begin{cases}
	\dot{\mathbf{x}}(t) &= \mathbf{f}(\mathbf{x}(t), \mathbf{u}(t), t) \\
	\mathbf{y}(t) &= \mathbf{g}(\mathbf{x}(t), \mathbf{u}(t), t) 	
\end{cases} \Leftrightarrow \begin{cases}
	\dot{x}_1(t) &= f_1(x_1(t), \cdots, x_n(t), u_1(t), \cdots, u_r(t), t) \\
	\dot{x}_2(t) &= f_2(x_1(t), \cdots, x_n(t), u_1(t), \cdots, u_r(t), t) \\
	 \vdots \\
	\dot{x}_n(t) &= f_n(x_1(t), \cdots, x_n(t), u_1(t), \cdots, u_r(t), t) \\
	y_1(t) &= g_1(x_1(t), \cdots, x_n(t), u_1(t), \cdots, u_r(t), t) \\
	y_2(t) &= g_2(x_1(t), \cdots, x_n(t), u_1(t), \cdots, u_r(t), t) \\
	\vdots \\
	y_p(t) &= g_p(x_1(t), \cdots, x_n(t), u_1(t), \cdots, u_r(t), t) 
\end{cases}
\end{align}

Now, it is possible to classify the systems in respect to the structure of the mathematical models describing them. There are five main properties used for this classification: if the system is causal or non-causal, linear or non-linear, dynamical or instantaneous, time-invariant or time-varying and with or without delay. The necessary and sufficient conditions for each one of these properties, in respect to models, is summarized in Table \ref{table:classes01}.

\begin{table}[hp]
	\centering
	\begin{tabular}{r | c | c }
	 & \textbf{Input-Output} & \textbf{State-Space} \\
	\hline 
		\textbf{Causal}			& $m \leq n$ & Always causal \\
	\hline 
		\textbf{Linear}			& \makecell{$y(t) \notin \mathcal{D}_i, i=1,2,...,n$\\$u(t) \notin \mathcal{D}_j, j=1,2,...,m$} & \makecell{$f_i = \mathbf{a}_i(t) \mathbf{x}(t) + \mathbf{b}_i(t) \mathbf{u}(t), i = 1,2,...,n$ \\ $g_j = \mathbf{c}_j(t) \mathbf{x}(t) + \mathbf{d}_j(t) \mathbf{u}(t), j = 1,2,...,p$ \\ $\mathbf{a}_i,\mathbf{c}_j \in \mathcal{R}^{1 \times n}$ and $\mathbf{b}_i, \mathbf{d}_j \in \mathcal{R}^{1 \times r}$} \\
	\hline 
		\textbf{Dynamical}		& $n > 0$ or $m > 0$ & $n > 0$ \\
	\hline 
		\textbf{Time-Invariant}	& \makecell{$t \notin \mathcal{D}_i, i=1,2,...,n$\\$t \notin \mathcal{D}_j, j=1,2,...,m$} & \makecell{$\dot{\mathbf{x}}(t) = \mathbf{f}(\mathbf{x}(t), \mathbf{u}(t))$ \\ $\mathbf{y}(t) = \mathbf{g}(\mathbf{x}(t), \mathbf{u}(t))$} \\
	\hline 
		\textbf{Without-Delay}	& \makecell{All the signals share\\the same arguments} & \makecell{All the signals share\\the same arguments} \\
	\end{tabular} 
	\caption{necessary and sufficient conditions for model classifications.}
	\label{table:classes01}	
\end{table} 

This work focus on dynamical linear systems, since its models are the most well studied in the control theory community. Under this assumption, a nice result is the possibility to represent the SS representation of Equation \eqref{eq:SSRepr02} in a matrix form:
\begin{align} \label{eq:SSRepr03}
\begin{cases}
	\dot{\mathbf{x}}(t) &= \mathbf{A}(t) \mathbf{x}(t) + \mathbf{B}(t) \mathbf{u}(t) \\
	\mathbf{y}(t) &= \mathbf{C}(t) \mathbf{x}(t) + \mathbf{D}(t) \mathbf{u}(t)
\end{cases}
\end{align}

\noindent where $\mathbf{A}(t) : \mathcal{R} \rightarrow \mathcal{R}^{n \times n}$, $\mathbf{B}(t) : \mathcal{R} \rightarrow \mathcal{R}^{n \times r}$, $\mathbf{C}(t) : \mathcal{R} \rightarrow \mathcal{R}^{p \times n}$ and $\mathbf{D}(t) : \mathcal{R} \rightarrow \mathcal{R}^{p \times r}$. In the case of a time-invariant system linear system, these matrices becomes constants. 

This formulation has the advantages that the time response of the system can be easily calculated and the analysis of the dynamics follows useful results from linear algebra. Furthermore, the representation benefits from the use of state variables to enhance the interpretation of the model, which is usually not so straightforward in IO representation. Thus, the model presented in Equation \eqref{eq:SSRepr03} will be the basis for the results later in this document.

In addition to the SS representation, the linear assumption also benefits IO representations as defined in Equation \eqref{eq:IORepr01}. One major analytical tool that can be used in these cases is to transform this model to a frequency domain, using an linear transform operator, in order to simplify the differential equation. The most popular choice of transformation is the \textit{Laplace transform}, $\mathcal{L}\{ h(t) \}$, which converts functions in time to functions in complex frequencies. Using the Laplace transform theorems, differential equations are transformed into algebraic equations, simplifying the model:
\begin{equation} \label{eq:IORepr02}
\begin{split}
    \mathcal{L} \left\{\alpha_n \cfrac{d^n y(t)}{dt^n} + \cdots + \alpha_{1} \cfrac{d y(t)}{dt} + \alpha_{0} y(t) \right\}  &= \mathcal{L} \left\{ \beta_m \cfrac{d^m u(t)}{dt^m} + \cdots + \beta_{1} \cfrac{d u(t)}{dt} + \beta_{0} u(t) \right \}  \\
    \alpha_0 Y(s) + \sum_{i=1}^{n} \alpha_i \left(s^i Y(s) - \sum^{i-1}_{j = 0} s^j \cfrac{d^j y(0^-)}{dt^j} \right) &= \beta_0 U(s) + \sum_{k=1}^{m} \beta_i \left(s^i U(s) - \sum^{k-1}_{l = 0} s^l \cfrac{d^l u(0^-)}{dt^l} \right)
\end{split}
\end{equation}

By assuming that all the initial conditions are zero, $y(0^-) = u(0^-) = 0$, and doing some basic algebra, this model can be even more simplified to a relation popularly known as the transfer function, $G(s)$, between the output, $Y(s)$, and input, $U(s)$:
\begin{equation} \label{eq:transFun01}
 G(s) = \cfrac{Y(s)}{U(s)} = \cfrac{\beta_m s^m + \beta_{m-1} s^{m-1} + \beta_{1} s + \beta_0}{\alpha_n s^n + \alpha_{n-1} s^{n-1} + \alpha_{1} s + \alpha_0}
\end{equation}

An indirect result of this is that the SS representation can be converted to the IO representation using basically the same procedure. Consider, for instance, the Laplace transform on the state equations of a LTI system, with initial states $\mathbf{x}(0^-) \equiv 0$:
\begin{equation} \label{eq:convertSSIO01}
\begin{split}
	\mathcal{L} \left\{ \dot{\mathbf{x}}(t) \right\} &= \mathbf{A} \mathcal{L} \left\{ \mathbf{x}(t) \right\} + \mathbf{B} \mathcal{L} \left\{ u(t) \right\} \\
	s \mathbf{X}(s) - \dot{\mathbf{x}}(0^-) &= \mathbf{A} \mathbf{X}(s) + \mathbf{B} \mathbf{U}(s) \\
	(s\mathbf{I}  - \mathbf{A}) \mathbf{X}(s) &=  \mathbf{B} \mathbf{U}(s) \\
	 \mathbf{X}(s) &= (s\mathbf{I}  - \mathbf{A})^{-1} \mathbf{B} \mathbf{U}(s)
\end{split}
\end{equation}

By applying the same procedure in the output equations, using the previous result, the Laplace transform of the output is:
\begin{equation} \label{eq:convertSSIO02}
\begin{split}
	\mathcal{L} \left\{ \mathbf{y}(t) \right\} &= \mathbf{C} \mathcal{L} \left\{ \mathbf{y}(t) \right\} + \mathbf{D} \mathcal{L} \left\{ u(t) \right\} \\
	\mathbf{Y}(s)  &= \mathbf{C} \mathbf{X}(s) + \mathbf{D} \mathbf{U}(s) \\
	\mathbf{Y}(s)  &= \mathbf{C} \left( (s\mathbf{I}  - \mathbf{A})^{-1} \mathbf{B} \mathbf{U}(s) \right) + \mathbf{D} \mathbf{U}(s) \\
	\mathbf{Y}(s)  &= \left( \mathbf{C} (s\mathbf{I} - \mathbf{A})^{-1} \mathbf{B}   + \mathbf{D} \right) \mathbf{U}(s) \\
\end{split}
\end{equation}

In conclusion, it is possible to obtain the transfer function matrix $\mathbf{G}(s) = \mathbf{Y}(s)\mathbf{U}^{-1}(s) = \mathbf{C} (s\mathbf{I} - \mathbf{A})^{-1} \mathbf{B}   + \mathbf{D}$ as an equivalent representation of the same system.

Despite of the discussion about the benefits of linear models, it is necessary to account for the fact that physical systems will present, in most situations, non-linear behavior, as evidenced in Equation \eqref{eq:isoModel2}. For this reason, some effort must be done to develop a linear model that can describe the non-linear behavior with certain accuracy, even if over some small region of the space. With this motivation, a technique for \textit{linearization} of a non-linear model, such as the one developed by the first principle method, is detailed below.

Consider a system represented by state equations $\mathbf{f}(.)$ and output equations $\mathbf{g}(.)$, with steady-state operation points $\mathbf{x}_o$, $\mathbf{y}_o$ and $\mathbf{u}_o$. Now, consider a small perturbation $\Delta u(t)$ in the input signal around these operation points. This perturbation will result in small changes in the state and output variables:
\begin{align}
\begin{cases}
	\mathbf{x}(t) &= \mathbf{x}_o + \Delta \mathbf{x}(t) \\
	\mathbf{u}(t) &= \mathbf{u}_o + \Delta \mathbf{u}(t) \\
	\mathbf{y}(t) &= \mathbf{y}_o + \Delta \mathbf{y}(t) \\
\end{cases}
\end{align}

This results in the following configuration on the State-Space:
\begin{align}
\begin{cases}
	\cfrac{d(\mathbf{x}_o + \Delta \mathbf{x}(t))}{dt} &= \mathbf{f}(\mathbf{x}_o + \Delta \mathbf{x}(t), \mathbf{u}_o + \Delta \mathbf{u}(t) ) \\
	\mathbf{y}_o + \Delta \mathbf{y}(t) &= \mathbf{g}(\mathbf{x}_o + \Delta \mathbf{x}(t), \mathbf{u}_o + \Delta \mathbf{u}(t) ) \\
\end{cases}
\end{align}

Where $d(\mathbf{x}_o + \Delta \mathbf{x}(t)) / dt = d(\Delta \mathbf{x}(t)) / dt$, since $\mathbf{x}_o$ is constant. The perturbations are very close to the operation points, and hence the functions $f(.)$ and $g(.)$ can be fairly approximated by a Taylor series expansion, yielding:
\begin{align}
\begin{cases}
	\cfrac{d(\Delta \mathbf{x}(t))}{dt} &= \mathbf{f}(\mathbf{x}_o, \mathbf{u}_o) + \left. \cfrac{\partial \mathbf{f}}{\partial \mathbf{x}}\right\vert_{s} \Delta \mathbf{x}(t) + \left. \cfrac{\partial \mathbf{f}}{\partial \mathbf{u}}\right\vert_{s}  \Delta \mathbf{u}(t) + \text{high order terms} \\ \\
	\mathbf{y}_o + \Delta \mathbf{y}(t) &= \mathbf{g}(\mathbf{x}_o, \mathbf{u}_o) + \left. \cfrac{\partial \mathbf{g}}{\partial \mathbf{x}}\right\vert_{s} \Delta \mathbf{x}(t) + \left. \cfrac{\partial \mathbf{g}}{\partial \mathbf{u}}\right\vert_{s}  \Delta \mathbf{u}(t) + \text{high order terms} \\
\end{cases}
\end{align}

Since the steady-state condition implies zero variation, it is possible to assume $f(\mathbf{x}_o, \mathbf{u}_o) = 0$ and $g(\mathbf{x}_o, \mathbf{u}_o) = 0$, since they are ordinary differential equations. Truncating in the first order terms and substituting $\Delta \mathbf{x}(t) = \mathbf{x}(t) - \mathbf{x}_o$, $\Delta \mathbf{u}(t) = \mathbf{u}(t) - \mathbf{u}_o$ and $\Delta \mathbf{y}(t) = \mathbf{y}(t) - \mathbf{y}_o$ results in:
\begin{align}
\begin{cases}
	\cfrac{d(\Delta \mathbf{x}(t))}{dt} &=\left. \cfrac{\partial \mathbf{f}}{\partial \mathbf{x}}\right\vert_{s} (\mathbf{x}(t) - \mathbf{x}_o) + \left. \cfrac{\partial \mathbf{f}}{\partial \mathbf{u}}\right\vert_{s}  (\mathbf{u}(t) - \mathbf{u}_o) \\ \\
	\Delta \mathbf{y}(t) &= \left. \cfrac{\partial \mathbf{g}}{\partial \mathbf{x}}\right\vert_{s} (\mathbf{x}(t) - \mathbf{x}_o) + \left. \cfrac{\partial \mathbf{g}}{\partial \mathbf{u}}\right\vert_{s}  (\mathbf{u}(t) - \mathbf{u}_o) \\
\end{cases}
\end{align}

Finally, since all the Jacobians involved are actually matrices of appropriate dimensions, the final linear approximation of the system is the SS model given by:
\begin{align}
\begin{cases}
	\Delta \mathbf{\dot{x}}(t) &= \mathbf{A}\Delta \mathbf{x}(t) + \mathbf{B}\Delta \mathbf{u}(t) \\
	\Delta \mathbf{y}(t) &= \mathbf{C}\Delta \mathbf{x}(t) + \mathbf{D}\Delta \mathbf{u}(t)
\end{cases}
\end{align}

\section{Time Response Analysis}

Once that a model is well-established, it is possible to analyze the properties of its response, both in a natural regime or in an forced regime. This section, then, focus on developing a quantitative understanding of a system behavior through a linear model. The results are focused on continuous-time response of LTI systems (however, the extension to discrete-time models is straightforward):
\begin{align}
\begin{cases}
	\mathbf{\dot{x}}(t) &= \mathbf{A} \mathbf{x}(t) + \mathbf{B} \mathbf{u}(t) \\
	\mathbf{y}(t) &= \mathbf{C} \mathbf{x}(t) + \mathbf{D} \mathbf{u}(t)
\end{cases}
\end{align}

First of all, it is necessary so access some properties of the matrix $A$, which describes the natural evolution of the states. 

\begin{definition}{(State-Transition Matrix)} \label{def:stateTransM}
	Consider any model in SS representation with matrix $\mathbf{A} \in \mathcal{R}^{n \times n}$. the State-Transition Matrix, $e^{\mathbf{A}t} \in \mathcal{R}^{n \times n}$ , of this system is the converging series:
\begin{equation}
	e^{\mathbf{A}t} = \mathbf{I} + \mathbf{At} + \cfrac{\mathbf{A}^2 t^2}{2!} + \cfrac{\mathbf{A}^3 t^3}{3!} + \cdots = \sum_{k=0}^{\infty} \cfrac{A^k t^k}{k!}
\end{equation} 
\end{definition}

This matrix is central to the computation of the system time response, and can be used both to simulate the system and to analyze the properties of its natural response.  Given that, by definition, the matrix $A$ is a square matrix, this operation leads to some useful properties, as stated below:

\begin{theorem}
	Consider a matrix exponential as in Definition \ref{def:stateTransM}, for a matrix $\mathbf{A}  \in \mathcal{R}^{n \times n}$. Then:
	
\begin{tabular}{c c c c c}
		1. $\cfrac{d e^{\mathbf{A} t}}{dt} = \mathbf{A} e^{\mathbf{A} t}$ & &
		2. $e^{\mathbf{A} t} e^{\mathbf{A} \tau} = e^{\mathbf{A} (t - \tau)}$ & &
		3. $e^{-\mathbf{A} t} e^{\mathbf{A} t} = e^{\mathbf{A} t} e^{-\mathbf{A} t} = \mathbf{I}$
	\end{tabular}
\end{theorem}

\begin{proof}
	Consider Definition \ref{def:stateTransM}. In this case:
	\begin{equation}
		\cfrac{d ( e^{\mathbf{A} t})}{dt} = \cfrac{d}{dt} \left( \sum_{k=0}^{\infty} \cfrac{\mathbf{A}^k  t^k}{k!} \right) = \sum_{k=0}^{\infty} \cfrac{\mathbf{A}^k  t^{k-1}}{(k-1)!}  = \mathbf{A} \sum_{k=1}^{\infty} \cfrac{\mathbf{A}^{k-1}  t^{k-1}}{(k-1)!}  = \mathbf{A} e^{\mathbf{A} t}
	\end{equation}

\noindent which proofs the first assertive. Similarly, it is possible to calculate:
	\begin{equation}
		 e^{\mathbf{A} t} e^{\mathbf{A} \tau} = \left( \sum_{k=0}^{\infty} \cfrac{\mathbf{A}^k  t^k}{k!} \right) \left( \sum_{k=0}^{\infty} \cfrac{\mathbf{A}^k  \tau^k}{k!} \right) = \left( \sum_{k=0}^{\infty} \cfrac{\mathbf{A}^k  t^k}{k!} + \cfrac{\mathbf{A}^k  \tau^k}{k!} \right) = \sum_{k=0}^{\infty} \cfrac{\mathbf{A}^k}{k!} (t + \tau) = e^{\mathbf{A} (t+\tau)}
	\end{equation}

\noindent which proofs the second assertive.  Using this result, it is possible to prove the third assertive:
	\begin{equation}
		 e^{\mathbf{A} t} e^{-\mathbf{A} t} = e^{\mathbf{A} (t-t)} = e^{0} = \mathbf{I}  
	\end{equation} 
\end{proof}



\section{Frequency Response Analysis}

Although the response of dynamical systems are naturally perceived in time, there are advantages of analyzing the models in a frequency domain perspective.

\section{Stability Analysis}

at

\section{Controlability and Observability}

a

% 3 - Controller Design
% ---------------------------------------------------------------
\clearpage
\chapter{Controller Design}

a

\section{Control Architectures}

a

\section{Full-State Feedback}

a

\section{Regulation and Reference Tracking}

a

\section{Deterministic State Observers}

a

% 4 - Optimal Control
% ---------------------------------------------------------------
\clearpage
\chapter{Optimal Control}

a

\section{General Formulation}

a

\section{Linear Quadratic Regulator (LQR)}

a

\section{Optimal State Estimators}

a

\section{Linear Quadratic Gaussian (LQG)}

a

\section{Robustness and Stability Analysis}


% 5 - Methodology
% ---------------------------------------------------------------
\clearpage
\chapter{Methodology}

a

% 6 - Results and Discussion
% ---------------------------------------------------------------
\clearpage
\chapter{Results and Discussion}

a

% 7 - Conclusion
% ---------------------------------------------------------------
\clearpage
\chapter{Conclusion}

a

% Bibliography
% ---------------------------------------------------------------
\clearpage
\addcontentsline{toc}{chapter}{Bibliography}

\bibliographystyle{apalike}
\bibliography{citations}

% A - Apêndice A
% ---------------------------------------------------------------
\clearpage
\addcontentsline{toc}{chapter}{Appendix A}
\chapter*{Appendix A}

a
	
% ---------------------------------------------------------------
% End document
% ---------------------------------------------------------------

\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Drafts:
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% Figure:
% \begin{figure}[ht]
% 	\centering
% 	\includegraphics[trim={0cm 0cm 0cm 0cm},clip,scale=1]{nameFigure}
% 	\caption{caption of the figure.}
% 	\label{fig:nameFigure}
% \end{figure} \vskip0.25cm
%
%%%%% Equation:
% \begin{equation} \label{eq:nameEquation}
% \begin{split}
%	 X = 1 + 1
% \end{split}
% \end{equation} \vskip0.25cm
%
%%%% Table:
% \begin{table}[hp]
% 	\centering
% 	\begin{tabular}{l | c c }
% 	Principal & Coluna1 & Coluna2 \\
% 	\hline 
% 	ABC	& 1 & 2 \\
% 	DFG	& 3 & 4 \\
% 	HIJ	& 5 & 6 \\
% 	\end{tabular} 
% 	\caption{caption of the table.}
% 	\label{table:nameTable}	
% \end{table} \vskip0.25cm